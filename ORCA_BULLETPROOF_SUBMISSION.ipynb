{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üêã ORCA BULLETPROOF - ARC Prize 2025\n",
    "\n",
    "**This version GUARANTEES correct submission format**\n",
    "\n",
    "Strategy:\n",
    "1. Read sample_submission.json to get EXACT format\n",
    "2. Generate predictions matching that structure EXACTLY\n",
    "3. Validate every single field\n",
    "4. Zero chance of format errors\n",
    "\n",
    "Just click Run All! ‚ú®"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3\n",
    "import numpy as np\n",
    "import json\n",
    "import os\n",
    "from pathlib import Path\n",
    "from collections import Counter\n",
    "import itertools\n",
    "\n",
    "print(\"üêã ORCA BULLETPROOF - Loading...\")\n",
    "\n",
    "# ============================================================================\n",
    "# STEP 1: DISCOVER THE EXACT FORMAT FROM SAMPLE_SUBMISSION.JSON\n",
    "# ============================================================================\n",
    "\n",
    "data_dir = Path('/kaggle/input/arc-prize-2025')\n",
    "\n",
    "# Read sample submission to understand format\n",
    "with open(data_dir / 'sample_submission.json', 'r') as f:\n",
    "    sample_submission = json.load(f)\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"SAMPLE SUBMISSION FORMAT ANALYSIS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Analyze structure\n",
    "print(f\"Type: {type(sample_submission)}\")\n",
    "\n",
    "if isinstance(sample_submission, dict):\n",
    "    print(f\"Keys: {len(sample_submission)} (dict of task_ids)\")\n",
    "    first_key = list(sample_submission.keys())[0]\n",
    "    print(f\"First key: {first_key}\")\n",
    "    print(f\"First value type: {type(sample_submission[first_key])}\")\n",
    "    print(f\"First value: {str(sample_submission[first_key])[:200]}...\")\n",
    "    IS_DICT_FORMAT = True\n",
    "elif isinstance(sample_submission, list):\n",
    "    print(f\"Length: {len(sample_submission)} (list of entries)\")\n",
    "    print(f\"First entry: {sample_submission[0]}\")\n",
    "    IS_DICT_FORMAT = False\n",
    "\n",
    "# Load test challenges\n",
    "with open(data_dir / 'arc-agi_test_challenges.json', 'r') as f:\n",
    "    test_challenges = json.load(f)\n",
    "\n",
    "print(f\"\\nTest tasks: {len(test_challenges)}\")\n",
    "print(f\"Sample submission entries: {len(sample_submission)}\")\n",
    "\n",
    "# ============================================================================\n",
    "# PRIMITIVES (COMPACT VERSION)\n",
    "# ============================================================================\n",
    "\n",
    "def identity(g): return g\n",
    "def rotate_90(g): return [list(row) for row in zip(*g[::-1])]\n",
    "def flip_h(g): return [row[::-1] for row in g]\n",
    "def flip_v(g): return g[::-1]\n",
    "\n",
    "PRIMITIVES = [\n",
    "    ('id', identity),\n",
    "    ('rot90', rotate_90),\n",
    "    ('flip_h', flip_h),\n",
    "    ('flip_v', flip_v),\n",
    "]\n",
    "\n",
    "# ============================================================================\n",
    "# GRID UTILITIES\n",
    "# ============================================================================\n",
    "\n",
    "def validate_grid(g):\n",
    "    \"\"\"Ensure grid is valid JSON-serializable with colors 0-9\"\"\"\n",
    "    if not g or not g[0]:\n",
    "        return [[0]]\n",
    "    \n",
    "    result = []\n",
    "    for row in g:\n",
    "        valid_row = []\n",
    "        for cell in row:\n",
    "            # Ensure it's an int in range 0-9\n",
    "            try:\n",
    "                val = int(cell)\n",
    "                val = max(0, min(9, val))\n",
    "                valid_row.append(val)\n",
    "            except:\n",
    "                valid_row.append(0)\n",
    "        result.append(valid_row)\n",
    "    \n",
    "    return result\n",
    "\n",
    "def simple_solve(test_input):\n",
    "    \"\"\"Simple solver: try a few transformations\"\"\"\n",
    "    test_input = validate_grid(test_input)\n",
    "    \n",
    "    # Try different operations\n",
    "    candidates = [test_input]\n",
    "    \n",
    "    for name, op in PRIMITIVES:\n",
    "        try:\n",
    "            result = validate_grid(op(test_input))\n",
    "            candidates.append(result)\n",
    "        except:\n",
    "            pass\n",
    "    \n",
    "    # Return first two different candidates\n",
    "    if len(candidates) >= 2:\n",
    "        return candidates[0], candidates[1]\n",
    "    else:\n",
    "        return candidates[0], candidates[0]\n",
    "\n",
    "print(\"‚úì Utilities loaded\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# STEP 2: GENERATE SUBMISSION IN EXACT FORMAT\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"GENERATING SUBMISSION\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Create submission matching sample format EXACTLY\n",
    "if IS_DICT_FORMAT:\n",
    "    # Format: {task_id: [list of attempts]}\n",
    "    submission = {}\n",
    "    \n",
    "    for task_id, task_data in test_challenges.items():\n",
    "        test_items = task_data['test']\n",
    "        task_attempts = []\n",
    "        \n",
    "        for test_item in test_items:\n",
    "            test_input = test_item['input']\n",
    "            attempt_1, attempt_2 = simple_solve(test_input)\n",
    "            \n",
    "            # Match sample format exactly\n",
    "            task_attempts.append({\n",
    "                'attempt_1': attempt_1,\n",
    "                'attempt_2': attempt_2\n",
    "            })\n",
    "        \n",
    "        submission[task_id] = task_attempts\n",
    "        \n",
    "        if len(submission) % 50 == 0:\n",
    "            print(f\"  Progress: {len(submission)}/{len(test_challenges)} tasks\")\n",
    "\nelse:\n",
    "    # Format: list of entries\n",
    "    submission = []\n",
    "    \n",
    "    for task_id, task_data in test_challenges.items():\n",
    "        test_items = task_data['test']\n",
    "        \n",
    "        for test_item in test_items:\n",
    "            test_input = test_item['input']\n",
    "            attempt_1, attempt_2 = simple_solve(test_input)\n",
    "            \n",
    "            submission.append({\n",
    "                'task_id': task_id,\n",
    "                'attempt_1': attempt_1,\n",
    "                'attempt_2': attempt_2\n",
    "            })\n",
    "        \n",
    "        if len(submission) % 50 == 0:\n",
    "            print(f\"  Progress: {len(submission)} entries\")\n",
    "\n",
    "print(f\"\\n‚úì Generated {'dict' if IS_DICT_FORMAT else 'list'} with {len(submission)} entries\")\n",
    "\n",
    "# ============================================================================\n",
    "# STEP 3: EXTREME VALIDATION\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"VALIDATION\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "validation_issues = []\n",
    "\n",
    "# Check structure matches sample\n",
    "if type(submission) != type(sample_submission):\n",
    "    validation_issues.append(f\"Type mismatch: {type(submission)} vs {type(sample_submission)}\")\n",
    "\n",
    "if IS_DICT_FORMAT:\n",
    "    # Validate dict format\n",
    "    if len(submission) != len(test_challenges):\n",
    "        validation_issues.append(f\"Wrong number of tasks: {len(submission)} vs {len(test_challenges)}\")\n",
    "    \n",
    "    for task_id, attempts in submission.items():\n",
    "        if not isinstance(attempts, list):\n",
    "            validation_issues.append(f\"Task {task_id}: attempts not a list\")\n",
    "            continue\n",
    "        \n",
    "        for i, attempt_obj in enumerate(attempts):\n",
    "            if 'attempt_1' not in attempt_obj:\n",
    "                validation_issues.append(f\"Task {task_id} item {i}: missing attempt_1\")\n",
    "            if 'attempt_2' not in attempt_obj:\n",
    "                validation_issues.append(f\"Task {task_id} item {i}: missing attempt_2\")\n",
    "            \n",
    "            for key in ['attempt_1', 'attempt_2']:\n",
    "                if key in attempt_obj:\n",
    "                    grid = attempt_obj[key]\n",
    "                    \n",
    "                    # Check it's a list of lists\n",
    "                    if not isinstance(grid, list):\n",
    "                        validation_issues.append(f\"Task {task_id} {key}: not a list\")\n",
    "                        continue\n",
    "                    \n",
    "                    if not grid or not isinstance(grid[0], list):\n",
    "                        validation_issues.append(f\"Task {task_id} {key}: not a 2D grid\")\n",
    "                        continue\n",
    "                    \n",
    "                    # Check all cells are valid integers 0-9\n",
    "                    for r, row in enumerate(grid):\n",
    "                        if not isinstance(row, list):\n",
    "                            validation_issues.append(f\"Task {task_id} {key} row {r}: not a list\")\n",
    "                            break\n",
    "                        for c, cell in enumerate(row):\n",
    "                            if not isinstance(cell, int) or cell < 0 or cell > 9:\n",
    "                                validation_issues.append(f\"Task {task_id} {key} [{r},{c}]: invalid value {cell}\")\n",
    "                                break\n",
    "\n",
    "else:\n",
    "    # Validate list format\n",
    "    for i, entry in enumerate(submission):\n",
    "        if 'attempt_1' not in entry:\n",
    "            validation_issues.append(f\"Entry {i}: missing attempt_1\")\n",
    "        if 'attempt_2' not in entry:\n",
    "            validation_issues.append(f\"Entry {i}: missing attempt_2\")\n",
    "\n",
    "if validation_issues:\n",
    "    print(f\"\\n‚ö†Ô∏è  Found {len(validation_issues)} issues:\")\n",
    "    for issue in validation_issues[:10]:\n",
    "        print(f\"  - {issue}\")\n",
    "    if len(validation_issues) > 10:\n",
    "        print(f\"  ... and {len(validation_issues)-10} more\")\n",
    "else:\n",
    "    print(\"‚úÖ ALL VALIDATIONS PASSED\")\n",
    "\n",
    "# ============================================================================\n",
    "# STEP 4: SAVE WITH ATOMIC WRITE\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"SAVING\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "output_paths = [\n",
    "    '/kaggle/working/submission.json',\n",
    "    '/kaggle/output/submission.json'\n",
    "]\n",
    "\n",
    "for output_path in output_paths:\n",
    "    try:\n",
    "        os.makedirs(os.path.dirname(output_path), exist_ok=True)\n",
    "        \n",
    "        # Atomic write (tmp file then rename)\n",
    "        tmp_path = output_path + '.tmp'\n",
    "        with open(tmp_path, 'w') as f:\n",
    "            json.dump(submission, f, separators=(',', ':'))\n",
    "        \n",
    "        os.replace(tmp_path, output_path)\n",
    "        \n",
    "        # Verify\n",
    "        size = os.path.getsize(output_path) / 1024\n",
    "        print(f\"‚úì {output_path} ({size:.1f} KB)\")\n",
    "        \n",
    "        # Double-check by reading back\n",
    "        with open(output_path, 'r') as f:\n",
    "            verify = json.load(f)\n",
    "        print(f\"  ‚úì Verified: {len(verify)} entries\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚úó Error saving {output_path}: {e}\")\n",
    "\n",
    "# ============================================================================\n",
    "# FINAL SUMMARY\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"‚úÖ COMPLETE\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "print(f\"\\nFormat: {'Dictionary (task_id: attempts)' if IS_DICT_FORMAT else 'List of entries'}\")\n",
    "print(f\"Entries: {len(submission)}\")\n",
    "print(f\"Validation: {'PASSED' if not validation_issues else f'{len(validation_issues)} issues'}\")\n",
    "print(f\"\\nReady for submission: {output_paths[0]}\")\n",
    "print(\"\\nüêã BULLETPROOF COMPLETE! üéâ\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.7.12"
  },
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [{
    "sourceId": 91496,
    "databundleVersionId": 11802066,
    "sourceType": "competition"
   }],
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook",
   "isGpuEnabled": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
