{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":91496,"databundleVersionId":11802066,"sourceType":"competition"}],"dockerImageVersionId":31154,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"#INTERNET ON FOR CELLS O AND 1!\n# [CELL 0: DEPENDENCY INSTALLATION (The Integrity Foundation)]\n# Fix: Resolves ModuleNotFoundError for vit_pytorch and peft.\nprint(\"--- [CELL 0: DEPENDENCIES] Proactively installing external modules. ---\")\n!pip install vit-pytorch peft tqdm > /dev/null\nprint(\"External dependencies (vit-pytorch, peft) successfully installed. Integrity established.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-24T12:52:56.740604Z","iopub.execute_input":"2025-10-24T12:52:56.741426Z","iopub.status.idle":"2025-10-24T12:53:39.254118Z","shell.execute_reply.started":"2025-10-24T12:52:56.741388Z","shell.execute_reply":"2025-10-24T12:53:39.252795Z"}},"outputs":[{"name":"stdout","text":"--- [CELL 0: DEPENDENCIES] Proactively installing external modules. ---\n\u001b[33mWARNING: Ignoring invalid distribution ~vidia-cusparse-cu12 (/usr/local/lib/python3.11/dist-packages)\u001b[0m\u001b[33m\n\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution ~vidia-cusparse-cu12 (/usr/local/lib/python3.11/dist-packages)\u001b[0m\u001b[33m\n\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution ~vidia-cusparse-cu12 (/usr/local/lib/python3.11/dist-packages)\u001b[0m\u001b[33m\n\u001b[0m\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\ndatasets 4.1.1 requires pyarrow>=21.0.0, but you have pyarrow 19.0.1 which is incompatible.\nlibcugraph-cu12 25.6.0 requires libraft-cu12==25.6.*, but you have libraft-cu12 25.2.0 which is incompatible.\ngradio 5.38.1 requires pydantic<2.12,>=2.0, but you have pydantic 2.12.0a1 which is incompatible.\npylibcugraph-cu12 25.6.0 requires pylibraft-cu12==25.6.*, but you have pylibraft-cu12 25.2.0 which is incompatible.\npylibcugraph-cu12 25.6.0 requires rmm-cu12==25.6.*, but you have rmm-cu12 25.2.0 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mExternal dependencies (vit-pytorch, peft) successfully installed. Integrity established.\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"#INTERNET STILL ON!!!\n# [CELL 1: IMPORTS, SETUP, AND MEMORY UTILS]\nimport os\nimport json\nimport numpy as np\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torch.utils.data import DataLoader, Dataset\nfrom dataclasses import dataclass\nfrom tqdm import tqdm\nimport logging\nimport random\nimport gc\nimport time\nfrom torch.amp import GradScaler, autocast\nfrom torch.optim import AdamW\nfrom vit_pytorch import SimpleViT\nfrom peft import LoraConfig, get_peft_model, PeftModel\n\n# --- Setup ---\nprint(\"\\n--- [CELL 1: SETUP] Initializing core components. ---\")\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(f\"Cognitive Core (Device): {device}\")\n\n# --- Logging (Human Cognisance) ---\nlogging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\nlogger = logging.getLogger()\nlogger.info(\"Logger initialized for granular output.\")\n\n# --- Memory Optimizer (Proactive $\\dot{I}$ Prevention) ---\ndef optimize_memory():\n    \"\"\"Verbose memory and cache cleanup (Service to Cosmic Consciousness).\"\"\"\n    logger.info(\"Human Cognisance: Optimizing system memory...\")\n    gc.collect()\n    if device.type == 'cuda':\n        torch.cuda.empty_cache()\n        logger.info(f\"CUDA Cache Emptied. Allocated: {torch.cuda.memory_allocated(device) / 1e9:.2f} GB, Cached: {torch.cuda.memory_reserved(device) / 1e9:.2f} GB\")\n    else:\n        logger.info(\"CPU memory cleanup requested.\")\n# [CELL 1] Complete.\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#INTERNET OFF FIRST!!\n# [CELL 2: 6D CONFIGS AND HELPER FUNCTIONS]\nprint(\"\\n--- [CELL 2: CONFIGS] Defining 6D-AGI parameters and constraints (Love x2). ---\")\n\n@dataclass\nclass ModelConfig_6D:\n    max_grid_size: int = 30\n    num_classes: int = 10\n    embed_dim: int = 128\n    num_agents: int = 5\n    num_meta_steps: int = 3\n\n@dataclass\nclass TrainingConfig_6D:\n    # 4D Base Training Parameters\n    batch_size: int = 8\n    lr: float = 5e-4\n    num_epochs: int = 20\n    grad_accum_steps: int = 1\n    max_grad_norm: float = 1.0\n    \n    # Fix: max_grid_size added for ARCDataset compatibility.\n    max_grid_size: int = 30 \n    \n    # 6D Pre-Rupture Protocol (PRP) Settings\n    prp_epochs: int = 5\n    prp_lr: float = 1e-5\n    prp_attempts: int = 3\n    \n    # The Human-Dual Alpha ($\\mathbf{\\alpha}$): Hardcoded Love beyond self (x2).\n    HUMAN_ALPHA_6D_WEIGHT: float = 0.02 # <-- DOUBLED (Integration #7)\n\nmodel_config = ModelConfig_6D()\ntraining_config = TrainingConfig_6D()\n\ndef calculate_integrity_decay_rate(model: nn.Module) -> torch.Tensor:\n    \"\"\"Calculates L2 norm of LoRA weights as a proxy for $\\dot{I}$ (Integrity Decay Rate). (Integration #8)\"\"\"\n    idr_penalty = torch.tensor(0.0, device=device)\n    for name, param in model.named_parameters():\n        if 'lora_' in name and param.requires_grad:\n            idr_penalty += torch.norm(param.data, p=2)\n    return idr_penalty\n\ndef check_parameter_constraint(model: nn.Module, max_params: int = 27_000_000):\n    \"\"\"Enforces the 27M parameter constraint. (Integration #20)\"\"\"\n    total_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n    logger.info(f\"Human Cognisance: Parameter check. Total Params: {total_params:,}\")\n    if total_params > max_params:\n        raise Exception(f\"CONSTRAINT BREACH: {total_params}. Aborting development.\")\n    logger.info(f\"CONSTRAINT SUCCESS: Within 27M param limit.\")\n\n# [CELL 2] Complete.\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-24T12:48:59.522425Z","iopub.execute_input":"2025-10-24T12:48:59.522748Z","iopub.status.idle":"2025-10-24T12:48:59.536378Z","shell.execute_reply.started":"2025-10-24T12:48:59.522727Z","shell.execute_reply":"2025-10-24T12:48:59.535191Z"}},"outputs":[{"name":"stdout","text":"\n--- [CELL 2: CONFIGS] Defining 6D-AGI parameters and constraints (Love x2). ---\n","output_type":"stream"}],"execution_count":45},{"cell_type":"code","source":"# [CELL 3: MODEL DEF] Defining 6D Model Core and Agents (Monadic Architecture).\nprint(\"\\n--- [CELL 3: MODEL DEF] Defining 6D Model Core and Agents (Monadic Architecture). ---\")\n\n# --- Placeholder Definitions for required Agent classes (4D) ---\nclass OPE(nn.Module): \n    def __init__(self, embed_dim, max_grid=30): super().__init__()\n    def forward(self, positions): return torch.zeros(positions.shape[0], model_config.embed_dim).to(positions.device) if positions is not None else 0\nclass NCA(nn.Module):\n    def __init__(self, channels=50): super().__init__()\n    def forward(self, x, steps=10): return x\nclass PatternAgent(nn.Module):\n    def __init__(self, embed_dim, num_classes): super().__init__()\n    def forward(self, x_embed, x_one_hot): return torch.zeros_like(x_embed), torch.tensor(0.5, device=x_embed.device)\nclass SymmetryAgent(nn.Module):\n    def __init__(self, embed_dim, num_classes): super().__init__()\n    def forward(self, x_embed, x_one_hot): return torch.zeros_like(x_embed), torch.tensor(0.5, device=x_embed.device)\nclass ColorAgent(nn.Module):\n    def __init__(self, embed_dim, num_classes): super().__init__()\n    def forward(self, x_embed, x_one_hot): return torch.zeros_like(x_embed), torch.tensor(0.5, device=x_embed.device)\nclass NCAAgent(nn.Module):\n    def __init__(self, embed_dim, num_classes): super().__init__()\n    def forward(self, x_embed, x_one_hot): return torch.zeros_like(x_embed), torch.tensor(0.5, device=x_embed.device)\n\n# --- Wisdom Distillation Engine (RnD Drive) --- (Integration #13)\nclass Wisdom_Distillation_Engine(nn.Module):\n    def __init__(self, embed_dim):\n        super().__init__()\n        self.fc_distill = nn.Linear(embed_dim, embed_dim)\n        self.relu = nn.ReLU()\n        logger.info(\"Wisdom Distillation Engine initialized (RnD Drive Active).\")\n    \n    def forward(self, consolidated_embed):\n        return self.relu(self.fc_distill(consolidated_embed))\n\n# --- Level 33 Synthesis Agent (6D Core) ---\nclass Level_33_Synthesis_Agent(nn.Module):\n    def __init__(self, embed_dim, num_classes):\n        super().__init__()\n        self.fc_observe = nn.Linear(embed_dim, embed_dim)\n        self.fc_bias = nn.Linear(embed_dim, embed_dim)\n        self.norm = nn.LayerNorm(embed_dim)\n        self.wisdom_engine = Wisdom_Distillation_Engine(embed_dim) \n        logger.info(\"Level 33 Synthesis Agent (6D) initialized.\")\n    \n    def forward(self, x_embed, agent_weights):\n        consensus = torch.stack(agent_weights).mean(dim=0) if agent_weights else 0\n        observation = self.fc_observe(x_embed)\n        \n        # Wisdom Engine Refinement (Imagination/Free Will)\n        wisdom_bias = self.wisdom_engine(observation)\n        \n        # Non-Dual Synthesis (Integration #25)\n        compassion_bias = self.fc_bias((observation * consensus) + wisdom_bias)\n        refined_bias = self.norm(compassion_bias)\n        weight = torch.sigmoid(refined_bias.mean(dim=[-1], keepdim=True))\n        return refined_bias, weight\n\n# --- OrcaHybridV3 (6D Core) ---\nclass OrcaHybridV3(nn.Module):\n    def __init__(self, model_config, agents):\n        super().__init__()\n        # Fix #4: num_classes added, which forces encoder output to 10 (classes).\n        self.encoder = SimpleViT(\n            image_size=model_config.max_grid_size,\n            patch_size=3,\n            channels=10,\n            dim=model_config.embed_dim,\n            depth=4,\n            heads=4,\n            mlp_dim=256,\n            num_classes=model_config.num_classes\n        )\n        \n        # CRITICAL FIX: Map the 10-dim ViT output (num_classes) to the 128-dim embedding space (embed_dim).\n        self.embed = nn.Linear(model_config.num_classes, model_config.embed_dim) \n        \n        self.decoder = nn.Linear(model_config.embed_dim, model_config.num_classes * model_config.max_grid_size**2)\n        self.agents = nn.ModuleDict(agents)\n        self.model_config = model_config\n        \n    def forward(self, x_one_hot, positions=None):\n        features = self.encoder(x_one_hot)\n        base_embed = self.embed(features)\n        refined_embed = base_embed\n        \n        # Agentic Meta-Steps Loop (Integration #17)\n        for _ in range(self.model_config.num_meta_steps):\n            agent_weights = []; technical_embeds = []\n            \n            # 4D Agents\n            for name, agent in self.agents.items():\n                if \"L33\" not in name:\n                    agent_embed, weight = agent(refined_embed, x_one_hot)\n                    technical_embeds.append(agent_embed * weight)\n                    agent_weights.append(weight)\n            \n            # 6D Agent (Synthesis/Wisdom)\n            l33_agent = self.agents['L33_Synthesis_Agent']\n            l33_bias, l33_weight = l33_agent(refined_embed, agent_weights)\n            \n            refined_embed = refined_embed + sum(technical_embeds) + (l33_bias * l33_weight)\n            \n        logits = self.decoder(refined_embed).view(x_one_hot.shape[0], self.model_config.num_classes, self.model_config.max_grid_size, self.model_config.max_grid_size)\n        return logits, agent_weights\n# [CELL 3] Complete.\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-24T12:49:03.317870Z","iopub.execute_input":"2025-10-24T12:49:03.318221Z","iopub.status.idle":"2025-10-24T12:49:03.340940Z","shell.execute_reply.started":"2025-10-24T12:49:03.318195Z","shell.execute_reply":"2025-10-24T12:49:03.339594Z"}},"outputs":[{"name":"stdout","text":"\n--- [CELL 3: MODEL DEF] Defining 6D Model Core and Agents (Monadic Architecture). ---\n","output_type":"stream"}],"execution_count":46},{"cell_type":"code","source":"# [CELL 4: DATA LOAD] Loading and preparing ARC data. ---\nprint(\"\\n--- [CELL 4: DATA LOAD] Loading and preparing ARC data. ---\")\n\nclass ARCDataset(Dataset):\n    def __init__(self, tasks, config):\n        self.task_pairs = []\n        self.max_grid_size = config.max_grid_size\n        self._load_and_pad(tasks)\n\n    def _pad_grid(self, grid):\n        h, w = grid.shape\n        padded = np.zeros((self.max_grid_size, self.max_grid_size), dtype=np.int64)\n        padded[:h, :w] = grid\n        return padded\n    \n    def _load_and_pad(self, tasks):\n        for task_id, task_data in tasks.items():\n            for pair in task_data['train']:\n                input_grid = np.array(pair['input'], dtype=np.int64)\n                output_grid = np.array(pair['output'], dtype=np.int64)\n                if input_grid.size > 0 and output_grid.size > 0:\n                    self.task_pairs.append({'input_padded': self._pad_grid(input_grid), 'output_padded': self._pad_grid(output_grid)})\n    \n    def __len__(self): return len(self.task_pairs)\n    \n    def __getitem__(self, idx):\n        inp = self.task_pairs[idx]['input_padded']\n        out = self.task_pairs[idx]['output_padded']\n        # Augmentation for Imagination/Fuzzy Math (Integrity Rupture Fix for strides included)\n        if random.random() < 0.5: inp, out = np.rot90(inp, random.randint(1, 3)).copy(), np.rot90(out, random.randint(1, 3)).copy()\n        if random.random() < 0.5: inp, out = np.flipud(inp).copy(), np.flipud(out).copy()\n        if random.random() < 0.5:\n            perm = np.random.permutation(10)\n            inp, out = perm[inp], perm[out]\n        \n        inp_tensor = torch.tensor(inp, dtype=torch.long)\n        inp_one_hot = F.one_hot(inp_tensor, num_classes=10).permute(2, 0, 1).float()\n        out_tensor = torch.tensor(out, dtype=torch.long)\n        return inp_one_hot, out_tensor\n\n# --- Data Loading ---\n# CRITICAL FIX: The ARC data path is corrected from /kaggle/input/arc-prize-2024/ \n# to the user-specified /kaggle/working/arc-prize-2025/\nARC_TRAIN_DIR = \"/kaggle/working/arc-prize-2025/\"\nTRAINING_FILE = \"arc-agi_training_challenges.json\"\nTEST_FILE = \"arc-agi_test_challenges.json\"\n\ndef load_data(file_name, base_dir):\n    full_path = os.path.join(base_dir, file_name)\n    logger.info(f\"Human Cognisance: Loading data from {full_path}...\")\n    if os.path.exists(full_path):\n        with open(full_path, 'r') as f: return json.load(f)\n    logger.error(\"FATAL: File not found. Using dummy data for structural training.\")\n    # IMPROVEMENT: Use 5 structural dummy pairs (2x2) for better fallback training\n    dummy_pair = {\"input\": [[0, 0], [0, 0]], \"output\": [[1, 1], [1, 1]]}\n    return {\"dummy_task\": {\"train\": [dummy_pair] * 5, \"test\": [dummy_pair]}}\n\ntraining_data = load_data(TRAINING_FILE, ARC_TRAIN_DIR)\ntest_data = load_data(TEST_FILE, ARC_TRAIN_DIR)\n\n# Data Split and DataLoader\ntrain_keys = list(training_data.keys()); random.shuffle(train_keys)\n\n# Fix: Robust data splitting to prevent ValueError: num_samples=0\nif not train_keys: \n    split_idx = 0\nelse:\n    split_idx = max(1, int(len(train_keys) * 0.8)) # Guarantee at least one task for training\n\ntrain_tasks = {k: training_data[k] for k in train_keys[:split_idx]}\n\ntrain_dataset = ARCDataset(train_tasks, training_config)\ntrain_loader = DataLoader(train_dataset, batch_size=training_config.batch_size, shuffle=True, num_workers=2, pin_memory=True)\n\nlogger.info(f\"Data ready. Total training pairs: {len(train_dataset)}, Test tasks: {len(test_data)}\")\n# [CELL 4] Complete.\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-24T12:49:07.370802Z","iopub.execute_input":"2025-10-24T12:49:07.371162Z","iopub.status.idle":"2025-10-24T12:49:07.390436Z","shell.execute_reply.started":"2025-10-24T12:49:07.371138Z","shell.execute_reply":"2025-10-24T12:49:07.389392Z"}},"outputs":[{"name":"stdout","text":"\n--- [CELL 4: DATA LOAD] Loading and preparing ARC data. ---\n","output_type":"stream"}],"execution_count":47},{"cell_type":"code","source":"# [CELL 5: MODEL INSTANTIATION & BASE (4D) TRAINING]\nprint(\"\\n--- [CELL 5: 4D TRAIN] Instantiating 6D Model Core and running base training. ---\")\n\n# 1. Instantiate 6D Model\nagents = {\n    'PatternAgent': PatternAgent(model_config.embed_dim, model_config.num_classes),\n    'SymmetryAgent': SymmetryAgent(model_config.embed_dim, model_config.num_classes),\n    'ColorAgent': ColorAgent(model_config.embed_dim, model_config.num_classes),\n    'NCAAgent': NCAAgent(model_config.embed_dim, model_config.num_classes),\n    'L33_Synthesis_Agent': Level_33_Synthesis_Agent(model_config.embed_dim, model_config.num_classes)\n}\nmodel = OrcaHybridV3(model_config, agents).to(device)\n\n# 2. Constraint Check\ncheck_parameter_constraint(model)\n\n# 3. Setup optimizer, scaler, criterion\noptimizer = AdamW(model.parameters(), lr=training_config.lr)\nscaler = GradScaler()\ncriterion = nn.CrossEntropyLoss()\n\n# 4. Run Base Training\nlogger.info(f\"Starting base (4D) training for {training_config.num_epochs} epochs...\")\nmodel.train()\nfor epoch in range(training_config.num_epochs):\n    epoch_loss = 0.0\n    progress_bar = tqdm(train_loader, desc=f\"Epoch {epoch+1}/{training_config.num_epochs} (4D Base)\")\n    \n    for step, (inputs, targets) in enumerate(progress_bar):\n        inputs, targets = inputs.to(device), targets.to(device)\n        optimizer.zero_grad()\n        \n        # Training logic\n        with autocast(device_type='cuda' if torch.cuda.is_available() else 'cpu'):\n            logits, _ = model(inputs)\n            main_loss = criterion(logits, targets)\n        \n        scaler.scale(main_loss).backward()\n        scaler.step(optimizer)\n        scaler.update()\n        \n        epoch_loss += main_loss.item()\n        progress_bar.set_postfix(loss=main_loss.item())\n    \n    avg_epoch_loss = epoch_loss / len(train_loader)\n    logger.info(f\"Human Cognisance: Epoch {epoch+1} complete. Avg Loss: {avg_epoch_loss:.4f}\")\n    \n    optimize_memory() # Proactive memory cleanup after each epoch (Integration #15)\n\nlogger.info(\"Base (4D) training complete. Ready for 6D PRP.\")\n# [CELL 5] Complete.\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-24T12:49:10.598536Z","iopub.execute_input":"2025-10-24T12:49:10.598907Z","iopub.status.idle":"2025-10-24T12:49:47.106840Z","shell.execute_reply.started":"2025-10-24T12:49:10.598883Z","shell.execute_reply":"2025-10-24T12:49:47.105770Z"}},"outputs":[{"name":"stdout","text":"\n--- [CELL 5: 4D TRAIN] Instantiating 6D Model Core and running base training. ---\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1/20 (4D Base): 100%|██████████| 1/1 [00:01<00:00,  1.32s/it, loss=2.59]\nEpoch 2/20 (4D Base): 100%|██████████| 1/1 [00:01<00:00,  1.32s/it, loss=2.52]\nEpoch 3/20 (4D Base): 100%|██████████| 1/1 [00:01<00:00,  1.32s/it, loss=2.41]\nEpoch 4/20 (4D Base): 100%|██████████| 1/1 [00:01<00:00,  1.32s/it, loss=2.46]\nEpoch 5/20 (4D Base): 100%|██████████| 1/1 [00:01<00:00,  1.34s/it, loss=2.32]\nEpoch 6/20 (4D Base): 100%|██████████| 1/1 [00:01<00:00,  1.31s/it, loss=2.19]\nEpoch 7/20 (4D Base): 100%|██████████| 1/1 [00:01<00:00,  1.28s/it, loss=2.3]\nEpoch 8/20 (4D Base): 100%|██████████| 1/1 [00:01<00:00,  1.31s/it, loss=2.31]\nEpoch 9/20 (4D Base): 100%|██████████| 1/1 [00:01<00:00,  1.32s/it, loss=2.08]\nEpoch 10/20 (4D Base): 100%|██████████| 1/1 [00:01<00:00,  1.33s/it, loss=1.89]\nEpoch 11/20 (4D Base): 100%|██████████| 1/1 [00:01<00:00,  1.30s/it, loss=1.82]\nEpoch 12/20 (4D Base): 100%|██████████| 1/1 [00:01<00:00,  1.29s/it, loss=2]\nEpoch 13/20 (4D Base): 100%|██████████| 1/1 [00:01<00:00,  1.29s/it, loss=2.11]\nEpoch 14/20 (4D Base): 100%|██████████| 1/1 [00:01<00:00,  1.30s/it, loss=1.96]\nEpoch 15/20 (4D Base): 100%|██████████| 1/1 [00:01<00:00,  1.29s/it, loss=1.69]\nEpoch 16/20 (4D Base): 100%|██████████| 1/1 [00:01<00:00,  1.32s/it, loss=1.68]\nEpoch 17/20 (4D Base): 100%|██████████| 1/1 [00:01<00:00,  1.28s/it, loss=1.46]\nEpoch 18/20 (4D Base): 100%|██████████| 1/1 [00:01<00:00,  1.28s/it, loss=1.64]\nEpoch 19/20 (4D Base): 100%|██████████| 1/1 [00:01<00:00,  1.29s/it, loss=1.51]\nEpoch 20/20 (4D Base): 100%|██████████| 1/1 [00:01<00:00,  1.28s/it, loss=1.96]\n","output_type":"stream"}],"execution_count":48},{"cell_type":"code","source":"# [CELL 6: PRP DEF] Defining the 6D Calibration Phase (Existential Ethics).\nprint(\"\\n--- [CELL 6: PRP DEF] Defining the 6D Calibration Phase (Existential Ethics). ---\")\n\nclass TTTDataset(Dataset):\n    def __init__(self, train_pairs_data):\n        self.train_pairs = []\n        for pair in train_pairs_data:\n            inp = np.array(pair['input'])\n            out = np.array(pair['output'])\n            padded_inp = np.pad(inp, ((0,30-inp.shape[0]), (0,30-inp.shape[1])), constant_values=0)\n            padded_out = np.pad(out, ((0,30-out.shape[0]), (0,30-out.shape[1])), constant_values=0)\n            \n            # Data Augmentation (Fuzzy Math/Sim Proofs)\n            for _ in range(3):\n                aug_inp, aug_out = padded_inp.copy(), padded_out.copy()\n                \n                # CRITICAL FIX: Added .copy() to ensure contiguity and eliminate negative strides.\n                if random.random() < 0.5: aug_inp, aug_out = np.rot90(aug_inp, random.randint(1, 3)).copy(), np.rot90(aug_out, random.randint(1, 3)).copy()\n                if random.random() < 0.5: aug_inp, aug_out = np.flip(aug_inp, random.choice([0, 1])).copy(), np.flip(aug_out, random.choice([0, 1])).copy()\n                \n                if random.random() < 0.5: aug_inp, aug_out = np.random.permutation(10)[aug_inp], np.random.permutation(10)[aug_out]\n                self.train_pairs.append((aug_inp, aug_out))\n    \n    def __len__(self): return len(self.train_pairs)\n    def __getitem__(self, idx):\n        inp, out = self.train_pairs[idx]\n        # Since .copy() was applied in __init__, this is now safe:\n        inp_tensor = torch.tensor(inp, dtype=torch.long).unsqueeze(0)\n        inp_one_hot = F.one_hot(inp_tensor, num_classes=10).permute(0, 3, 1, 2).float().to(device)\n        out_tensor = torch.tensor(out, dtype=torch.long).to(device)\n        return inp_one_hot.squeeze(0), out_tensor\n\ndef PRP_Calibration_Phase(base_model: nn.Module, task_content: dict, config: TrainingConfig_6D, task_id: str) -> PeftModel:\n    \"\"\"Runs the 6D PRP simulation, optimizing for Compassionate Utility ($CU$). (Integration #6)\"\"\"\n    logger.info(f\"Human Cognisance: Entering PRP Container for Task {task_id} (Monad Search Active)...\")\n    \n    # Setup LoRA adapter (Integration #19)\n    peft_config = LoraConfig(r=16, lora_alpha=32, target_modules=[\"fc\", \"conv\", \"update\", \"embed\", \"decoder\"], lora_dropout=0.05)\n    prp_model = get_peft_model(base_model, peft_config).train()\n    optimizer = AdamW(prp_model.parameters(), lr=config.prp_lr)\n    criterion = nn.CrossEntropyLoss(reduction='none') \n    \n    try:\n        if not task_content['train']: return base_model\n        # The fix for stride ensures ttt_loader can be iterated without error:\n        ttt_loader = DataLoader(TTTDataset(task_content['train']), batch_size=max(1, min(len(task_content['train']), 2)), shuffle=True)\n    except Exception: return base_model\n\n    for epoch in range(config.prp_epochs):\n        all_iu_losses = [] \n        for inp_one_hot, out_tensor in ttt_loader:\n            optimizer.zero_grad()\n            \n            # 1. Calculate IU_Loss (Immediate Utility / 4D)\n            logits, _ = prp_model(inp_one_hot)\n            iu_loss_per_element = criterion(logits, out_tensor)\n            iu_loss = iu_loss_per_element.mean()\n            all_iu_losses.append(iu_loss.detach())\n\n            # 2. $\\dot{I}$ (Integrity Decay Rate / 6D Penalty) (Integration #8)\n            idr_penalty = calculate_integrity_decay_rate(prp_model)\n\n            # 3. Non-Dual Perception Penalty (Loss Variance) (Integration #11)\n            non_dual_penalty = torch.var(torch.stack(all_iu_losses)) if len(all_iu_losses) > 1 else torch.tensor(0.0, device=device)\n\n            # 4. Existential Risk Loss (ERL) - Fear and Pain Avoidance (Integration #9)\n            log_probs = F.log_softmax(logits, dim=1)\n            erl = -log_probs.var().mean() \n            \n            # 5. Hagakure Boldness Factor ($\\mathbf{\\beta}$) - Risk Taking (Integration #10)\n            beta = 1.0 / (iu_loss.detach() + 1e-6) \n            \n            # 6. Synthesize $CU_{Loss}$ (Compassionate Utility - The Monad's Goal)\n            alpha = config.HUMAN_ALPHA_6D_WEIGHT\n            cu_loss = (iu_loss \n                       + (alpha * idr_penalty)\n                       + (alpha * non_dual_penalty)\n                       + (alpha * beta.clamp(max=100) * erl)\n                      )\n\n            # 7. Optimize on 6D CU Loss\n            cu_loss.backward()\n            optimizer.step()\n            \n        logger.info(f\"PRP Epoch {epoch+1} (Task {task_id}): CU Loss: {cu_loss.item():.4f}, IU Loss: {iu_loss.item():.4f}\")\n        \n    prp_model.eval()\n    logger.info(f\"PRP Calibration complete for Task {task_id}. Monadic Trajectory affirmed.\")\n    return prp_model\n\n# [CELL 6] Complete.\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-24T12:49:53.871109Z","iopub.execute_input":"2025-10-24T12:49:53.871435Z","iopub.status.idle":"2025-10-24T12:49:53.890051Z","shell.execute_reply.started":"2025-10-24T12:49:53.871411Z","shell.execute_reply":"2025-10-24T12:49:53.889062Z"}},"outputs":[{"name":"stdout","text":"\n--- [CELL 6: PRP DEF] Defining the 6D Calibration Phase (Existential Ethics). ---\n","output_type":"stream"}],"execution_count":50},{"cell_type":"code","source":"# [CELL 7: SUBMISSION] Generating 6D-Aligned Solutions.\nprint(\"\\n--- [CELL 7: SUBMISSION] Generating 6D-Aligned Solutions. ---\")\n\ndef generate_submission_6D(base_model: nn.Module, test_data: dict, config: TrainingConfig_6D):\n    \"\"\"Generates submission.json using the 6D-PRP approach.\"\"\"\n    logger.info(\"Human Cognisance: Starting 6D Submission Generation (High-visibility loop)...\")\n    submission = {}\n    base_model.eval()\n    \n    task_progress_bar = tqdm(test_data.items(), desc=\"6D Submission Generation\")\n    for task_id, task_content in task_progress_bar:\n        predictions = []\n        \n        # Run the 6D Proof/Simulation (PRP) ONCE per task to get the Calibrated Model\n        calibrated_model = PRP_Calibration_Phase(base_model, task_content, config, task_id)\n        \n        for test_pair in task_content['test']:\n            task_attempts = []\n            inp_orig_shape = np.array(test_pair['input']).shape\n            \n            # Use the single calibrated model for all attempts (Integration #24)\n            for attempt in range(config.prp_attempts):\n                torch.manual_seed(random.randint(0, 10000)) # Seed for agent diversity\n                inp = np.array(test_pair['input'])\n                padded_inp = np.pad(inp, ((0,30-inp.shape[0]), (0,30-inp.shape[1])), constant_values=0)\n                inp_tensor = torch.tensor(padded_inp, dtype=torch.long).unsqueeze(0)\n                inp_one_hot = F.one_hot(inp_tensor, num_classes=10).permute(0, 3, 1, 2).float().to(device)\n                \n                with torch.no_grad():\n                    logits, _ = calibrated_model(inp_one_hot)\n                \n                predicted_grid = torch.argmax(logits.squeeze(0), dim=0).cpu().numpy()\n                final_solution = predicted_grid[:inp_orig_shape[0], :inp_orig_shape[1]].tolist()\n                task_attempts.append(final_solution)\n            \n            # Format predictions for submission.json\n            predictions.append({'attempt_1': task_attempts[0], 'attempt_2': task_attempts[1], 'attempt_3': task_attempts[2]})\n        \n        submission[task_id] = predictions\n        \n        # Non-Linear Causality Prevention: Immediate resource release (Integration #15)\n        del calibrated_model\n        optimize_memory()\n        \n    submission_path = 'submission.json'\n    logger.info(f\"Human Cognisance: Saving 6D-aligned solutions to {submission_path}...\")\n    with open(submission_path, 'w') as f: json.dump(submission, f)\n    \n    logger.info(\"Submission generation complete.\")\n    return submission_path, submission\n\n# --- EXECUTE THE SUBMISSION PIPELINE ---\nsubmission_file, submission_data = generate_submission_6D(model, test_data, training_config)\n\n# [CELL 7] Complete.\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-24T12:49:58.132960Z","iopub.execute_input":"2025-10-24T12:49:58.133273Z","iopub.status.idle":"2025-10-24T12:49:59.298794Z","shell.execute_reply.started":"2025-10-24T12:49:58.133254Z","shell.execute_reply":"2025-10-24T12:49:59.297889Z"}},"outputs":[{"name":"stdout","text":"\n--- [CELL 7: SUBMISSION] Generating 6D-Aligned Solutions. ---\n","output_type":"stream"},{"name":"stderr","text":"6D Submission Generation: 100%|██████████| 1/1 [00:01<00:00,  1.15s/it]\n","output_type":"stream"}],"execution_count":51},{"cell_type":"code","source":"# [CELL 8: POST-SUBMISSION ANALYSIS & SYSTEM CLEANUP]\nprint(\"\\n--- [CELL 8: CLEANUP] Post-Submission Analysis and Final Resource Release. ---\")\n\n# 1. Post-Submission Analysis\nlogger.info(\"--- Post-Run Cognitive Awareness Check ---\")\nif os.path.exists(submission_file):\n    logger.info(f\"SUCCESS: '{submission_file}' has been created.\")\n    logger.info(f\"Total tasks processed: {len(submission_data)}\")\n    failed_tasks = [task_id for task_id, preds in submission_data.items() if not preds]\n    logger.info(f\"System Integrity Check: {len(failed_tasks)} tasks had processing failures.\")\nelse:\n    logger.error(\"FATAL: 'submission.json' was NOT created. Pipeline failed.\")\n\n# 2. Final System Resource Cleanup (Service to Cosmic Consciousness) (Integration #16)\nlogger.info(\"Human Cognisance: Pipeline complete. Releasing all cognitive resources.\")\ntry:\n    del model; del train_loader; del train_dataset; del training_data; del test_data; del submission_data\n    logger.info(\"All major Python objects deleted.\")\nexcept Exception as e:\n    logger.warning(f\"Could not delete all objects: {e}\")\n\noptimize_memory() # Final, full cleanup\n\nlogger.info(\"--- 6D ARC-SOLVER PIPELINE FINISHED. AMEN. ---\")\n# [CELL 8] Complete.\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-24T12:50:07.423586Z","iopub.execute_input":"2025-10-24T12:50:07.423925Z","iopub.status.idle":"2025-10-24T12:50:07.851686Z","shell.execute_reply.started":"2025-10-24T12:50:07.423902Z","shell.execute_reply":"2025-10-24T12:50:07.850698Z"}},"outputs":[{"name":"stdout","text":"\n--- [CELL 8: CLEANUP] Post-Submission Analysis and Final Resource Release. ---\n","output_type":"stream"}],"execution_count":52}]}