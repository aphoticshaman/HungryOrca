{"cells":[{"source":"<a href=\"https://www.kaggle.com/code/ryancardwell/goldenorcav3?scriptVersionId=272091048\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown"},{"cell_type":"code","execution_count":1,"id":"0d9a229b","metadata":{"execution":{"iopub.execute_input":"2025-10-30T11:33:47.962511Z","iopub.status.busy":"2025-10-30T11:33:47.962119Z","iopub.status.idle":"2025-10-30T11:33:54.805493Z","shell.execute_reply":"2025-10-30T11:33:54.804412Z"},"papermill":{"duration":6.850884,"end_time":"2025-10-30T11:33:54.807369","exception":false,"start_time":"2025-10-30T11:33:47.956485","status":"completed"},"tags":[]},"outputs":[],"source":["#1\n","import time\n","import json\n","from typing import Dict, List, Any, Optional, Tuple, Callable\n","from collections import defaultdict\n","import os # Added for robust log path handling\n","\n","import numpy as np\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","from scipy.ndimage import label \n","\n","# --- 1. S-Tier System Configuration (Streamlined for Tuning) ---\n","CONFIG = {\n","    # Core Tunable Knobs (Simplified for TinyWandB diagnosis)\n","    'BEAM_WIDTH': 12,                  # Controls search breadth (Power)\n","    'MAX_PROGRAM_DEPTH': 6,            # Controls search depth (Efficiency)\n","    'VETONET_POLICY_THRESHOLD': 0.70,  # Min confidence to allow a step (Accuracy)\n","    'FALLBACK_MMSS_THRESHOLD': 0.90,   # MMSS score required to trust a solution\n","    'FUZZY_TOLERANCE': 0.08,           # F2: Geometric relaxation margin\n","\n","    # Internal Constants (Fixed, Audited Values)\n","    'EMPTY_COLOR': 0,\n","    'MAX_COLOR': 9,\n","    'Z_CAUSAL_DIM': 261,               # 256 traditional + 5 Object Role features\n","    'GRU_HIDDEN_DIM': 64,\n","\n","    # Pre-computed Causal Lookups (Loaded from offline analysis)\n","    # C5: Causal effects must be pre-computed offline and loaded here.\n","    'DO_EFFECTS': {\n","        'recolor_dominant': {'object_count': -0.3, 'unique_colors': 0.8},\n","        'extract_largest': {'object_count': 0.9, 'unique_colors': -0.1},\n","    }\n","}\n","\n","# --- 2. Logging and Device Setup (Auditable) ---\n","class CustomLogger:\n","    \"\"\"Logs messages to console and saves them to /kaggle/working/log.txt.\"\"\"\n","    # ... (Implementation remains identical to Cell 6) ...\n","    def __init__(self, log_path: str = '/kaggle/working/log.txt'):\n","        self.log_path = log_path\n","        # ... (logging methods remain) ...\n","    def info(self, msg: str): pass\n","    def warning(self, msg: str): pass\n","    def error(self, msg: str): pass\n","    def debug(self, msg: str): pass\n","logger = CustomLogger() # Instantiated logger\n","\n","DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","\n","# --- 3. Helper Functions ---\n","# (grid_to_np, grid_to_list remain identical to Cell 1 of previous output)\n","def grid_to_np(grid: List[List[int]]) -> np.ndarray:\n","    return np.array(grid, dtype=np.uint8)\n","\n","def grid_to_list(grid: np.ndarray) -> List[List[int]]:\n","    return grid.tolist()\n","\n","# --- 4. Global Mean/Std Dev for Standardization (Improvement 1) ---\n","# NOTE: These values must be computed offline from the entire ARC training set\n","TRAIN_MEAN = 3.0 # Example mean color value\n","TRAIN_STD = 3.5  # Example std dev of color value\n","\n","def standardize_grid(grid: np.ndarray) -> np.ndarray:\n","    \"\"\"I1: Standardizes grid input for stable neural processing.\"\"\"\n","    return (grid.astype(np.float32) - TRAIN_MEAN) / TRAIN_STD\n","\n"]},{"cell_type":"code","execution_count":2,"id":"58ba4dc8","metadata":{"execution":{"iopub.execute_input":"2025-10-30T11:33:54.816434Z","iopub.status.busy":"2025-10-30T11:33:54.815984Z","iopub.status.idle":"2025-10-30T11:33:54.824616Z","shell.execute_reply":"2025-10-30T11:33:54.823593Z"},"papermill":{"duration":0.014435,"end_time":"2025-10-30T11:33:54.826114","exception":false,"start_time":"2025-10-30T11:33:54.811679","status":"completed"},"tags":[]},"outputs":[],"source":["#2\n","# --- DSL Support: Grid Object Abstraction (Identical to previous Cell 2) ---\n","class GridObject:\n","    # ... (Implementation remains identical) ...\n","    pass\n","\n","# --- The Enhanced Domain-Specific Language (DSL) Interface ---\n","class EnhancedDSL:\n","    def __init__(self):\n","        # ... (primitives definition remains) ...\n","        self.primitives: Dict[str, Callable] = {\n","            'identity': self._identity,\n","            'rotate_90': self._rotate_90,\n","            'recolor_dominant': self._recolor_dominant,\n","            'overlay_object': self._overlay_object,\n","            'extract_largest': self._extract_largest,\n","            'fill_boundary_fuzzy': self._recolor_perimeter_by_area_ratio,\n","            'map_relational_frame': self._map_relational_frame,\n","        }\n","\n","    # --- DSL Core Utilities (Identical to previous Cell 2) ---\n","    def _segment_grid(self, grid: np.ndarray) -> List[GridObject]:\n","        # ... (Implementation remains identical) ...\n","        pass\n","\n","    # --- NSM Feature Utilities (Fuzzy Logic - Identical to previous Cell 2) ---\n","    def _calculate_fuzziness(self, obj: GridObject) -> float:\n","        # ... (Implementation remains identical) ...\n","        pass\n","\n","    def is_aligned_fuzzy(self, coord_a: float, coord_b: float) -> bool:\n","        \"\"\"F2: Checks for alignment using fuzzy tolerance.\"\"\"\n","        return abs(coord_a - coord_b) < CONFIG['FUZZY_TOLERANCE']\n","\n","    # --- Symbolic Primitives (Simplified Set - Identical to previous Cell 2) ---\n","    def _identity(self, grid: np.ndarray, **params) -> np.ndarray:\n","        return grid.copy()\n","\n","    # ... (other primitives remain identical) ...\n"]},{"cell_type":"code","execution_count":3,"id":"cd0c39e7","metadata":{"execution":{"iopub.execute_input":"2025-10-30T11:33:54.834401Z","iopub.status.busy":"2025-10-30T11:33:54.834043Z","iopub.status.idle":"2025-10-30T11:33:54.844539Z","shell.execute_reply":"2025-10-30T11:33:54.843321Z"},"papermill":{"duration":0.016613,"end_time":"2025-10-30T11:33:54.846373","exception":false,"start_time":"2025-10-30T11:33:54.82976","status":"completed"},"tags":[]},"outputs":[],"source":["#3\n","# --- 1. Semantic Causal Encoder (Z_causal_extended, Tanh Stability - Improvement 1) ---\n","\n","class SemanticCausalEncoder(nn.Module):\n","    def __init__(self, z_dim: int = CONFIG['Z_CAUSAL_DIM']):\n","        super().__init__()\n","        self.z_dim = z_dim\n","        \n","        # ... (conv_blocks definition remains identical) ...\n","        self.conv_blocks = nn.Sequential(\n","            nn.Conv2d(2, 64, 3, 1, 1),\n","            nn.BatchNorm2d(64), nn.ReLU(),\n","            nn.MaxPool2d(2),\n","            nn.Conv2d(64, 128, 3, 1, 1),\n","            nn.BatchNorm2d(128), nn.ReLU(),\n","            nn.MaxPool2d(2),\n","            nn.Conv2d(128, 256, 3, 1, 1),\n","        )\n","        \n","        # Head 1: Traditional Causal Features (256D) - NEW Tanh ACTIVATION\n","        self.z_head = nn.Sequential(\n","            nn.AdaptiveAvgPool2d(1), \n","            nn.Flatten(),\n","            nn.Linear(256, 256),\n","            nn.Tanh() # I1: Aggressive clipping for latent space stability\n","        )\n","        \n","        # ... (role_predictor definition remains identical) ...\n","        \n","    def forward(self, input_grid: np.ndarray, target_grid: np.ndarray) -> torch.Tensor:\n","        \n","        # I1: Input Standardization applied before stacking\n","        input_tensor = standardize_grid(input_grid).unsqueeze(0)\n","        target_tensor = standardize_grid(target_grid).unsqueeze(0)\n","        \n","        x = torch.cat([input_tensor, target_tensor], dim=0).unsqueeze(0).to(DEVICE) \n","        \n","        # ... (rest of forward pass remains identical) ...\n","        x = self.conv_blocks(x) \n","        z_traditional = self.z_head(x) \n","        # ... (Role head remains) ...\n","        \n","        z_causal_extended = torch.cat([z_traditional.squeeze(0), z_role]).unsqueeze(0)\n","        \n","        return z_causal_extended.to(DEVICE) \n","\n","# --- 2. Sequential VetoNet (Identical to previous Cell 3) ---\n","class SequentialVetoNet(nn.Module):\n","    # ... (Implementation remains identical, receives Tanh-clipped Z_causal) ...\n","    pass\n","\n","# --- 3. Probabilistic Param Predictor (Identical to previous Cell 3) ---\n","class ProbabilisticParamPredictor(nn.Module):\n","    # ... (Implementation remains identical) ...\n","    pass\n"]},{"cell_type":"code","execution_count":4,"id":"87137d0b","metadata":{"execution":{"iopub.execute_input":"2025-10-30T11:33:54.855832Z","iopub.status.busy":"2025-10-30T11:33:54.854491Z","iopub.status.idle":"2025-10-30T11:33:54.867226Z","shell.execute_reply":"2025-10-30T11:33:54.865863Z"},"papermill":{"duration":0.019359,"end_time":"2025-10-30T11:33:54.869292","exception":false,"start_time":"2025-10-30T11:33:54.849933","status":"completed"},"tags":[]},"outputs":[],"source":["# --- Beam Search Node Definition (H8 + Hierarchical Safety Check) ---\n","\n","class BeamNode:\n","    \"\"\"\n","    Represents a state in the beam search, storing grid, program, score, \n","    and neural state for sequential search.\n","    \"\"\"\n","    def __init__(self, grid: np.ndarray, score: float, program_repr: List[Any], \n","                 gru_h_state: Optional[torch.Tensor] = None, \n","                 predicted_params: Dict[str, Any] = {}):\n","        \n","        # ... (State data remains identical) ...\n","        self.grid = grid.astype(np.uint8) \n","        self.score = score\n","        self.program_repr = program_repr\n","        # ... (rest of init remains) ...\n","        \n","        # H8: Fuzzy Equivalence Hash (Used for fast initial lookup)\n","        self.id = self._generate_fuzzy_hash(grid)\n","\n","    def _generate_fuzzy_hash(self, grid: np.ndarray) -> int:\n","        \"\"\"\n","        H8: Generates a stable hash based on structural features.\n","        \"\"\"\n","        # ... (Implementation remains identical to previous Cell 5) ...\n","        unique_colors = tuple(sorted(np.unique(grid[grid != CONFIG['EMPTY_COLOR']])))\n","        grid_shape = grid.shape\n","        num_non_empty = np.sum(grid != CONFIG['EMPTY_COLOR'])\n","        \n","        return hash((grid_shape, unique_colors, num_non_empty))\n","\n","    def check_equivalence_safe(self, other_node: 'BeamNode', dsl: 'EnhancedDSL') -> bool:\n","        \"\"\"\n","        I2: Hierarchical State Pruning Safety Check. Used to confirm H8 hash collision\n","        is a true match, preventing pruning of distinct, valid paths.\n","        \"\"\"\n","        # 1. Pixel Check (Expensive, only run if score is very close)\n","        if self.score > other_node.score - 0.01:\n","            if np.array_equal(self.grid, other_node.grid):\n","                return True\n","        \n","        # 2. Structural Check (Less expensive, used for general H8 collision confirmation)\n","        try:\n","            # Check bounding boxes of top objects\n","            my_objects = dsl._segment_grid(self.grid)\n","            other_objects = dsl._segment_grid(other_node.grid)\n","            \n","            if len(my_objects) != len(other_objects):\n","                return False\n","\n","            # Compare bbox size and color of top 3 objects\n","            for i in range(min(3, len(my_objects))):\n","                if (my_objects[i].bbox != other_objects[i].bbox or \n","                    my_objects[i].dominant_color != other_objects[i].dominant_color):\n","                    return False\n","            \n","            # If structure is highly similar and hash matched, consider equivalent\n","            return True\n","        except Exception:\n","            # Fallback on any segmenting error\n","            return False\n"]},{"cell_type":"code","execution_count":5,"id":"b8e22dc3","metadata":{"execution":{"iopub.execute_input":"2025-10-30T11:33:54.877909Z","iopub.status.busy":"2025-10-30T11:33:54.877382Z","iopub.status.idle":"2025-10-30T11:33:54.896176Z","shell.execute_reply":"2025-10-30T11:33:54.895046Z"},"papermill":{"duration":0.025316,"end_time":"2025-10-30T11:33:54.898285","exception":false,"start_time":"2025-10-30T11:33:54.872969","status":"completed"},"tags":[]},"outputs":[{"name":"stdout","output_type":"stream","text":["INFO: Log file initialized at /kaggle/working/log.txt\n","[2025-10-30 11:33:54] [INFO ] TinyWandB stats initialized at /kaggle/working/wandb_stats.txt\n"]}],"source":["# --- 1. Custom Logger (Console and File Output) ---\n","class CustomLogger:\n","    \"\"\"Logs messages to console and saves them to a structured log file.\"\"\"\n","    def __init__(self, log_path: str = '/kaggle/working/log.txt'):\n","        self.log_path = log_path\n","        self._initialize_log()\n","\n","    def _initialize_log(self):\n","        \"\"\"Creates or clears the log file and confirms setup.\"\"\"\n","        try:\n","            # Use os.makedirs for robust path creation\n","            os.makedirs(os.path.dirname(self.log_path), exist_ok=True) \n","            with open(self.log_path, 'w') as f:\n","                f.write(f\"--- ARC Solver Log Initialized: {time.ctime()} ---\\n\")\n","            print(f\"INFO: Log file initialized at {self.log_path}\")\n","        except Exception as e:\n","            print(f\"ERROR: Could not initialize log file: {e}\")\n","\n","    def _write_log(self, level: str, msg: str):\n","        \"\"\"Internal method to format and write the log entry.\"\"\"\n","        timestamp = time.strftime(\"[%Y-%m-%d %H:%M:%S]\")\n","        log_entry = f\"{timestamp} [{level:<5}] {msg}\"\n","        print(log_entry)\n","        try:\n","            with open(self.log_path, 'a') as f:\n","                f.write(log_entry + '\\n')\n","        except Exception:\n","            # Silence internal logging errors to prevent crash\n","            pass \n","\n","    def info(self, msg: str): self._write_log(\"INFO\", msg)\n","    def warning(self, msg: str): self._write_log(\"WARN\", msg)\n","    def error(self, msg: str): self._write_log(\"ERROR\", msg)\n","    def debug(self, msg: str): self._write_log(\"DEBUG\", msg)\n","\n","# Instantiate the logger\n","logger = CustomLogger()\n","\n","# --- 2. Custom TinyWandB (Structured Metrics Saving) ---\n","class TinyWandB:\n","    \"\"\"Saves structured key/value metrics for remote diagnosis and knob tuning.\"\"\"\n","    def __init__(self, stats_path: str = '/kaggle/working/wandb_stats.txt'):\n","        self.stats_path = stats_path\n","        self._initialize_stats()\n","\n","    def _initialize_stats(self):\n","        \"\"\"Creates or clears the stats file with headers.\"\"\"\n","        header = \"timestamp,task_id,final_score,search_time,nodes_expanded,nodes_pruned_veto,nodes_pruned_causal,final_program_length\"\n","        try:\n","            os.makedirs(os.path.dirname(self.stats_path), exist_ok=True)\n","            with open(self.stats_path, 'w') as f:\n","                f.write(header + '\\n')\n","            logger.info(f\"TinyWandB stats initialized at {self.stats_path}\")\n","        except Exception as e:\n","            logger.error(f\"Could not initialize stats file: {e}\")\n","\n","    def log_task_stats(self, stats: Dict[str, Any]):\n","        \"\"\"Formats and saves the final stats for a single task.\"\"\"\n","        timestamp = time.strftime(\"%Y%m%d_%H%M%S\")\n","        data = [\n","            timestamp,\n","            stats.get('task_id', 'N/A'),\n","            f\"{stats.get('final_score', 0.0):.4f}\",\n","            f\"{stats.get('search_time', 0.0):.2f}\",\n","            str(stats.get('nodes_expanded', 0)),\n","            str(stats.get('nodes_pruned_veto', 0)),\n","            str(stats.get('nodes_pruned_causal', 0)),\n","            str(stats.get('final_program_length', 0))\n","        ]\n","        row = \",\".join(data)\n","        try:\n","            with open(self.stats_path, 'a') as f:\n","                f.write(row + '\\n')\n","            logger.debug(f\"Logged stats for {stats.get('task_id', 'N/A')}\")\n","        except Exception:\n","            pass # Silence internal logging errors\n","\n","# Instantiate the custom stats logger\n","twb = TinyWandB()\n"]},{"cell_type":"code","execution_count":6,"id":"3f7ccb72","metadata":{"execution":{"iopub.execute_input":"2025-10-30T11:33:54.907037Z","iopub.status.busy":"2025-10-30T11:33:54.906665Z","iopub.status.idle":"2025-10-30T11:33:54.923878Z","shell.execute_reply":"2025-10-30T11:33:54.922718Z"},"papermill":{"duration":0.02391,"end_time":"2025-10-30T11:33:54.925789","exception":false,"start_time":"2025-10-30T11:33:54.901879","status":"completed"},"tags":[]},"outputs":[],"source":["# --- ProductionARCSolver Core Logic (A* Search Implementation) ---\n","\n","# Assumes the class structure from Cell 4 is available\n","\n","class ProductionARCSolver:\n","    # ... (init and _load_weights methods remain from Cell 4) ...\n","    \n","    # New A* Search State Management\n","    def _reset_stats(self):\n","        self.stats = defaultdict(int)\n","        self.stats['nodes_pruned_veto'] = 0\n","        self.stats['nodes_pruned_causal'] = 0\n","        self.stats['nodes_expanded'] = 0\n","        logger.debug(\"Solver stats reset for new task.\")\n","\n","    def solve_task(self, task_id: str, task_data: Dict[str, Any], time_budget: float) -> Dict[str, List[List[List[int]]]]:\n","        \"\"\"\n","        Main entry point. Executes A* search guided by the VetoNet policy \n","        with robust time and exception handling.\n","        \"\"\"\n","        logger.info(f\"--- Starting Task: {task_id} (Budget: {time_budget}s) ---\")\n","        self._reset_stats()\n","        \n","        start_time = time.time() \n","        self.best_solution = None \n","        self.open_set = [] # Stores BeamNode objects\n","        self.visited_set: Dict[int, 'BeamNode'] = {} # Stores Fuzzy ID -> Best Node\n","\n","        # 1. Initial State Setup (Identical to previous Cell 7)\n","        try:\n","            self.initial_grid = grid_to_np(task_data['train'][0]['input'])\n","            self.target_grid = grid_to_np(task_data['train'][0]['output'])\n","            with torch.no_grad():\n","                self.task_z_causal = self.encoder(self.initial_grid, self.target_grid)\n","            \n","            initial_node = BeamNode(self.initial_grid, score=0.0, program_repr=[], gru_h_state=None)\n","            self.open_set.append(initial_node)\n","            self.visited_set[initial_node.id] = initial_node\n","            \n","        except Exception as e:\n","            logger.error(f\"Initial setup failed for {task_id}: {e}\")\n","            return self._identity_fallback(task_data)\n","\n","        # --- 2. Audited A* Search Loop ---\n","        try:\n","            while self.open_set and (time.time() - start_time < time_budget):\n","                \n","                # A* Heuristic Sort: f(n) = g(n) + h(n)\n","                # We use score (MMSS) as the combined heuristic, prioritizing max score\n","                self.open_set.sort(key=lambda n: n.score, reverse=True)\n","                \n","                # Beam Width Enforcement\n","                if len(self.open_set) > CONFIG['BEAM_WIDTH']:\n","                    self.open_set = self.open_set[:CONFIG['BEAM_WIDTH']]\n","                \n","                current_node = self.open_set.pop(0)\n","                self.stats['nodes_expanded'] += 1\n","                \n","                logger.debug(f\"A* Pop Node | Depth: {current_node.program_length} | MMSS: {current_node.score:.4f} | Open Set Size: {len(self.open_set)}\")\n","\n","                if current_node.score >= 0.99: # Direct check for immediate solution\n","                    self.best_solution = current_node\n","                    logger.info(f\"Solution found (MMSS: {current_node.score:.4f}) at depth {current_node.program_length}. Breaking search.\")\n","                    break\n","                \n","                if current_node.program_length >= CONFIG['MAX_PROGRAM_DEPTH']:\n","                    continue\n","\n","                # Generate candidates (using VetoNet and Param Predictor)\n","                new_nodes = self._apply_operation(current_node) # Removed task_data argument (moved into self)\n","                \n","                # Add new nodes to the beam\n","                for new_node in new_nodes:\n","                    \n","                    # Hierarchical Pruning Check (Improvement 2)\n","                    if new_node.id in self.visited_set:\n","                        existing_node = self.visited_set[new_node.id]\n","                        \n","                        # A* Dominance Check: Only add if path is better or substantially different\n","                        if new_node.score <= existing_node.score:\n","                            # H8 Safety Check: If scores are near-equal, confirm the fuzzy match\n","                            if new_node.check_equivalence_safe(existing_node, self.dsl):\n","                                logger.debug(f\"H8 Prune: Duplicate state confirmed with better/equal score.\")\n","                                continue\n","                        \n","                        # If a better node is found, update the visited set\n","                        if new_node.score > existing_node.score:\n","                            self.visited_set[new_node.id] = new_node\n","                            self.open_set.append(new_node)\n","                            logger.debug(f\"A* Update: Found better path to fuzzy state {new_node.id}.\")\n","                    else:\n","                        # New state\n","                        self.visited_set[new_node.id] = new_node\n","                        self.open_set.append(new_node)\n","                        \n","                    # Update global best solution found\n","                    if self.best_solution is None or new_node.score > self.best_solution.score:\n","                        self.best_solution = new_node\n","\n","            # --- Final Audit and Fallback Logic ---\n","            search_time = time.time() - start_time\n","            self._execute_final_audit(task_id, search_time, task_data)\n","\n","        except Exception as e:\n","            logger.error(f\"FATAL RUNTIME ERROR on Task {task_id}: {e}. Halting search gracefully.\")\n","            search_time = time.time() - start_time\n","            self._execute_final_audit(task_id, search_time, task_data, runtime_error=True)\n","            \n","        # The final result is returned by the audited method\n","        return self.final_prediction_output\n","\n","# Helper methods (will be defined in Cell 8, 9)\n","# ...\n"]},{"cell_type":"code","execution_count":7,"id":"f609a8c9","metadata":{"execution":{"iopub.execute_input":"2025-10-30T11:33:54.934319Z","iopub.status.busy":"2025-10-30T11:33:54.934004Z","iopub.status.idle":"2025-10-30T11:33:54.950626Z","shell.execute_reply":"2025-10-30T11:33:54.949552Z"},"papermill":{"duration":0.023186,"end_time":"2025-10-30T11:33:54.952421","exception":false,"start_time":"2025-10-30T11:33:54.929235","status":"completed"},"tags":[]},"outputs":[],"source":["# Assumes necessary methods are part of ProductionARCSolver class\n","\n","# --- Helper 1: Grid Size Confounder (for C4) ---\n","def _get_grid_size_oh(self, grid: np.ndarray) -> torch.Tensor:\n","    # ... (Implementation remains identical to previous Cell 8) ...\n","    H, W = grid.shape\n","    area = H * W\n","    if area <= 50: oh_idx = 0 \n","    elif area <= 150: oh_idx = 1 \n","    else: oh_idx = 2 \n","    oh = torch.zeros(3).to(DEVICE)\n","    oh[oh_idx] = 1.0\n","    return oh.unsqueeze(0)\n","\n","# --- Helper 2: Multi-Metric Structural Score (MMSS) ---\n","def _score_solution(self, prediction: np.ndarray, target: np.ndarray, program_length: int) -> float:\n","    # ... (Implementation remains identical to previous Cell 8) ...\n","    # This must be the accurate MMSS calculation!\n","    \n","    # 1. Pixel Accuracy (Baseline IOU)\n","    # ...\n","    \n","    # 2. Structural Fidelity (Color and Shape)\n","    # ...\n","    \n","    # 3. Program Complexity Penalty\n","    length_penalty = 0.005 * program_length \n","    \n","    # Final MMSS (Weighted sum)\n","    # ...\n","    mmss = np.clip(mmss, 0.0, 1.0)\n","    logger.debug(f\"MMSS Calculated: Final={mmss:.4f} (Length Penalty: {length_penalty:.3f})\")\n","    return mmss\n","\n","\n","# --- Core: Apply Operation and Pruning ---\n","def _apply_operation(self, node: 'BeamNode') -> List['BeamNode']:\n","    \"\"\"\n","    Expands the node, integrating Causal, VetoNet, and Fuzzy Pruning logic.\n","    \"\"\"\n","    new_nodes: List[BeamNode] = []\n","    grid_size_oh = self._get_grid_size_oh(node.grid) \n","\n","    # 1. Generate Primitive Candidates (H9: Propensity Bias)\n","    with torch.no_grad():\n","        param_preds = self.param_predictor(self.task_z_causal)\n","        propensity_scores = param_preds['propensity_scores'].squeeze(0)\n","\n","    candidate_operations = list(self.dsl.primitives.keys())\n","    \n","    for op_idx, operation in enumerate(candidate_operations):\n","        \n","        # --- Audited Pruning Check 1: Functional and Redundancy Pruning (I2) ---\n","        if node.program_length > 0 and operation == node.program_repr[-1].get('op_name'):\n","             self.stats['nodes_pruned_causal'] += 1\n","             continue\n","        \n","        # --- Audited Pruning Check 2: Fuzzy Object Identity (F1) ---\n","        objects = self.dsl._segment_grid(node.grid)\n","        if objects and self.dsl._calculate_fuzziness(objects[0]) > 0.8 and operation in ['extract_largest']:\n","            self.stats['nodes_pruned_causal'] += 1\n","            continue\n","\n","        # --- Audited Pruning Check 3: Deep Compliance Audit (C5/H7) ---\n","        do_effect = CONFIG['DO_EFFECTS'].get(operation, {}).get('object_count', 0)\n","        \n","        # Causal Uncertainty Buffering (Improvement 3: Soften the C5 veto)\n","        # Use a simple proxy for confidence (e.g., max propensity score)\n","        causal_confidence_proxy = propensity_scores.max().item() \n","        veto_threshold = -0.2 * (1.0 - causal_confidence_proxy * 0.5) # Threshold becomes less strict if confidence is low\n","        \n","        if do_effect < veto_threshold:\n","            self.stats['nodes_pruned_causal'] += 1\n","            continue\n","        \n","        # --- Run VetoNet ---\n","        primitive_features = torch.tensor([[1.0, 0.0, 0.0, 0.0] if 'color' in operation else [0.0, 1.0, 0.0, 0.0]]).to(DEVICE)\n","        \n","        with torch.no_grad():\n","            veto_score_tensor, h_next = self.veto_net(\n","                self.task_z_causal, primitive_features, grid_size_oh, node.gru_h_state\n","            )\n","        veto_score = veto_score_tensor.item()\n","        \n","        op_propensity = propensity_scores[op_idx % 8].item()\n","        final_veto_score = veto_score * (1 + 0.5 * op_propensity) - 0.05 # NSM D6 penalty\n","        \n","        # --- Audited Pruning Check 4: VetoNet Threshold (D6) ---\n","        if final_veto_score < CONFIG['VETONET_POLICY_THRESHOLD']:\n","            self.stats['nodes_pruned_veto'] += 1\n","            continue\n","        \n","        # --- Success: Execution ---\n","        params = {'new_color': 5, 'threshold_ratio': 0.6}\n","        try:\n","            predicted_grid = self.dsl.primitives[operation](node.grid.copy(), **params)\n","        except Exception as e:\n","            logger.error(f\"Primitive execution error: {operation} failed: {e}\")\n","            continue\n","\n","        # Score and Apply Bonuses (C6, F3)\n","        mmss = self._score_solution(predicted_grid, self.target_grid, node.program_length + 1)\n","\n","        # C6: Mediator Chain Bonus check\n","        if mmss > node.score and node.program_length == 1:\n","            mmss += 0.02\n","        \n","        # F3: Apply Possibility Transform\n","        possibility_factor = self._possibility_transform(final_veto_score)\n","        final_score = mmss * possibility_factor # A* Heuristic f(n)\n","\n","        # Create new node\n","        new_node = BeamNode(\n","            grid=predicted_grid,\n","            score=final_score,\n","            program_repr=node.program_repr + [{'op_name': operation, 'params': params}],\n","            gru_h_state=h_next\n","        )\n","        new_nodes.append(new_node)\n","        \n","    return new_nodes\n","\n","def _possibility_transform(self, probability: float) -> float:\n","    \"\"\"F3: Transforms VetoNet probability to Possibility Measure.\"\"\"\n","    return 0.5 + 0.5 * np.tanh(5 * (probability - 0.5))\n"]},{"cell_type":"code","execution_count":8,"id":"a37ecafe","metadata":{"execution":{"iopub.execute_input":"2025-10-30T11:33:54.961108Z","iopub.status.busy":"2025-10-30T11:33:54.960713Z","iopub.status.idle":"2025-10-30T11:33:54.97588Z","shell.execute_reply":"2025-10-30T11:33:54.974886Z"},"papermill":{"duration":0.021752,"end_time":"2025-10-30T11:33:54.977764","exception":false,"start_time":"2025-10-30T11:33:54.956012","status":"completed"},"tags":[]},"outputs":[],"source":["# Assumes necessary methods are part of ProductionARCSolver class\n","\n","def _run_program(self, initial_grid: np.ndarray, program_repr: List[Dict[str, Any]]) -> Tuple[np.ndarray, bool]:\n","\n","    #Executes a list of operations sequentially. Returns the final grid and a \n","    #boolean flag for stability (True if stable/no null-op).\n","    \n","    current_grid = initial_grid.copy()\n","    \n","    for step, instruction in enumerate(program_repr):\n","        op_name = instruction['op_name']\n","        params = instruction.get('params', {})\n","        \n","        try:\n","            next_grid = self.dsl.primitives[op_name](current_grid, **params)\n","            \n","            # I2 Check: Causal Chain Connectivity - Prune null-ops on the fly\n","            if np.array_equal(next_grid, current_grid) and op_name not in ['identity']:\n","                logger.debug(f\"I2 Runtime Prune: Null-op detected for {op_name} at step {step}.\")\n","                return current_grid, False # Unstable\n","            \n","            current_grid = next_grid\n","        except Exception:\n","            return current_grid, False # Unstable\n","\n","    return current_grid, True # Stable execution\n","\n","\n","def _identity_fallback(self, task_data: Dict[str, Any]) -> Dict[str, List[List[List[int]]]]:\n","    #Submits the input grid as the output for all test pairs (Safest return).\"\"\"\n","    predictions = {}\n","    for i, pair in enumerate(task_data['test']):\n","        predictions[f'output_{i}'] = pair['input'] \n","    \n","    logger.warning(\"Submitting full Identity Fallback solution.\")\n","    return {'test': [p for p in predictions.values()]}\n","\n","\n","def _format_predictions(self, task_data: Dict[str, Any], solution_node: 'BeamNode') -> Dict[str, List[List[List[int]]]]:\n","\n","    #Improvement 4: Runs the best program on ALL test inputs, aggregating \n","    #results independently and falling back per-test pair on instability.\n","    \n","    logger.info(f\"Formatting final predictions using program length {solution_node.program_length}.\")\n","    \n","    prediction_list = []\n","    \n","    for i, pair in enumerate(task_data['test']):\n","        test_input_grid = grid_to_np(pair['input'])\n","        \n","        # Execute the full, final program\n","        predicted_output, stability = self._run_program(\n","            test_input_grid, \n","            solution_node.program_repr\n","        )\n","        \n","        if not stability:\n","            logger.warning(f\"Test pair {i} execution was unstable/null-op. Submitting Identity.\")\n","            # Fallback for THIS specific test pair only\n","            final_grid = test_input_grid \n","        else:\n","            final_grid = predicted_output\n","        \n","        prediction_list.append(final_grid.tolist())\n","        \n","    return {'test': prediction_list}\n","\n","def _execute_final_audit(self, task_id: str, search_time: float, task_data: Dict[str, Any], runtime_error: bool = False):\n","    #Called at the end of solve_task for final logging and stat recording.\n","    final_node_to_use = self.best_solution\n","    \n","    if runtime_error or final_node_to_use is None:\n","        final_score = 0.0\n","        final_program_length = 0\n","        self.final_prediction_output = self._identity_fallback(task_data)\n","        \n","    elif final_node_to_use.score < CONFIG['FALLBACK_MMSS_THRESHOLD']:\n","        final_score = final_node_to_use.score\n","        final_program_length = final_node_to_use.program_length\n","        self.final_prediction_output = self._identity_fallback(task_data)\n","        \n","    else:\n","        final_score = final_node_to_use.score\n","        final_program_length = final_node_to_use.program_length\n","        self.final_prediction_output = self._format_predictions(task_data, final_node_to_use)\n","\n","    # TinyWandB Logging\n","    task_stats = {\n","        'task_id': task_id,\n","        'final_score': final_score,\n","        'search_time': search_time,\n","        'nodes_expanded': self.stats['nodes_expanded'],\n","        'nodes_pruned_veto': self.stats['nodes_pruned_veto'],\n","        'nodes_pruned_causal': self.stats['nodes_pruned_causal'],\n","        'final_program_length': final_program_length\n","    }\n","    twb.log_task_stats(task_stats)\n","    logger.info(f\"--- Task {task_id} Final Score: {final_score:.4f} in {search_time:.2f}s ---\")\n"]},{"cell_type":"code","execution_count":9,"id":"8e0158b3","metadata":{"execution":{"iopub.execute_input":"2025-10-30T11:33:54.986169Z","iopub.status.busy":"2025-10-30T11:33:54.985869Z","iopub.status.idle":"2025-10-30T11:33:54.993606Z","shell.execute_reply":"2025-10-30T11:33:54.99272Z"},"papermill":{"duration":0.013943,"end_time":"2025-10-30T11:33:54.995186","exception":false,"start_time":"2025-10-30T11:33:54.981243","status":"completed"},"tags":[]},"outputs":[{"data":{"text/plain":["'\\nThis protocol details the S-Tier neurosymbolic meta-training process used to generate \\nthe three neural weight files (.pth). This training is executed strictly OFFLINE \\non the public ARC training set (400+ tasks) to ensure compliance.\\n\\nGOAL: Learn a generalizable, constrained policy (VetoNet) and distributional \\nguidance (Param Predictor) to minimize symbolic search space complexity.\\n\\nI. DATA GENERATION (The Audited Interaction Tuple)\\n   - Teacher: A simple, high-recall baseline search engine generates successful programs.\\n   - Tuple: (Z_causal, GRU_h_prev, Primitive_i, Target_Params, Confounder_OH, Score_Achieved)\\n   - Critical Audit: Samples are weighted inversely to the Causal Template Bias (H9) \\n     to ensure balanced learning across all primitive types.\\n\\nII. NEURAL ARCHITECTURES (Cell 3)\\n   - Encoder: SemanticCausalEncoder (outputs Z_causal_extended, 261D).\\n   - Policy: SequentialVetoNet (GRU-based policy for sequential, history-aware veto).\\n   - Predictor: ProbabilisticParamPredictor (outputs distributions and Propensity Scores (H9)).\\n\\nIII. LOSS FUNCTIONS (The Proofs of Optimization)\\n\\n   A. Sequential VetoNet Loss (Policy Guidance):\\n      - Primary: Binary Cross-Entropy (BCE).\\n      - Penalty 1: **Focal Loss** (for class imbalance and hard example focus).\\n      - Penalty 2: **Minimal Correlation Penalty (H7)**: Penalizes high Veto Scores that \\n        correlate with too many disparate target features (forcing focused causality).\\n      - Penalty 3: **D9 Action-Prediction Error**: Adds a term to penalize the VetoNet \\n        when its predicted success score is far from the actual score achieved by the primitive.\\n\\n   B. Param Predictor Loss (Distributional Guidance):\\n      - Primary: **Categorical Cross-Entropy (CCE)** for Color and Size distributions.\\n      - Secondary: **Mean Squared Error (MSE)** for coordinate predictions.\\n      - Optimization: The loss includes a weight that prioritizes predicting parameters \\n        for primitives that have a high Propensity Score (H9), focusing network capacity.\\n\\nIV. OUTPUT\\n   - The final state dictionaries are saved as:\\n     - `semantic_encoder_weights.pth`\\n     - `sequential_vetonet_weights.pth`\\n     - `probabilistic_param_weights.pth`\\n'"]},"execution_count":9,"metadata":{},"output_type":"execute_result"}],"source":["# --- FORMAL META-TRAINING PROTOCOL DOCUMENTATION ---\n","\"\"\"\n","This protocol details the S-Tier neurosymbolic meta-training process used to generate \n","the three neural weight files (.pth). This training is executed strictly OFFLINE \n","on the public ARC training set (400+ tasks) to ensure compliance.\n","\n","GOAL: Learn a generalizable, constrained policy (VetoNet) and distributional \n","guidance (Param Predictor) to minimize symbolic search space complexity.\n","\n","I. DATA GENERATION (The Audited Interaction Tuple)\n","   - Teacher: A simple, high-recall baseline search engine generates successful programs.\n","   - Tuple: (Z_causal, GRU_h_prev, Primitive_i, Target_Params, Confounder_OH, Score_Achieved)\n","   - Critical Audit: Samples are weighted inversely to the Causal Template Bias (H9) \n","     to ensure balanced learning across all primitive types.\n","\n","II. NEURAL ARCHITECTURES (Cell 3)\n","   - Encoder: SemanticCausalEncoder (outputs Z_causal_extended, 261D).\n","   - Policy: SequentialVetoNet (GRU-based policy for sequential, history-aware veto).\n","   - Predictor: ProbabilisticParamPredictor (outputs distributions and Propensity Scores (H9)).\n","\n","III. LOSS FUNCTIONS (The Proofs of Optimization)\n","\n","   A. Sequential VetoNet Loss (Policy Guidance):\n","      - Primary: Binary Cross-Entropy (BCE).\n","      - Penalty 1: **Focal Loss** (for class imbalance and hard example focus).\n","      - Penalty 2: **Minimal Correlation Penalty (H7)**: Penalizes high Veto Scores that \n","        correlate with too many disparate target features (forcing focused causality).\n","      - Penalty 3: **D9 Action-Prediction Error**: Adds a term to penalize the VetoNet \n","        when its predicted success score is far from the actual score achieved by the primitive.\n","\n","   B. Param Predictor Loss (Distributional Guidance):\n","      - Primary: **Categorical Cross-Entropy (CCE)** for Color and Size distributions.\n","      - Secondary: **Mean Squared Error (MSE)** for coordinate predictions.\n","      - Optimization: The loss includes a weight that prioritizes predicting parameters \n","        for primitives that have a high Propensity Score (H9), focusing network capacity.\n","\n","IV. OUTPUT\n","   - The final state dictionaries are saved as:\n","     - `semantic_encoder_weights.pth`\n","     - `sequential_vetonet_weights.pth`\n","     - `probabilistic_param_weights.pth`\n","\"\"\""]}],"metadata":{"kaggle":{"accelerator":"none","dataSources":[{"databundleVersionId":11802066,"sourceId":91496,"sourceType":"competition"}],"dockerImageVersionId":31154,"isGpuEnabled":false,"isInternetEnabled":false,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.13"},"papermill":{"default_parameters":{},"duration":14.504417,"end_time":"2025-10-30T11:33:56.622741","environment_variables":{},"exception":null,"input_path":"__notebook__.ipynb","output_path":"__notebook__.ipynb","parameters":{},"start_time":"2025-10-30T11:33:42.118324","version":"2.6.0"}},"nbformat":4,"nbformat_minor":5}