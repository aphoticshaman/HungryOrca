# HungryOrca Repository Catalogue
**Generated**: 2025-11-03
**Purpose**: Complete inventory of codebase structure for LLM+TTT integration

---

## ğŸ“ Directory Structure

```
/home/user/HungryOrca/
â”œâ”€â”€ .git/                              # Git repository
â””â”€â”€ (flat structure - no subdirectories)
```

**Note**: All files are in root directory. Clean, simple structure.

---

## ğŸ Python Solvers (3 files, 2,995 total lines)

### 1. TurboOrcav9_iter2.py (987 lines, 40 KB) âœ… ACTIVE
**Purpose**: Current production solver - Geometric transforms + pattern learning
**Key Components**:
- `TurboOrcaV9` - Main solver class
- `NeuralSymbolicModel` (NSM) - Extract symbolic rules
- `SymbolicDifferentiableProgramModel` (SDPM) - Rule-to-program synthesis
- `CodeX3Strategies` - 3 parallel search strategies
- `PatternLearner` - Learn from training examples
- Time budget: Configurable (default 2 min, set via `TIME_BUDGET_MINUTES`)

**Architecture**: NSM â†’ SDPM â†’ CODE X3 pipeline
**Performance**: ~41% confidence on test tasks
**Status**: âœ… Running now (32.5 min elapsed, 117.5 min remaining)

### 2. advanced_toroid_physics_arc_insights.py (1,069 lines, 41 KB)
**Purpose**: Advanced physics-inspired solver (toroid magnetosphere model)
**Key Components**:
- `MagnetosphereConfig` - Earth magnetosphere modeling
- Physics-based reasoning from quantum/geology principles
- Target: ARC Prize 2026 (50Ã—50 grids)

**Status**: âš ï¸ Research/experimental code

### 3. fuzzy_meta_controller_production.py (939 lines, 34 KB)
**Purpose**: Fuzzy logic meta-controller for strategy blending
**Key Components**:
- `FuzzySet` - Fuzzy membership functions
- `FuzzyMetaController` - Adaptive strategy orchestration
- Designed to blend multiple solver strategies

**Status**: âš ï¸ Available but not integrated with TurboOrca

---

## ğŸ“Š ARC Competition Data Files

### Training Data
- `arc-agi_training_challenges.json` (3.9 MB) - 1,000 training tasks
- `arc-agi_training_solutions.json` (644 KB) - Solutions for training

### Evaluation Data
- `arc-agi_evaluation_challenges.json` (962 KB) - 120 eval tasks
- `arc-agi_evaluation_solutions.json` (219 KB) - Eval solutions

### Test Data (Competition)
- `arc-agi_test_challenges.json` (992 KB) - 240 test tasks (no solutions)

### Submission Files
- `submission.json` (351 KB) - Current submission (being generated)
- `sample_submission.json` (20 KB) - Example format

---

## ğŸ“ Documentation Files

### Core Documentation
- `README.md` (8.1 KB) - Project overview, consciousness-informed architecture
- `12_STEP_CLAUDE_CODE_GUIDE_FOR_RYAN.md` (31 KB) - Development guide
- `Claude's Lessons.txt` (71 KB) - Learning/insights log

### Research Documentation
- `FUZZY_ARC_CRITICAL_CONNECTION.md` (33 KB) - Fuzzy logic integration notes
- `MASTER_SUMMARY_PHYSICS_TO_AGI.md` (25 KB) - Physics â†’ AGI insights

### Other Files
- `LICENSE` - Repository license
- `PivotOrcav2.ipynb` (176 KB) - Jupyter notebook (legacy?)
- `uberorcav2.1.ipynb` (20 KB) - Jupyter notebook (legacy?)
- `hungryorcav2_cell1_kaggle` (22 KB) - Kaggle cell export

---

## ğŸ¯ Current State Analysis

### âœ… What's Working
1. **TurboOrcav9_iter2.py** is actively running (~41% performance)
2. Clean data pipeline with all ARC-AGI-2 datasets
3. Time budget management implemented
4. Submission generation in progress

### âš ï¸ What's Not Integrated
1. **Fuzzy meta-controller** exists but not used by TurboOrca
2. **Physics-based solver** is standalone research code
3. **No LLM integration** - all current solvers are heuristic-based
4. **No test-time training (TTT)** - needed to reach 53%+ accuracy

### ğŸ¯ Integration Opportunity
The fuzzy meta-controller (`fuzzy_meta_controller_production.py`) could be the **perfect bridge** between:
- Existing geometric solver (TurboOrca)
- New LLM+TTT solver (to be built)
- Physics-based insights (optional)

---

## ğŸš€ Recommended Architecture for Hybrid LLM+TTT

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚           FUZZY META-CONTROLLER (EXISTS!)               â”‚
â”‚  Adaptive strategy selection & ensemble voting          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚                  â”‚                 â”‚
    â”Œâ”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”
    â”‚ TurboOrcaâ”‚      â”‚ LLM+TTT  â”‚     â”‚ Physics  â”‚
    â”‚(Geometric)â”‚      â”‚ (NEW!)   â”‚     â”‚(Optional)â”‚
    â”‚ 41% conf â”‚      â”‚ ?% acc   â”‚     â”‚  N/A     â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚                  â”‚                 â”‚
         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                    â”‚
            â”Œâ”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”
            â”‚  Ensemble Vote  â”‚
            â”‚  Best Solution  â”‚
            â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### File Organization Plan

**New files to create**:
```
/home/user/HungryOrca/
â”œâ”€â”€ llm_solver.py              # LLM+TTT solver class
â”œâ”€â”€ llm_utils.py               # Task formatting, augmentation
â”œâ”€â”€ hybrid_solver.py           # Integrates all solvers
â”œâ”€â”€ requirements_llm.txt       # New dependencies
â””â”€â”€ HYBRID_ARCHITECTURE.md     # Design document
```

**Modified files**:
```
TurboOrcav9_iter2.py          # Add hybrid mode flag
fuzzy_meta_controller_production.py  # Connect to solvers
```

---

## ğŸ“¦ Dependencies Analysis

### Current Dependencies (TurboOrca)
```python
numpy
json (stdlib)
time (stdlib)
os (stdlib)
sys (stdlib)
typing (stdlib)
datetime (stdlib)
collections (stdlib)
```

**Status**: âœ… Minimal, stdlib-based, fast

### New Dependencies Needed (LLM+TTT)
```python
transformers       # Hugging Face models
peft              # LoRA fine-tuning
bitsandbytes      # 4-bit quantization
accelerate        # GPU optimization
torch             # PyTorch backend
datasets          # Data handling
```

**Size Impact**: ~5-10 GB for model weights + libraries

---

## ğŸ¯ Next Steps (10-15 min chunks)

### âœ… COMPLETED: Repository Catalogue (10 min)
- Mapped all files
- Identified integration points
- Planned architecture

### ğŸ”„ NEXT: Create Hybrid Architecture Document (10 min)
- Detailed design doc
- Time budget allocation
- Component interfaces

### ğŸ”œ AFTER THAT: Install Dependencies (10 min)
- Add requirements_llm.txt
- Test minimal transformers import
- Verify GPU availability

---

## ğŸ’¡ Key Insights

1. **Clean slate**: No existing LLM code = no legacy baggage
2. **Meta-controller exists**: Don't reinvent the wheel, use fuzzy controller
3. **Good patterns**: TurboOrca's time budget management is solid
4. **Flat structure**: Easy to navigate, add new modules
5. **Production ready**: Already generating submissions, just needs boost

---

**END OF CATALOGUE**
