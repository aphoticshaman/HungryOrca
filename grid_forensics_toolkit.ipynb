{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ARC Grid Forensics Toolkit - Production Solver\n",
    "\n",
    "## Overview\n",
    "This notebook implements a production-grade ARC (Abstraction and Reasoning Corpus) solver using a modular, forensics-inspired architecture.\n",
    "\n",
    "## Architecture Components\n",
    "1. **arc_utils.py** - Core data structures, I/O, and visualization\n",
    "2. **grid_forensics.py** - Object detection and grid analysis (BFS flood-fill)\n",
    "3. **hypothesis_engine.py** - Rule framework and pattern learning\n",
    "4. **arc_solver_orchestrator.py** - Main execution controller\n",
    "\n",
    "## Execution Flow\n",
    "```\n",
    "Load Data â†’ Analyze Grids â†’ Learn Rules â†’ Apply Transformations â†’ Generate Submission\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Cell 1: Dependencies and Environment Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install optional dependencies (if needed)\n",
    "# !pip install numpy tqdm -q\n",
    "\n",
    "import logging\n",
    "import json\n",
    "import os\n",
    "import time\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from typing import List, Dict, Any, Tuple, Set, Optional\n",
    "from dataclasses import dataclass, field\n",
    "from collections import deque\n",
    "from abc import ABC, abstractmethod\n",
    "\n",
    "# Attempt to import tqdm for progress visualization\n",
    "try:\n",
    "    from tqdm import tqdm\n",
    "except ImportError:\n",
    "    def tqdm(iterable, *args, **kwargs):\n",
    "        return iterable\n",
    "    print(\"âš ï¸ tqdm not found. Using simple iteration.\")\n",
    "\n",
    "# Configure global logging\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,  # Change to DEBUG for detailed tracing\n",
    "    format='[%(asctime)s] {%(levelname)s} [%(name)s]: %(message)s',\n",
    "    datefmt='%H:%M:%S'\n",
    ")\n",
    "\n",
    "logger = logging.getLogger(__name__)\n",
    "logger.info(\"âœ… Environment initialized successfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Cell 2: Module 1 - arc_utils.py\n",
    "**Purpose**: Core data structures, JSON loading, and grid visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "ARC Utility and Data Structure Module (arc_utils.py) - Production Version\n",
    "\n",
    "This module handles core ARC competition functionality:\n",
    "1. Data structures for tasks and examples (using dataclasses).\n",
    "2. Robust JSON file loading and validation.\n",
    "3. Grid visualization utility (for quick debugging).\n",
    "\n",
    "This is the I/O layer of the solver.\n",
    "\"\"\"\n",
    "\n",
    "logger = logging.getLogger('arc_utils')\n",
    "\n",
    "# --- Core Data Structures (The Schema) ---\n",
    "\n",
    "@dataclass(frozen=True)\n",
    "class ArcExample:\n",
    "    \"\"\"Represents a single input/output example within an ARC task.\"\"\"\n",
    "    input: List[List[int]]\n",
    "    output: List[List[int]]\n",
    "\n",
    "@dataclass(frozen=True)\n",
    "class ArcTask:\n",
    "    \"\"\"\n",
    "    Represents a full ARC task, comprising training examples and test examples.\n",
    "    This structure ensures all tasks conform to the expected competition format.\n",
    "    \"\"\"\n",
    "    train: List[ArcExample]\n",
    "    test: List[ArcExample]\n",
    "    task_id: str = field(default=\"\")  # Unique ID for this task (e.g., \"007d3886\")\n",
    "    \n",
    "    def __post_init__(self):\n",
    "        \"\"\"Perform basic validation on load.\"\"\"\n",
    "        if not self.train:\n",
    "            logger.warning(f\"Task {self.task_id}: No training examples found.\")\n",
    "        if not self.test:\n",
    "            logger.warning(f\"Task {self.task_id}: No test examples found.\")\n",
    "\n",
    "# --- File Loading and Parsing ---\n",
    "\n",
    "def get_arc_data_path(base_path: str = \".\") -> Path:\n",
    "    \"\"\"\n",
    "    Attempts to locate the root ARC data directory, adapting to common\n",
    "    competition environments (like Kaggle or local development).\n",
    "    \n",
    "    Args:\n",
    "        base_path: The directory to start searching from.\n",
    "        \n",
    "    Returns:\n",
    "        The Path object pointing to the data directory.\n",
    "        \n",
    "    Raises:\n",
    "        FileNotFoundError: If the data directory cannot be located.\n",
    "    \"\"\"\n",
    "    # Kaggle-specific paths\n",
    "    kaggle_paths = [\n",
    "        Path(\"/kaggle/input/arc-prize-2024\"),\n",
    "        Path(\"/kaggle/input/arc-agi-2024\"),\n",
    "        Path(\"/kaggle/input/abstraction-and-reasoning-challenge\"),\n",
    "    ]\n",
    "    \n",
    "    # Check Kaggle paths first\n",
    "    for path in kaggle_paths:\n",
    "        if path.exists():\n",
    "            logger.info(f\"ðŸ“ ARC data path located at: {path.resolve()}\")\n",
    "            return path\n",
    "    \n",
    "    # Local development paths\n",
    "    arc_dir = Path(base_path) / \"arc-prize-2024\"\n",
    "    if not arc_dir.exists():\n",
    "        arc_dir = Path(base_path) / \"arc-agi-2024\"\n",
    "        if not arc_dir.exists():\n",
    "            arc_dir = Path(base_path)\n",
    "            if not (arc_dir / \"arc-agi_training_challenges.json\").exists():\n",
    "                logger.error(f\"Could not find ARC data directory starting from {base_path}.\")\n",
    "                raise FileNotFoundError(\"ARC data directory not found. Check environment setup.\")\n",
    "    \n",
    "    logger.info(f\"ðŸ“ ARC data path located at: {arc_dir.resolve()}\")\n",
    "    return arc_dir\n",
    "\n",
    "def load_arc_tasks(filepath: Path) -> Dict[str, ArcTask]:\n",
    "    \"\"\"\n",
    "    Loads ARC tasks from a JSON file and structures them using ArcTask objects.\n",
    "    \n",
    "    Args:\n",
    "        filepath: Path object pointing to the JSON file (e.g., train_challenges.json).\n",
    "        \n",
    "    Returns:\n",
    "        A dictionary mapping task IDs (str) to ArcTask instances.\n",
    "        \n",
    "    Raises:\n",
    "        FileNotFoundError: If the specified file does not exist.\n",
    "        json.JSONDecodeError: If the file is not valid JSON.\n",
    "    \"\"\"\n",
    "    if not filepath.exists():\n",
    "        logger.error(f\"load_arc_tasks: File not found at {filepath.resolve()}\")\n",
    "        raise FileNotFoundError(f\"Input file not found: {filepath}\")\n",
    "\n",
    "    logger.info(f\"ðŸ“‚ Loading and parsing {filepath.name}...\")\n",
    "    \n",
    "    try:\n",
    "        with open(filepath, 'r') as f:\n",
    "            raw_data = json.load(f)\n",
    "    except json.JSONDecodeError as e:\n",
    "        logger.error(f\"load_arc_tasks: Failed to decode JSON from {filepath.name}. Error: {e}\")\n",
    "        raise\n",
    "        \n",
    "    parsed_tasks: Dict[str, ArcTask] = {}\n",
    "    \n",
    "    for task_id, task_data in raw_data.items():\n",
    "        try:\n",
    "            train_examples = [\n",
    "                ArcExample(input=ex['input'], output=ex['output'])\n",
    "                for ex in task_data['train']\n",
    "            ]\n",
    "            test_examples = [\n",
    "                ArcExample(input=ex['input'], output=ex['output'])\n",
    "                for ex in task_data['test']\n",
    "            ]\n",
    "            \n",
    "            parsed_tasks[task_id] = ArcTask(\n",
    "                train=train_examples, \n",
    "                test=test_examples, \n",
    "                task_id=task_id\n",
    "            )\n",
    "            \n",
    "        except KeyError as e:\n",
    "            logger.error(f\"Task {task_id} is missing a required key: {e}. Skipping.\")\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Failed to parse task {task_id}. Error: {e}. Skipping.\")\n",
    "\n",
    "    logger.info(f\"âœ… Successfully loaded and parsed {len(parsed_tasks)} tasks.\")\n",
    "    return parsed_tasks\n",
    "\n",
    "# --- Visualization Utility (for debugging) ---\n",
    "\n",
    "# Custom ANSI color map for clear console display\n",
    "# Colors 0-9 correspond to ARC's palette\n",
    "ANSI_COLORS = {\n",
    "    0: \"\\033[47m  \\033[0m\",  # White/Background (using bright white BG)\n",
    "    1: \"\\033[44m  \\033[0m\",  # Blue\n",
    "    2: \"\\033[41m  \\033[0m\",  # Red\n",
    "    3: \"\\033[42m  \\033[0m\",  # Green\n",
    "    4: \"\\033[43m  \\033[0m\",  # Yellow\n",
    "    5: \"\\033[40m  \\033[0m\",  # Black\n",
    "    6: \"\\033[45m  \\033[0m\",  # Magenta\n",
    "    7: \"\\033[46m  \\033[0m\",  # Cyan\n",
    "    8: \"\\033[100m  \\033[0m\", # Gray (Bright Black BG)\n",
    "    9: \"\\033[105m  \\033[0m\", # Orange/Purple (Bright Magenta BG)\n",
    "}\n",
    "\n",
    "def display_grid(grid: List[List[int]], title: str = \"Grid View\") -> None:\n",
    "    \"\"\"\n",
    "    Prints a grid to the console with color-coded ANSI characters.\n",
    "    This provides an immediate, visual debugging tool.\n",
    "    \n",
    "    Args:\n",
    "        grid: The 2D list grid to display.\n",
    "        title: The title to display above the grid.\n",
    "    \"\"\"\n",
    "    if not grid or not grid[0]:\n",
    "        print(f\"\\n--- {title} (EMPTY) ---\")\n",
    "        return\n",
    "        \n",
    "    print(f\"\\n--- {title} ({len(grid)}x{len(grid[0])}) ---\")\n",
    "    \n",
    "    output = []\n",
    "    for row in grid:\n",
    "        line = \"\".join(ANSI_COLORS.get(cell, f\"[{cell}]\") for cell in row)\n",
    "        output.append(line)\n",
    "    \n",
    "    print(\"\\n\".join(output))\n",
    "    print(\"-\" * (len(title) + 12))\n",
    "\n",
    "logger.info(\"âœ… arc_utils module loaded\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Cell 3: Module 2 - grid_forensics.py\n",
    "**Purpose**: Object detection using BFS flood-fill and property extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Grid Forensics Toolkit (grid_forensics.py) - Production Version\n",
    "\n",
    "This module provides the core \"disassembly\" tools for ARC grids.\n",
    "It is designed to be a stable, reliable, and performant library for\n",
    "turning raw pixel grids (the \"binary\") into structured, object-oriented\n",
    "reports (the \"assembly\").\n",
    "\n",
    "This module is the \"IDA Pro\" or \"Volatility\" for your solver. It provides\n",
    "the static analysis that all higher-level \"vulnerability\" (hypothesis)\n",
    "research will be built upon.\n",
    "\n",
    "Main Public API:\n",
    "- class GridAnalysis(grid, background_color=0)\n",
    "- func analyze_grid(grid, background_color=0)\n",
    "\"\"\"\n",
    "\n",
    "logger = logging.getLogger('grid_forensics')\n",
    "\n",
    "# --- Core Object Definition ---\n",
    "\n",
    "class ArcObject:\n",
    "    \"\"\"\n",
    "    Represents a single, contiguous object (structure) found in a grid.\n",
    "    This is the primary unit of analysis, analogous to a process,\n",
    "    file handle, or data structure in memory forensics.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, color: int, coords: Set[Tuple[int, int]]):\n",
    "        \"\"\"\n",
    "        Initializes an object with its color and a set of (row, col) coordinates.\n",
    "        \"\"\"\n",
    "        self.color: int = color\n",
    "        self.coords: Set[Tuple[int, int]] = coords\n",
    "        self.size: int = len(coords)\n",
    "        \n",
    "        # Properties are lazy-loaded by get_object_properties\n",
    "        self.bounding_box: Optional[Tuple[int, int, int, int]] = None  # (min_r, min_c, max_r, max_c)\n",
    "        self.height: int = 0\n",
    "        self.width: int = 0\n",
    "        self.shape_hash: str = \"\"  # String \"mask\" of the shape (e.g., \"1101\")\n",
    "        self.grid_array: Optional[np.ndarray] = None  # Minimal numpy array of the object\n",
    "\n",
    "    def __repr__(self) -> str:\n",
    "        \"\"\"Provides a clean, readable string for debugging.\"\"\"\n",
    "        return f\"ArcObject(Color={self.color}, Size={self.size}, BB={self.bounding_box})\"\n",
    "\n",
    "    def to_dict(self) -> Dict[str, Any]:\n",
    "        \"\"\"Serializes the object's properties for JSON logging or reports.\"\"\"\n",
    "        return {\n",
    "            \"color\": self.color,\n",
    "            \"size\": self.size,\n",
    "            \"bounding_box\": self.bounding_box,\n",
    "            \"height\": self.height,\n",
    "            \"width\": self.width,\n",
    "            \"shape_hash\": self.shape_hash,\n",
    "            \"grid_array\": self.grid_array.tolist() if self.grid_array is not None else None\n",
    "        }\n",
    "\n",
    "# --- Core \"Disassembly\" Functions ---\n",
    "\n",
    "def find_objects(grid: np.ndarray, ignore_color: int = 0) -> List[ArcObject]:\n",
    "    \"\"\"\n",
    "    Finds all contiguous objects in a grid using a Breadth-First Search (BFS)\n",
    "    flood-fill algorithm. This is the \"structure-finding\" part of the\n",
    "    disassembler (like finding function prologs in IDA Pro).\n",
    "    \n",
    "    Args:\n",
    "        grid: The 2D numpy array to scan.\n",
    "        ignore_color: The color to treat as \"background\" (usually 0).\n",
    "                      These pixels will not be part of any object.\n",
    "                      \n",
    "    Returns:\n",
    "        A list of ArcObject instances.\n",
    "    \"\"\"\n",
    "    logger.debug(f\"find_objects: Starting scan on grid {grid.shape}. Ignoring color {ignore_color}.\")\n",
    "    height, width = grid.shape\n",
    "    visited = np.zeros_like(grid, dtype=bool)\n",
    "    objects: List[ArcObject] = []\n",
    "    \n",
    "    # Use a deque for an efficient O(1) queue for the BFS\n",
    "    q: deque[Tuple[int, int]] = deque()\n",
    "    \n",
    "    for r in range(height):\n",
    "        for c in range(width):\n",
    "            # Skip if visited or if it's the background/ignored color\n",
    "            if visited[r, c] or grid[r, c] == ignore_color:\n",
    "                visited[r, c] = True\n",
    "                continue\n",
    "\n",
    "            # New object found. Start flood fill.\n",
    "            color = grid[r, c]\n",
    "            coords: Set[Tuple[int, int]] = set()\n",
    "            \n",
    "            q.append((r, c))\n",
    "            visited[r, c] = True\n",
    "            \n",
    "            while q:\n",
    "                curr_r, curr_c = q.popleft()\n",
    "                coords.add((curr_r, curr_c))\n",
    "                \n",
    "                # Check 4-way neighbors\n",
    "                for dr, dc in [(0, 1), (0, -1), (1, 0), (-1, 0)]:\n",
    "                    nr, nc = curr_r + dr, curr_c + dc\n",
    "                    \n",
    "                    # Check boundaries\n",
    "                    if 0 <= nr < height and 0 <= nc < width:\n",
    "                        # Check color and if already visited\n",
    "                        if not visited[nr, nc] and grid[nr, nc] == color:\n",
    "                            visited[nr, nc] = True\n",
    "                            q.append((nr, nc))\n",
    "                            \n",
    "            if coords:\n",
    "                logger.debug(f\"  > Found object: color={color}, size={len(coords)} at ({r},{c})\")\n",
    "                objects.append(ArcObject(color, coords))\n",
    "                \n",
    "    logger.debug(f\"find_objects: Scan complete. Found {len(objects)} objects.\")\n",
    "    return objects\n",
    "\n",
    "def get_object_properties(obj: ArcObject, background_color: int = -1) -> None:\n",
    "    \"\"\"\n",
    "    Analyzes a found ArcObject to extract its core properties.\n",
    "    This is the \"property dumper\" (like `procdump` or IDA's structure view).\n",
    "    \n",
    "    This function modifies the object IN-PLACE.\n",
    "    \n",
    "    Args:\n",
    "        obj: The ArcObject to analyze.\n",
    "        background_color: The color to use as the \"fill\" for the\n",
    "                          minimal `grid_array` (default -1).\n",
    "    \"\"\"\n",
    "    if not obj.coords:\n",
    "        logger.warning(f\"get_object_properties: Called on an empty object.\")\n",
    "        return\n",
    "\n",
    "    # 1. Calculate Bounding Box\n",
    "    min_r = min(r for r, c in obj.coords)\n",
    "    min_c = min(c for r, c in obj.coords)\n",
    "    max_r = max(r for r, c in obj.coords)\n",
    "    max_c = max(c for r, c in obj.coords)\n",
    "    \n",
    "    obj.bounding_box = (min_r, min_c, max_r, max_c)\n",
    "    obj.height = (max_r - min_r) + 1\n",
    "    obj.width = (max_c - min_c) + 1\n",
    "\n",
    "    # 2. Generate minimal grid_array (the object's \"footprint\")\n",
    "    # This is a *highly* useful property for matching, rotation, etc.\n",
    "    obj.grid_array = np.full((obj.height, obj.width), background_color, dtype=int)\n",
    "    shape_mask = np.zeros((obj.height, obj.width), dtype=int)\n",
    "    \n",
    "    for r, c in obj.coords:\n",
    "        norm_r, norm_c = r - min_r, c - min_c\n",
    "        obj.grid_array[norm_r, norm_c] = obj.color\n",
    "        shape_mask[norm_r, norm_c] = 1\n",
    "        \n",
    "    # 3. Generate a \"Shape Hash\"\n",
    "    # This is a string \"mask\" of the shape, normalized to its top-left corner.\n",
    "    # e.g., a 2x2 square is \"1111\". A 2x2 'L' shape is \"1011\".\n",
    "    obj.shape_hash = \"\".join(map(str, shape_mask.flatten()))\n",
    "\n",
    "# --- Main Public API ---\n",
    "\n",
    "def analyze_grid(grid: List[List[int]], background_color: int = 0) -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Main entry point for \"Grid Forensics\".\n",
    "    Takes a raw grid and returns a full \"autopsy report\"\n",
    "    that the solver can use to make intelligent decisions.\n",
    "    \n",
    "    Args:\n",
    "        grid: The raw 2D list grid from the ARC task.\n",
    "        background_color: The color to treat as background (default 0).\n",
    "        \n",
    "    Returns:\n",
    "        A dictionary report containing all analysis.\n",
    "    \"\"\"\n",
    "    if not grid or not isinstance(grid, list) or not grid[0]:\n",
    "        logger.warning(\"analyze_grid: Received an empty or invalid grid.\")\n",
    "        return {\n",
    "            \"height\": 0, \"width\": 0, \"total_pixels\": 0,\n",
    "            \"unique_colors\": [], \"object_count\": 0, \"objects\": [],\n",
    "            \"error\": \"Empty or invalid grid\"\n",
    "        }\n",
    "        \n",
    "    try:\n",
    "        grid_np = np.array(grid, dtype=int)\n",
    "    except Exception as e:\n",
    "        logger.error(f\"analyze_grid: Could not convert grid to numpy array. Error: {e}\")\n",
    "        return {\n",
    "            \"height\": 0, \"width\": 0, \"total_pixels\": 0,\n",
    "            \"unique_colors\": [], \"object_count\": 0, \"objects\": [],\n",
    "            \"error\": f\"Numpy conversion failed: {e}\"\n",
    "        }\n",
    "    \n",
    "    # 1. Find all object structures\n",
    "    objects = find_objects(grid_np, ignore_color=background_color)\n",
    "    \n",
    "    # 2. Get properties for each object\n",
    "    for obj in objects:\n",
    "        get_object_properties(obj)  # Modifies obj in-place\n",
    "        \n",
    "    # 3. Generate the final report\n",
    "    report = {\n",
    "        \"height\": grid_np.shape[0],\n",
    "        \"width\": grid_np.shape[1],\n",
    "        \"total_pixels\": int(grid_np.size),\n",
    "        \"unique_colors\": [int(c) for c in np.unique(grid_np)],\n",
    "        \"object_count\": len(objects),\n",
    "        \"objects\": objects  # The list of ArcObject instances\n",
    "    }\n",
    "    \n",
    "    logger.debug(f\"analyze_grid: Analysis complete. Found {len(objects)} objects.\")\n",
    "    return report\n",
    "\n",
    "class GridAnalysis:\n",
    "    \"\"\"\n",
    "    A high-level convenience wrapper class that holds the raw grid,\n",
    "    the numpy grid, and the full analysis report.\n",
    "    \"\"\"\n",
    "    def __init__(self, grid: List[List[int]], background_color: int = 0):\n",
    "        self.raw_grid = grid\n",
    "        self.background_color = background_color\n",
    "        \n",
    "        try:\n",
    "            self.grid_np = np.array(grid, dtype=int)\n",
    "            self.report = analyze_grid(grid, background_color)\n",
    "        except Exception as e:\n",
    "            logger.error(f\"GridAnalysis __init__: Failed. Error: {e}\")\n",
    "            self.grid_np = np.array([[]], dtype=int)\n",
    "            self.report = {\"error\": str(e), \"objects\": []}\n",
    "\n",
    "        self.objects: List[ArcObject] = self.report.get(\"objects\", [])\n",
    "        self.object_count: int = self.report.get(\"object_count\", 0)\n",
    "        self.height: int = self.report.get(\"height\", 0)\n",
    "        self.width: int = self.report.get(\"width\", 0)\n",
    "\n",
    "    def to_dict(self) -> Dict[str, Any]:\n",
    "        \"\"\"Serializes the full report for logging.\"\"\"\n",
    "        serializable_report = self.report.copy()\n",
    "        serializable_report[\"objects\"] = [o.to_dict() for o in self.objects]\n",
    "        return serializable_report\n",
    "\n",
    "logger.info(\"âœ… grid_forensics module loaded\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Cell 4: Module 3 - hypothesis_engine.py\n",
    "**Purpose**: Rule framework for pattern learning and transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Hypothesis Engine Architecture (hypothesis_engine.py) - Production Version\n",
    "\n",
    "This module defines the abstract framework for creating and applying\n",
    "transformation rules. It acts as the orchestration layer between the\n",
    "GridAnalysis (static analysis) and the actual solution generation.\n",
    "\n",
    "Core Components:\n",
    "- BaseRule: Abstract class defining the required API for any rule.\n",
    "- HypothesisEngine: The main class that loads, trains, and applies rules.\n",
    "\"\"\"\n",
    "\n",
    "logger = logging.getLogger('hypothesis_engine')\n",
    "\n",
    "# --- Rule Interface (The Plugin API) ---\n",
    "\n",
    "class BaseRule(ABC):\n",
    "    \"\"\"\n",
    "    Abstract Base Class for all ARC transformation rules.\n",
    "    Every rule must implement the 'learn' and 'apply' methods.\n",
    "    \"\"\"\n",
    "    \n",
    "    # REQUIRED: A short, unique identifier for the rule\n",
    "    RULE_ID: str = \"BaseRule\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        \"\"\"Initializes the rule with state storage.\"\"\"\n",
    "        self.is_learned: bool = False\n",
    "        self.metadata: Dict[str, Any] = {}\n",
    "        logger.debug(f\"Rule {self.RULE_ID} initialized.\")\n",
    "\n",
    "    @abstractmethod\n",
    "    def learn(self, task: ArcTask) -> bool:\n",
    "        \"\"\"\n",
    "        Analyzes the training examples in an ArcTask to determine if this rule\n",
    "        can explain the transformation (Input -> Output).\n",
    "        \n",
    "        Args:\n",
    "            task: The ArcTask containing training data.\n",
    "            \n",
    "        Returns:\n",
    "            True if the rule successfully learned a pattern, False otherwise.\n",
    "        \"\"\"\n",
    "        pass\n",
    "\n",
    "    @abstractmethod\n",
    "    def apply(self, input_grid: List[List[int]]) -> Optional[List[List[int]]]:\n",
    "        \"\"\"\n",
    "        Applies the learned transformation to a new input grid.\n",
    "        \n",
    "        Args:\n",
    "            input_grid: The raw 2D input grid.\n",
    "            \n",
    "        Returns:\n",
    "            The transformed output grid (List[List[int]]) or None if the\n",
    "            rule cannot be applied or is not learned.\n",
    "        \"\"\"\n",
    "        pass\n",
    "\n",
    "# --- Rule Implementations (Example: The simplest rule) ---\n",
    "\n",
    "class ColorSwapRule(BaseRule):\n",
    "    \"\"\"\n",
    "    A simple rule that checks if the task is a single color swap.\n",
    "    Example: All 1s become 2s.\n",
    "    \"\"\"\n",
    "    RULE_ID = \"ColorSwap_R01\"\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        # Internal state to store the required color mapping\n",
    "        self.mapping: Dict[int, int] = {}\n",
    "        self.background_color: int = 0\n",
    "        \n",
    "    def learn(self, task: ArcTask) -> bool:\n",
    "        \"\"\"\n",
    "        Learns the color swap mapping based on the first example.\n",
    "        \"\"\"\n",
    "        if not task.train:\n",
    "            return False\n",
    "            \n",
    "        example = task.train[0]\n",
    "        \n",
    "        # 1. Analyze input and output colors\n",
    "        input_analysis = GridAnalysis(example.input, self.background_color)\n",
    "        output_analysis = GridAnalysis(example.output, self.background_color)\n",
    "        \n",
    "        input_colors = set(input_analysis.report['unique_colors'])\n",
    "        output_colors = set(output_analysis.report['unique_colors'])\n",
    "        \n",
    "        # Remove background color from consideration\n",
    "        if self.background_color in input_colors:\n",
    "            input_colors.remove(self.background_color)\n",
    "        if self.background_color in output_colors:\n",
    "            output_colors.remove(self.background_color)\n",
    "\n",
    "        # Basic check: The number of unique non-background colors must match\n",
    "        if len(input_colors) != len(output_colors) or not input_colors:\n",
    "            logger.debug(f\"{self.RULE_ID}: Color count mismatch or no objects.\")\n",
    "            return False\n",
    "\n",
    "        # 2. Derive the mapping\n",
    "        # Simplistic mapping: smallest input color maps to smallest output color, etc.\n",
    "        # This is a placeholder for a much more complex mapping\n",
    "        sorted_input = sorted(list(input_colors))\n",
    "        sorted_output = sorted(list(output_colors))\n",
    "        \n",
    "        self.mapping = dict(zip(sorted_input, sorted_output))\n",
    "        \n",
    "        if not self.mapping:\n",
    "             return False\n",
    "        \n",
    "        # 3. Validation: Test the mapping on all training examples\n",
    "        for ex in task.train:\n",
    "            predicted_output = self._perform_swap(ex.input)\n",
    "            if predicted_output != ex.output:\n",
    "                logger.debug(f\"{self.RULE_ID}: Failed validation on a training example.\")\n",
    "                self.mapping = {}  # Reset state\n",
    "                return False\n",
    "\n",
    "        # If all checks pass, we learned the rule\n",
    "        self.is_learned = True\n",
    "        self.metadata['mapping'] = self.mapping\n",
    "        logger.info(f\"{self.RULE_ID}: Successfully learned mapping {self.mapping}.\")\n",
    "        return True\n",
    "\n",
    "    def _perform_swap(self, grid: List[List[int]]) -> List[List[int]]:\n",
    "        \"\"\"Helper to apply the internal mapping to a grid.\"\"\"\n",
    "        output_grid = []\n",
    "        for row in grid:\n",
    "            new_row = [self.mapping.get(cell, cell) for cell in row]\n",
    "            output_grid.append(new_row)\n",
    "        return output_grid\n",
    "\n",
    "    def apply(self, input_grid: List[List[int]]) -> Optional[List[List[int]]]:\n",
    "        \"\"\"Applies the learned color swap.\"\"\"\n",
    "        if not self.is_learned:\n",
    "            logger.warning(f\"{self.RULE_ID}: Cannot apply, rule not learned.\")\n",
    "            return None\n",
    "        \n",
    "        return self._perform_swap(input_grid)\n",
    "\n",
    "# --- The Orchestration Layer (The main component) ---\n",
    "\n",
    "class HypothesisEngine:\n",
    "    \"\"\"\n",
    "    The central intelligence unit that loads available rules, attempts\n",
    "    to train them on a given task, and then uses the best-fit rules\n",
    "    to generate predictions.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, rule_classes: List[type[BaseRule]]):\n",
    "        \"\"\"\n",
    "        Initializes the engine by registering all available rule classes.\n",
    "        \n",
    "        Args:\n",
    "            rule_classes: A list of classes inheriting from BaseRule.\n",
    "        \"\"\"\n",
    "        self.rule_classes = rule_classes\n",
    "        self.learned_rules: List[BaseRule] = []\n",
    "        logger.info(f\"HypothesisEngine initialized with {len(rule_classes)} rule types.\")\n",
    "\n",
    "    def train_task(self, task: ArcTask) -> List[BaseRule]:\n",
    "        \"\"\"\n",
    "        Attempts to train all registered rule types on the given task.\n",
    "        \n",
    "        Args:\n",
    "            task: The ArcTask to train on.\n",
    "            \n",
    "        Returns:\n",
    "            A list of successfully learned (trained) BaseRule instances.\n",
    "        \"\"\"\n",
    "        self.learned_rules = []\n",
    "        logger.info(f\"--- Training on Task: {task.task_id} ---\")\n",
    "\n",
    "        for RuleClass in self.rule_classes:\n",
    "            try:\n",
    "                rule = RuleClass()\n",
    "                logger.debug(f\"Attempting to learn with Rule: {rule.RULE_ID}...\")\n",
    "                \n",
    "                if rule.learn(task):\n",
    "                    self.learned_rules.append(rule)\n",
    "                    logger.info(f\"âœ… Success: Rule {rule.RULE_ID} learned the pattern.\")\n",
    "                else:\n",
    "                    logger.debug(f\"âŒ Failure: Rule {rule.RULE_ID} did not match.\")\n",
    "                    \n",
    "            except Exception as e:\n",
    "                logger.error(f\"FATAL: Rule {RuleClass.RULE_ID} crashed during learn phase: {e}\", exc_info=True)\n",
    "\n",
    "        if not self.learned_rules:\n",
    "            logger.warning(f\"No rules could explain Task {task.task_id}. Proceeding without a strong hypothesis.\")\n",
    "        \n",
    "        return self.learned_rules\n",
    "\n",
    "    def solve_test_case(self, input_grid: List[List[int]]) -> List[List[int]]:\n",
    "        \"\"\"\n",
    "        Uses the list of successfully learned rules to generate a prediction.\n",
    "        \n",
    "        In a production solver, this would try the highest-confidence rule first.\n",
    "        For now, we just return the first successful prediction.\n",
    "        \n",
    "        Args:\n",
    "            input_grid: The test input grid.\n",
    "            \n",
    "        Returns:\n",
    "            The predicted output grid, or the original input grid as a fallback.\n",
    "        \"\"\"\n",
    "        if not self.learned_rules:\n",
    "            logger.warning(\"No hypotheses available to solve. Returning identity transformation.\")\n",
    "            return input_grid  # Identity transformation (the safest guess)\n",
    "\n",
    "        # Attempt to apply rules in the order they were learned (or by priority/score later)\n",
    "        for rule in self.learned_rules:\n",
    "            logger.debug(f\"Attempting to apply learned rule: {rule.RULE_ID}\")\n",
    "            prediction = rule.apply(input_grid)\n",
    "            \n",
    "            if prediction is not None:\n",
    "                logger.info(f\"âœ… Prediction generated by Rule: {rule.RULE_ID}\")\n",
    "                return prediction\n",
    "        \n",
    "        logger.warning(\"All learned rules failed to generate a prediction. Returning identity transformation.\")\n",
    "        return input_grid\n",
    "\n",
    "logger.info(\"âœ… hypothesis_engine module loaded\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Cell 5: Module 4 - arc_solver_orchestrator.py\n",
    "**Purpose**: Main solver orchestrator and submission generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "ARC Solver Orchestrator (arc_solver_orchestrator.py) - Production Version\n",
    "\n",
    "This is the main entry point and execution controller for the ARC Solver.\n",
    "\n",
    "It performs the following high-level tasks:\n",
    "1. Loads all challenge data (train/test).\n",
    "2. Initializes the Hypothesis Engine with all known transformation rules.\n",
    "3. Iterates through each task, training the engine and generating predictions.\n",
    "4. Formats and saves the final submission file.\n",
    "\"\"\"\n",
    "\n",
    "logger = logging.getLogger('arc_solver')\n",
    "\n",
    "# --- Solver Orchestrator Class ---\n",
    "\n",
    "class ArcSolver:\n",
    "    \"\"\"\n",
    "    Manages the entire ARC solving process from data loading to submission generation.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, data_root: str = \".\", submission_path: str = \"submission.json\"):\n",
    "        \"\"\"\n",
    "        Initializes the solver, registers all rules, and sets up paths.\n",
    "        \n",
    "        Args:\n",
    "            data_root: Base directory to search for ARC data.\n",
    "            submission_path: Path to save the final submission JSON file.\n",
    "        \"\"\"\n",
    "        self.data_root = data_root\n",
    "        self.submission_path = Path(submission_path)\n",
    "        self.challenges: Dict[str, ArcTask] = {}\n",
    "        self.predictions: Dict[str, List[List[List[int]]]] = {}\n",
    "        \n",
    "        # Register all available rules here. This list will grow over time.\n",
    "        self.available_rules: List[type[BaseRule]] = [\n",
    "            ColorSwapRule, \n",
    "            # Future rules (e.g., RotationRule, FloodFillRule) would be added here\n",
    "        ]\n",
    "        \n",
    "        # Initialize the core rule engine\n",
    "        self.engine = HypothesisEngine(rule_classes=self.available_rules)\n",
    "        logger.info(f\"ðŸš€ ArcSolver initialized. Rules registered: {[r.RULE_ID for r in self.engine.rule_classes]}\")\n",
    "\n",
    "    def load_data(self, dataset_name: str = \"arc-agi_test_challenges.json\") -> bool:\n",
    "        \"\"\"\n",
    "        Locates the data path and loads the specified challenges file.\n",
    "        \n",
    "        Args:\n",
    "            dataset_name: The name of the JSON file containing the tasks.\n",
    "            \n",
    "        Returns:\n",
    "            True if data was successfully loaded, False otherwise.\n",
    "        \"\"\"\n",
    "        try:\n",
    "            arc_data_dir = get_arc_data_path(self.data_root)\n",
    "            data_filepath = arc_data_dir / dataset_name\n",
    "            self.challenges = load_arc_tasks(data_filepath)\n",
    "            logger.info(f\"âœ… Successfully loaded {len(self.challenges)} tasks.\")\n",
    "            return True\n",
    "        except FileNotFoundError as e:\n",
    "            logger.error(f\"âŒ FATAL: Data loading failed. {e}\")\n",
    "            return False\n",
    "        except Exception as e:\n",
    "            logger.error(f\"âŒ FATAL: An unexpected error occurred during data loading: {e}\", exc_info=True)\n",
    "            return False\n",
    "\n",
    "    def run_solver(self, max_attempts_per_case: int = 1, visualize_first: bool = False):\n",
    "        \"\"\"\n",
    "        Iterates through all loaded tasks, trains the engine, and makes predictions.\n",
    "        \n",
    "        Args:\n",
    "            max_attempts_per_case: Max number of predictions to generate per test example.\n",
    "                                   ARC submission allows up to 3 predictions.\n",
    "            visualize_first: If True, displays the first task's input/output.\n",
    "        \"\"\"\n",
    "        if not self.challenges:\n",
    "            logger.warning(\"âš ï¸ No challenges loaded. Please run load_data() first.\")\n",
    "            return\n",
    "\n",
    "        total_tasks = len(self.challenges)\n",
    "        logger.info(f\"ðŸ”„ Starting solver loop for {total_tasks} tasks...\")\n",
    "        \n",
    "        for task_id, task in tqdm(self.challenges.items(), desc=\"Solving Tasks\"):\n",
    "            predictions_for_task = []\n",
    "            \n",
    "            # Phase 1: Training (Find the pattern)\n",
    "            learned_rules = self.engine.train_task(task)\n",
    "            \n",
    "            # If no rule was learned, skip prediction generation for this task.\n",
    "            if not learned_rules:\n",
    "                self.predictions[task_id] = predictions_for_task\n",
    "                continue\n",
    "\n",
    "            # Phase 2: Prediction (Apply the pattern to test cases)\n",
    "            for i, example in enumerate(task.test):\n",
    "                test_input = example.input\n",
    "                # We can try to use different rules/strategies for multiple attempts\n",
    "                \n",
    "                for attempt in range(max_attempts_per_case):\n",
    "                    # For simplicity, we currently rely on the engine's internal priority\n",
    "                    predicted_output = self.engine.solve_test_case(test_input)\n",
    "                    \n",
    "                    if predicted_output != test_input:  # Check if a real transformation occurred\n",
    "                        predictions_for_task.append(predicted_output)\n",
    "                        logger.debug(f\"Task {task_id}, Test {i}: Generated prediction {attempt + 1}\")\n",
    "                        break  # Move to the next test case\n",
    "                        \n",
    "            # Store the final list of predictions for this task\n",
    "            self.predictions[task_id] = predictions_for_task\n",
    "            \n",
    "            # Optional: Display the first solved test case for visual confirmation\n",
    "            if visualize_first and predictions_for_task and len(task.test) > 0:\n",
    "                display_grid(task.test[0].input, f\"Task {task_id} Test Input\")\n",
    "                display_grid(predictions_for_task[0], f\"Task {task_id} Predicted Output\")\n",
    "                visualize_first = False  # Only show first task\n",
    "\n",
    "    def generate_submission(self) -> str:\n",
    "        \"\"\"\n",
    "        Formats the predictions into the required submission JSON structure.\n",
    "        The required format is: {\"task_id\": [output_grid_1, output_grid_2, ...]}\n",
    "        \n",
    "        Returns:\n",
    "            The path to the generated submission file.\n",
    "        \"\"\"\n",
    "        submission_data = {}\n",
    "        for task_id, output_list in self.predictions.items():\n",
    "            submission_data[task_id] = output_list\n",
    "\n",
    "        try:\n",
    "            with open(self.submission_path, 'w') as f:\n",
    "                json.dump(submission_data, f, indent=2)\n",
    "            logger.info(f\"ðŸ’¾ Submission file successfully written to {self.submission_path.resolve()}\")\n",
    "            return str(self.submission_path.resolve())\n",
    "        except Exception as e:\n",
    "            logger.error(f\"âŒ Failed to write submission file: {e}\")\n",
    "            return f\"Error: {e}\"\n",
    "\n",
    "logger.info(\"âœ… arc_solver_orchestrator module loaded\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Cell 6: Main Execution - Run the Solver\n",
    "**This is the main cell to execute the entire pipeline**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# MAIN EXECUTION CELL\n",
    "# ============================================================================\n",
    "\n",
    "logger.info(\"=\"*70)\n",
    "logger.info(\"          ARC Grid Forensics Toolkit - Solver Execution\")\n",
    "logger.info(\"=\"*70)\n",
    "\n",
    "# Configuration\n",
    "DATA_ROOT = \"/kaggle/input\"  # Kaggle default input path\n",
    "SUBMISSION_FILE = \"submission.json\"\n",
    "DATASET_NAME = \"arc-agi_test_challenges.json\"  # Change as needed\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "try:\n",
    "    # 1. Initialize Solver\n",
    "    solver = ArcSolver(data_root=DATA_ROOT, submission_path=SUBMISSION_FILE)\n",
    "    \n",
    "    # 2. Load Data\n",
    "    if solver.load_data(dataset_name=DATASET_NAME):\n",
    "        \n",
    "        # 3. Run Solver Loop (Train and Predict)\n",
    "        solver.run_solver(max_attempts_per_case=1, visualize_first=True)\n",
    "        \n",
    "        # 4. Generate Submission File\n",
    "        submission_path = solver.generate_submission()\n",
    "        elapsed_time = time.time() - start_time\n",
    "        \n",
    "        logger.info(f\"â±ï¸  Execution finished in {elapsed_time:.2f} seconds.\")\n",
    "        logger.info(f\"ðŸ“„ Final Submission Path: {submission_path}\")\n",
    "        \n",
    "    else:\n",
    "        logger.error(\"âŒ Skipping solver run due to data loading failure.\")\n",
    "\n",
    "except Exception as e:\n",
    "    logger.critical(f\"ðŸ’¥ A CRITICAL ERROR occurred in the main execution loop: {e}\", exc_info=True)\n",
    "    \n",
    "logger.info(\"=\"*70)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Cell 7: Testing and Debugging (Optional)\n",
    "**Use this cell to test individual components or debug specific tasks**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# TESTING AND DEBUGGING CELL\n",
    "# ============================================================================\n",
    "\n",
    "# Example: Test grid_forensics on a simple grid\n",
    "test_grid = [\n",
    "    [1, 1, 0, 0, 0],\n",
    "    [1, 1, 0, 0, 0],\n",
    "    [0, 0, 0, 0, 0],\n",
    "    [0, 0, 0, 2, 0],\n",
    "    [0, 0, 0, 0, 0]\n",
    "]\n",
    "\n",
    "print(\"\\nðŸ” Testing Grid Forensics...\")\n",
    "analysis = GridAnalysis(test_grid, background_color=0)\n",
    "\n",
    "print(f\"Objects found: {analysis.object_count}\")\n",
    "for obj in analysis.objects:\n",
    "    print(f\"  {obj}\")\n",
    "    print(f\"  Shape Hash: {obj.shape_hash}\")\n",
    "\n",
    "display_grid(test_grid, \"Test Grid\")\n",
    "\n",
    "# Example: Test a single task\n",
    "# if solver.challenges:\n",
    "#     task_id = list(solver.challenges.keys())[0]\n",
    "#     task = solver.challenges[task_id]\n",
    "#     print(f\"\\nðŸŽ¯ Testing Task: {task_id}\")\n",
    "#     learned = solver.engine.train_task(task)\n",
    "#     if learned:\n",
    "#         test_input = task.test[0].input\n",
    "#         prediction = solver.engine.solve_test_case(test_input)\n",
    "#         display_grid(test_input, f\"Input {task_id}\")\n",
    "#         display_grid(prediction, f\"Prediction {task_id}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Cell 8: Add More Rules Here\n",
    "**Template for adding new transformation rules**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# CUSTOM RULES - Add your own transformation rules here\n",
    "# ============================================================================\n",
    "\n",
    "# Example: IdentityRule (passthrough)\n",
    "class IdentityRule(BaseRule):\n",
    "    \"\"\"Simple passthrough rule for testing.\"\"\"\n",
    "    RULE_ID = \"Identity_R00\"\n",
    "    \n",
    "    def learn(self, task: ArcTask) -> bool:\n",
    "        \"\"\"Always returns True for testing.\"\"\"\n",
    "        self.is_learned = True\n",
    "        return True\n",
    "    \n",
    "    def apply(self, input_grid: List[List[int]]) -> Optional[List[List[int]]]:\n",
    "        \"\"\"Returns the input unchanged.\"\"\"\n",
    "        return input_grid\n",
    "\n",
    "# To use this rule, add it to solver.available_rules:\n",
    "# solver.available_rules.append(IdentityRule)\n",
    "# solver.engine = HypothesisEngine(rule_classes=solver.available_rules)\n",
    "\n",
    "print(\"âœ… Custom rules cell ready for your implementations\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
