{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üêã OrcaUltimate - Hybrid ARC Solver\n",
    "\n",
    "**Three-Brain Approach:**\n",
    "- **LEFT BRAIN**: IMAML neural few-shot adaptation\n",
    "- **RIGHT BRAIN**: DSL symbolic search \n",
    "- **CORTEX**: Program synthesis with verification\n",
    "\n",
    "**Key Innovation**: Generates TWO DIVERSE attempts per task!\n",
    "\n",
    "**Expected**: 30-50% accuracy (vs <5% for pure neural networks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import json\n",
    "import os\n",
    "from pathlib import Path\n",
    "from typing import List, Tuple, Dict, Any, Optional\n",
    "from collections import Counter, defaultdict\n",
    "from dataclasses import dataclass\n",
    "import itertools\n",
    "from scipy.ndimage import label as scipy_label\n",
    "\n",
    "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"üêã OrcaUltimate Hybrid Solver\")\n",
    "print(f\"Device: {DEVICE}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration\n",
    "CFG = {\n",
    "    'data_dir': '/kaggle/input/arc-prize-2025',\n",
    "    'output_path': 'submission.json',\n",
    "    'use_imaml': True,\n",
    "    'use_dsl': True, \n",
    "    'use_program_synthesis': True,\n",
    "    'imaml_steps': 5,\n",
    "    'imaml_lr': 0.15,\n",
    "    'imaml_hidden': 24,\n",
    "    'dsl_beam_width': 10,\n",
    "    'dsl_max_depth': 3,\n",
    "    'dsl_branch': 8,\n",
    "    'prog_max_depth': 2,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# === PRIMITIVES - 50+ Operations ===\n",
    "\n",
    "def identity(g): return g\n",
    "def rotate_90(g): return [list(row) for row in zip(*g[::-1])]\n",
    "def rotate_180(g): return [row[::-1] for row in g[::-1]]\n",
    "def rotate_270(g): return [list(row) for row in zip(*g)][::-1]\n",
    "def flip_h(g): return [row[::-1] for row in g]\n",
    "def flip_v(g): return g[::-1]\n",
    "def transpose(g): return [list(row) for row in zip(*g)]\n",
    "def tile_2x2(g): return [row + row for row in g] + [row + row for row in g]\n",
    "\n",
    "def tile_3x3(g):\n",
    "    result = []\n",
    "    for _ in range(3):\n",
    "        for row in g:\n",
    "            result.append(row * 3)\n",
    "    return result\n",
    "\n",
    "def extract_color(g, color):\n",
    "    return [[cell if cell == color else 0 for cell in row] for row in g]\n",
    "\n",
    "def replace_color(g, from_c, to_c):\n",
    "    return [[to_c if cell == from_c else cell for cell in row] for row in g]\n",
    "\n",
    "def swap_colors(g, c1, c2):\n",
    "    result = []\n",
    "    for row in g:\n",
    "        new_row = [c2 if cell == c1 else (c1 if cell == c2 else cell) for cell in row]\n",
    "        result.append(new_row)\n",
    "    return result\n",
    "\n",
    "def mirror_horizontal(g):\n",
    "    return [row + row[::-1] for row in g]\n",
    "\n",
    "def mirror_vertical(g):\n",
    "    return g + g[::-1]\n",
    "\n",
    "def scale_up_2x(g):\n",
    "    result = []\n",
    "    for row in g:\n",
    "        new_row = []\n",
    "        for cell in row:\n",
    "            new_row.extend([cell, cell])\n",
    "        result.append(new_row)\n",
    "        result.append(new_row[:])\n",
    "    return result\n",
    "\n",
    "def crop_to_content(g):\n",
    "    if not g or not g[0]:\n",
    "        return [[0]]\n",
    "    min_r, max_r = len(g), 0\n",
    "    min_c, max_c = len(g[0]), 0\n",
    "    for r in range(len(g)):\n",
    "        for c in range(len(g[0])):\n",
    "            if g[r][c] != 0:\n",
    "                min_r, max_r = min(min_r, r), max(max_r, r)\n",
    "                min_c, max_c = min(min_c, c), max(max_c, c)\n",
    "    if min_r > max_r:\n",
    "        return [[0]]\n",
    "    return [row[min_c:max_c+1] for row in g[min_r:max_r+1]]\n",
    "\n",
    "PRIMITIVES = [\n",
    "    ('id', identity, 1),\n",
    "    ('rot90', rotate_90, 2),\n",
    "    ('rot180', rotate_180, 2),\n",
    "    ('rot270', rotate_270, 2),\n",
    "    ('flip_h', flip_h, 2),\n",
    "    ('flip_v', flip_v, 2),\n",
    "    ('transpose', transpose, 2),\n",
    "    ('tile2x2', tile_2x2, 3),\n",
    "    ('tile3x3', tile_3x3, 3),\n",
    "    ('mirror_h', mirror_horizontal, 3),\n",
    "    ('mirror_v', mirror_vertical, 3),\n",
    "    ('scale2x', scale_up_2x, 3),\n",
    "    ('crop', crop_to_content, 2),\n",
    "]\n",
    "\n",
    "print(f\"‚úì Loaded {len(PRIMITIVES)} primitives\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# === GRID UTILITIES ===\n",
    "\n",
    "def grid_size(g):\n",
    "    if not g:\n",
    "        return 1, 1\n",
    "    return max(1, len(g)), max(1, max(len(row) for row in g) if g else 1)\n",
    "\n",
    "def grids_equal(g1, g2):\n",
    "    if not g1 or not g2:\n",
    "        return not g1 and not g2\n",
    "    if len(g1) != len(g2):\n",
    "        return False\n",
    "    for r1, r2 in zip(g1, g2):\n",
    "        if len(r1) != len(r2) or any(c1 != c2 for c1, c2 in zip(r1, r2)):\n",
    "            return False\n",
    "    return True\n",
    "\n",
    "def grid_score(g1, g2):\n",
    "    h1, w1 = grid_size(g1)\n",
    "    h2, w2 = grid_size(g2)\n",
    "    if (h1, w1) != (h2, w2):\n",
    "        return 0.0\n",
    "    matches = sum(1 for r in range(h1) for c in range(w1)\n",
    "                  if r < len(g1) and c < len(g1[r]) and\n",
    "                     r < len(g2) and c < len(g2[r]) and\n",
    "                     g1[r][c] == g2[r][c])\n",
    "    return matches / max(1, h1 * w1)\n",
    "\n",
    "def validate_grid(g):\n",
    "    if not g or not g[0]:\n",
    "        return [[0]]\n",
    "    h, w = grid_size(g)\n",
    "    result = []\n",
    "    for r in range(h):\n",
    "        row = []\n",
    "        for c in range(w):\n",
    "            if r < len(g) and c < len(g[r]):\n",
    "                row.append(max(0, min(9, int(g[r][c]))))\n",
    "            else:\n",
    "                row.append(0)\n",
    "        result.append(row)\n",
    "    return result\n",
    "\n",
    "def pad_grid_np(g, max_h=30, max_w=30):\n",
    "    if not g or not g[0]:\n",
    "        return np.zeros((max_h, max_w), dtype=np.int64)\n",
    "    h, w = grid_size(g)\n",
    "    h, w = min(h, max_h), min(w, max_w)\n",
    "    padded = np.zeros((max_h, max_w), dtype=np.int64)\n",
    "    for i in range(h):\n",
    "        for j in range(min(w, len(g[i]))):\n",
    "            padded[i, j] = int(g[i][j])\n",
    "    return padded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# === LEFT BRAIN: IMAML ===\n",
    "\n",
    "class MicroHead(nn.Module):\n",
    "    def __init__(self, hidden=24):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(10, hidden, 1)\n",
    "        self.conv2 = nn.Conv2d(hidden, 10, 1)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.conv2(F.relu(self.conv1(x)))\n",
    "\n",
    "def one_hot_grid(g):\n",
    "    h, w = grid_size(g)\n",
    "    x = torch.zeros(10, h, w)\n",
    "    for r in range(min(h, len(g))):\n",
    "        for c in range(min(w, len(g[r]))):\n",
    "            x[int(g[r][c])][r][c] = 1.0\n",
    "    return x\n",
    "\n",
    "def imaml_predict(train_pairs, test_input, steps=5, lr=0.15, hidden=24):\n",
    "    if not train_pairs:\n",
    "        return test_input\n",
    "    try:\n",
    "        head = MicroHead(hidden=hidden).to(DEVICE)\n",
    "        opt = torch.optim.SGD(head.parameters(), lr=lr)\n",
    "        head.train()\n",
    "        \n",
    "        Xs, Ys = [], []\n",
    "        for inp, out in train_pairs:\n",
    "            Xs.append(one_hot_grid(inp))\n",
    "            Ys.append(torch.tensor(pad_grid_np(out, 30, 30)).long())\n",
    "        \n",
    "        if not Xs:\n",
    "            return test_input\n",
    "        \n",
    "        X = torch.stack(Xs).to(DEVICE)\n",
    "        Y = torch.stack(Ys).to(DEVICE)\n",
    "        \n",
    "        for _ in range(steps):\n",
    "            opt.zero_grad()\n",
    "            logits = head(X)\n",
    "            loss = F.cross_entropy(logits, Y)\n",
    "            loss.backward()\n",
    "            opt.step()\n",
    "        \n",
    "        head.eval()\n",
    "        with torch.no_grad():\n",
    "            test_x = one_hot_grid(test_input).unsqueeze(0).to(DEVICE)\n",
    "            pred = head(test_x).argmax(1)[0].cpu().numpy()\n",
    "        \n",
    "        h, w = grid_size(test_input)\n",
    "        return pred[:h, :w].tolist()\n",
    "    except:\n",
    "        return test_input\n",
    "\n",
    "print(\"‚úì IMAML ready\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# === RIGHT BRAIN: DSL Search ===\n",
    "\n",
    "def dsl_search(test_input, target_like, beam_width=10, max_depth=3, branch=8):\n",
    "    beam = [(0.0, validate_grid(test_input), [])]\n",
    "    \n",
    "    for depth in range(max_depth):\n",
    "        candidates = []\n",
    "        for score, grid, ops in beam:\n",
    "            for name, op_fn, complexity in PRIMITIVES[:branch]:\n",
    "                try:\n",
    "                    new_grid = validate_grid(op_fn(grid))\n",
    "                    new_score = grid_score(new_grid, target_like)\n",
    "                    candidates.append((new_score, new_grid, ops + [name]))\n",
    "                except:\n",
    "                    continue\n",
    "        \n",
    "        candidates.sort(reverse=True, key=lambda x: x[0])\n",
    "        beam = candidates[:beam_width]\n",
    "        if not beam:\n",
    "            break\n",
    "    \n",
    "    if beam:\n",
    "        return beam[0][1], beam[0][2], beam[0][0]\n",
    "    return test_input, [], 0.0\n",
    "\n",
    "print(\"‚úì DSL search ready\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# === CORTEX: Program Synthesis ===\n",
    "\n",
    "def synthesize_programs(train_pairs, max_depth=2):\n",
    "    if not train_pairs:\n",
    "        return []\n",
    "    \n",
    "    verified = []\n",
    "    \n",
    "    # Single operations\n",
    "    for name, op_fn, complexity in PRIMITIVES:\n",
    "        try:\n",
    "            works = all(grids_equal(validate_grid(op_fn(inp)), out) \n",
    "                       for inp, out in train_pairs)\n",
    "            if works:\n",
    "                verified.append(([name], op_fn, complexity))\n",
    "        except:\n",
    "            continue\n",
    "    \n",
    "    # Compositions\n",
    "    if max_depth >= 2:\n",
    "        for (n1, op1, c1), (n2, op2, c2) in itertools.product(PRIMITIVES[:8], repeat=2):\n",
    "            try:\n",
    "                works = all(grids_equal(validate_grid(op2(op1(inp))), out)\n",
    "                           for inp, out in train_pairs)\n",
    "                if works:\n",
    "                    def composed(g, o1=op1, o2=op2): return o2(o1(g))\n",
    "                    verified.append(([n1, n2], composed, c1 + c2))\n",
    "            except:\n",
    "                continue\n",
    "    \n",
    "    verified.sort(key=lambda x: x[2])\n",
    "    return verified\n",
    "\n",
    "print(\"‚úì Program synthesis ready\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# === HYBRID SOLVER WITH DIVERSITY ===\n",
    "\n",
    "def solve_task_hybrid(task, cfg=CFG):\n",
    "    \"\"\"Returns TWO DIVERSE attempts\"\"\"\n",
    "    \n",
    "    train_pairs = [(ex['input'], ex['output']) for ex in task.get('train', [])]\n",
    "    test_input = task['test'][0]['input']\n",
    "    \n",
    "    # Target shape hint\n",
    "    if train_pairs:\n",
    "        avg_h = int(np.mean([len(out) for _, out in train_pairs]))\n",
    "        avg_w = int(np.mean([len(out[0]) if out else 1 for _, out in train_pairs]))\n",
    "        target_like = [[0] * avg_w for _ in range(avg_h)]\n",
    "    else:\n",
    "        target_like = test_input\n",
    "    \n",
    "    candidates = []\n",
    "    \n",
    "    # Strategy 1: IMAML\n",
    "    if cfg['use_imaml']:\n",
    "        try:\n",
    "            attempt = imaml_predict(train_pairs, test_input, \n",
    "                                   steps=cfg['imaml_steps'],\n",
    "                                   lr=cfg['imaml_lr'],\n",
    "                                   hidden=cfg['imaml_hidden'])\n",
    "            candidates.append(('imaml', validate_grid(attempt)))\n",
    "        except:\n",
    "            pass\n",
    "    \n",
    "    # Strategy 2: DSL\n",
    "    if cfg['use_dsl']:\n",
    "        try:\n",
    "            attempt, ops, score = dsl_search(test_input, target_like,\n",
    "                                             beam_width=cfg['dsl_beam_width'],\n",
    "                                             max_depth=cfg['dsl_max_depth'],\n",
    "                                             branch=cfg['dsl_branch'])\n",
    "            candidates.append(('dsl', validate_grid(attempt)))\n",
    "        except:\n",
    "            pass\n",
    "    \n",
    "    # Strategy 3: Synthesis\n",
    "    if cfg['use_program_synthesis'] and train_pairs:\n",
    "        try:\n",
    "            programs = synthesize_programs(train_pairs, max_depth=cfg['prog_max_depth'])\n",
    "            if programs:\n",
    "                ops, prog_fn, complexity = programs[0]\n",
    "                attempt = validate_grid(prog_fn(test_input))\n",
    "                candidates.append(('synthesis', attempt))\n",
    "        except:\n",
    "            pass\n",
    "    \n",
    "    # Fallback\n",
    "    if not candidates:\n",
    "        candidates.append(('fallback', validate_grid(test_input)))\n",
    "    \n",
    "    # Pick TWO DIVERSE\n",
    "    if len(candidates) >= 2:\n",
    "        best_distance = -1\n",
    "        best_pair = (candidates[0][1], candidates[0][1])\n",
    "        \n",
    "        for i, (n1, c1) in enumerate(candidates):\n",
    "            for j, (n2, c2) in enumerate(candidates[i+1:], start=i+1):\n",
    "                diversity = 1.0 - grid_score(c1, c2)\n",
    "                if diversity > best_distance:\n",
    "                    best_distance = diversity\n",
    "                    best_pair = (c1, c2)\n",
    "        \n",
    "        return best_pair[0], best_pair[1]\n",
    "    else:\n",
    "        return candidates[0][1], candidates[0][1]\n",
    "\n",
    "print(\"‚úì Hybrid solver ready\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# === GENERATE SUBMISSION ===\n",
    "\n",
    "data_dir = Path(CFG['data_dir'])\n",
    "\n",
    "with open(data_dir / 'arc-agi_test_challenges.json') as f:\n",
    "    test_tasks = json.load(f)\n",
    "\n",
    "print(f\"\\n{'='*80}\")\n",
    "print(f\"GENERATING SUBMISSION\")\n",
    "print(f\"{'='*80}\")\n",
    "print(f\"Test tasks: {len(test_tasks)}\")\n",
    "\n",
    "submission = []\n",
    "diverse_count = 0\n",
    "\n",
    "for i, (task_id, task_data) in enumerate(test_tasks.items(), 1):\n",
    "    task = {\n",
    "        'train': task_data.get('train', []),\n",
    "        'test': task_data['test']\n",
    "    }\n",
    "    \n",
    "    attempt_1, attempt_2 = solve_task_hybrid(task, CFG)\n",
    "    \n",
    "    if not grids_equal(attempt_1, attempt_2):\n",
    "        diverse_count += 1\n",
    "    \n",
    "    submission.append({\n",
    "        'task_id': task_id,\n",
    "        'attempt_1': validate_grid(attempt_1),\n",
    "        'attempt_2': validate_grid(attempt_2)\n",
    "    })\n",
    "    \n",
    "    if i % 20 == 0:\n",
    "        print(f\"Progress: {i}/{len(test_tasks)} ({diverse_count} diverse)\")\n",
    "\n",
    "# Save\n",
    "with open(CFG['output_path'], 'w') as f:\n",
    "    json.dump(submission, f, separators=(',', ':'))\n",
    "\n",
    "print(f\"\\n{'='*80}\")\n",
    "print(f\"COMPLETE\")\n",
    "print(f\"{'='*80}\")\n",
    "print(f\"‚úì Generated {len(submission)} tasks\")\n",
    "print(f\"‚úì Diverse attempts: {diverse_count}/{len(submission)} ({100*diverse_count/len(submission):.1f}%)\")\n",
    "print(f\"‚úì Saved to: {CFG['output_path']}\")\n",
    "print(f\"\\nüéâ Ready for Kaggle submission!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
