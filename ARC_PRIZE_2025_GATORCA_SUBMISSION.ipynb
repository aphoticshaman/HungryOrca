{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üêä PROJECT GATORCA - ARC PRIZE 2025 SUBMISSION\n",
    "## One-Click Complete Solution\n",
    "\n",
    "**This notebook does EVERYTHING:**\n",
    "1. Loads the solver code (embedded)\n",
    "2. Loads `arc-agi_test_challenges.json`\n",
    "3. Generates predictions with 2 attempts per test case\n",
    "4. Creates `submission.json` in EXACT format\n",
    "5. Validates the format\n",
    "6. Saves to `/kaggle/working/submission.json`\n",
    "\n",
    "**Just click \"Run All\" and wait!**\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üì¶ STEP 1: Load GatORCA Solver (Embedded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile gatorca_solver.py\n",
    "# GatORCA Solver - Complete code embedded\n",
    "import json\n",
    "import random\n",
    "import time\n",
    "from typing import List, Dict, Any, Tuple\n",
    "from collections import Counter\n",
    "\n",
    "Grid = List[List[int]]\n",
    "\n",
    "# Paste the ENTIRE contents of gatorca_submission_compressed.py here\n",
    "# OR we'll load it from the file\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the actual solver code\n",
    "print(\"üêä Loading GatORCA Solver...\")\n",
    "\n",
    "# Read the compressed solver\n",
    "with open('/kaggle/input/gatorca-solver/gatorca_submission_compressed.py', 'r') as f:\n",
    "    solver_code = f.read()\n",
    "\n",
    "# Execute it\n",
    "exec(solver_code)\n",
    "\n",
    "print(f\"‚úÖ Solver loaded! {len(get_all_operations())} operations ready\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìÅ STEP 2: Load ARC-AGI 2025 Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"üìÅ Loading arc-agi_test_challenges.json...\")\n",
    "\n",
    "# Load test challenges (the ones we need to solve)\n",
    "with open('/kaggle/input/arc-prize-2025/arc-agi_test_challenges.json', 'r') as f:\n",
    "    test_challenges = json.load(f)\n",
    "\n",
    "print(f\"‚úÖ Loaded {len(test_challenges)} test tasks\")\n",
    "print(f\"üìù Task IDs: {list(test_challenges.keys())[:5]}...\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üß† STEP 3: Generate Predictions\n",
    "\n",
    "**Format:** Each task gets 2 attempts per test case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "print(\"üß† Generating predictions for all test tasks...\")\n",
    "print(\"‚è±Ô∏è  This will take a while...\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "START_TIME = time.time()\n",
    "submission = {}\n",
    "ops = get_all_operations()\n",
    "\n",
    "for i, (task_id, task) in enumerate(test_challenges.items(), 1):\n",
    "    if i % 10 == 0:\n",
    "        elapsed = time.time() - START_TIME\n",
    "        remaining = (elapsed / i) * (len(test_challenges) - i)\n",
    "        print(f\"[{i}/{len(test_challenges)}] {elapsed/60:.1f}min elapsed, ~{remaining/60:.1f}min remaining\")\n",
    "    \n",
    "    # Create solver for this task\n",
    "    solver = OptimizedEvolutionarySolver(ops)\n",
    "    \n",
    "    # Solve to get best DNA\n",
    "    result = solver.solve_task(task, max_generations=20, timeout_seconds=30)\n",
    "    best_dna = result['best_dna']\n",
    "    \n",
    "    # Generate predictions for each test case\n",
    "    task_predictions = []\n",
    "    \n",
    "    for test_case in task['test']:\n",
    "        input_grid = test_case['input']\n",
    "        \n",
    "        # Attempt 1: Use the evolved DNA\n",
    "        attempt_1 = input_grid\n",
    "        try:\n",
    "            for gene in best_dna:\n",
    "                if gene in ops:\n",
    "                    attempt_1 = ops[gene](attempt_1)\n",
    "        except:\n",
    "            attempt_1 = input_grid\n",
    "        \n",
    "        # Attempt 2: Try a variation (swap last 2 operations)\n",
    "        attempt_2 = input_grid\n",
    "        try:\n",
    "            varied_dna = best_dna[:]\n",
    "            if len(varied_dna) >= 2:\n",
    "                varied_dna[-1], varied_dna[-2] = varied_dna[-2], varied_dna[-1]\n",
    "            for gene in varied_dna:\n",
    "                if gene in ops:\n",
    "                    attempt_2 = ops[gene](attempt_2)\n",
    "        except:\n",
    "            attempt_2 = input_grid\n",
    "        \n",
    "        # Add to predictions in EXACT format\n",
    "        task_predictions.append({\n",
    "            \"attempt_1\": attempt_1,\n",
    "            \"attempt_2\": attempt_2\n",
    "        })\n",
    "    \n",
    "    # Add to submission\n",
    "    submission[task_id] = task_predictions\n",
    "\n",
    "print(f\"\\n‚úÖ All predictions generated!\")\n",
    "print(f\"‚è±Ô∏è  Total time: {(time.time() - START_TIME)/60:.1f} minutes\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üíæ STEP 4: Save to /kaggle/working/submission.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "\n",
    "# Ensure directory exists\n",
    "os.makedirs('/kaggle/working', exist_ok=True)\n",
    "\n",
    "# Save submission\n",
    "output_path = '/kaggle/working/submission.json'\n",
    "\n",
    "with open(output_path, 'w') as f:\n",
    "    json.dump(submission, f)\n",
    "\n",
    "print(f\"üíæ Submission saved to: {output_path}\")\n",
    "print(f\"üìä File size: {os.path.getsize(output_path) / 1024:.1f} KB\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ‚úÖ STEP 5: Validate Submission Format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"‚úÖ Validating submission format...\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Load and validate\n",
    "with open('/kaggle/working/submission.json', 'r') as f:\n",
    "    loaded_submission = json.load(f)\n",
    "\n",
    "# Check format\n",
    "valid = True\n",
    "errors = []\n",
    "\n",
    "# Check all task IDs present\n",
    "if set(loaded_submission.keys()) != set(test_challenges.keys()):\n",
    "    errors.append(\"‚ùå Task ID mismatch!\")\n",
    "    valid = False\n",
    "else:\n",
    "    print(f\"‚úÖ All {len(test_challenges)} task IDs present\")\n",
    "\n",
    "# Check format for each task\n",
    "for task_id, predictions in loaded_submission.items():\n",
    "    if not isinstance(predictions, list):\n",
    "        errors.append(f\"‚ùå {task_id}: predictions not a list\")\n",
    "        valid = False\n",
    "        continue\n",
    "    \n",
    "    # Check number of test cases matches\n",
    "    expected_tests = len(test_challenges[task_id]['test'])\n",
    "    if len(predictions) != expected_tests:\n",
    "        errors.append(f\"‚ùå {task_id}: {len(predictions)} predictions, expected {expected_tests}\")\n",
    "        valid = False\n",
    "        continue\n",
    "    \n",
    "    # Check each prediction has attempt_1 and attempt_2\n",
    "    for idx, pred in enumerate(predictions):\n",
    "        if 'attempt_1' not in pred or 'attempt_2' not in pred:\n",
    "            errors.append(f\"‚ùå {task_id} test {idx}: missing attempts\")\n",
    "            valid = False\n",
    "\n",
    "if valid:\n",
    "    print(\"‚úÖ Submission format is VALID!\")\n",
    "    print(f\"‚úÖ Ready to submit to ARC Prize 2025!\")\n",
    "else:\n",
    "    print(\"‚ùå Submission has errors:\")\n",
    "    for error in errors[:10]:  # Show first 10 errors\n",
    "        print(f\"   {error}\")\n",
    "\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìä STEP 6: Submission Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"üìä SUBMISSION SUMMARY\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Tasks: {len(loaded_submission)}\")\n",
    "print(f\"Total predictions: {sum(len(p) for p in loaded_submission.values())}\")\n",
    "print(f\"File: /kaggle/working/submission.json\")\n",
    "print(f\"Size: {os.path.getsize('/kaggle/working/submission.json') / 1024:.1f} KB\")\n",
    "print(f\"\\n‚úÖ READY FOR SUBMISSION!\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Show sample\n",
    "sample_task = list(loaded_submission.keys())[0]\n",
    "print(f\"\\nüìù Sample (task {sample_task}):\")\n",
    "print(json.dumps({sample_task: loaded_submission[sample_task][:1]}, indent=2)[:500])\n",
    "print(\"...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## üéâ COMPLETE!\n",
    "\n",
    "**Your submission is ready at:** `/kaggle/working/submission.json`\n",
    "\n",
    "**Next steps:**\n",
    "1. Download the submission file\n",
    "2. Submit to ARC Prize 2025 competition\n",
    "3. Wait for results!\n",
    "\n",
    "**üêä GatORCA - 36-Level Recursive Meta-Cognitive Evolutionary Solver**\n",
    "\n",
    "**Good luck! üéñÔ∏è**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
