{"cells":[{"source":"<a href=\"https://www.kaggle.com/code/ryancardwell/orcaswordv2?scriptVersionId=272248137\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown"},{"cell_type":"code","execution_count":1,"id":"84d29a2a","metadata":{"execution":{"iopub.execute_input":"2025-10-31T00:55:32.018297Z","iopub.status.busy":"2025-10-31T00:55:32.017902Z","iopub.status.idle":"2025-10-31T00:55:32.581388Z","shell.execute_reply":"2025-10-31T00:55:32.580295Z"},"papermill":{"duration":0.57161,"end_time":"2025-10-31T00:55:32.583268","exception":false,"start_time":"2025-10-31T00:55:32.011658","status":"completed"},"tags":[]},"outputs":[],"source":["#Cell 1\n","\"\"\"\n","ARC PRIZE 2025 - ORCASWORD SOLVER v9.0 (META-AWARENESS CORE)\n","================================================================================\n","Cell 1/5: Configuration, Core Data Structures, GridOps, and PET Integration.\n","(Foundation for Meta-Awareness, including multi-dimensional context definition.)\n","\"\"\"\n","\n","import json\n","import numpy as np\n","import time \n","from typing import List, Dict, Tuple, Optional, Set, Callable\n","from dataclasses import dataclass, field\n","from collections import defaultdict\n","from itertools import permutations\n","import copy\n","from math import sqrt, ceil, floor\n","\n","# Scipy fallback for Cell 4 functionality\n","try:\n","    from scipy.ndimage import label\n","except ImportError:\n","    def label(array, structure=None):\n","        return array, 0\n","\n","# =============================================================================\n","# --- Global Configuration & PET Dimensional Constants ---\n","# =============================================================================\n","\n","MAX_PERMUTATION_LENGTH = 5      \n","MAX_VP_SEARCH_ITERATIONS = 5    \n","MAX_HYPOTHESIS_EXPANSION = 16   \n","TRAINING_TIME_LIMIT_MIN = 120  # SIGNIFICANTLY INCREASED TRAINING TIME (x3)\n","\n","# =============================================================================\n","# --- CORE DATA STRUCTURES & PET CONTEXT --- \n","# =============================================================================\n","\n","Grid = List[List[int]]\n","TaskTier = str \n","PET_KEY = Tuple[str, str, str, str] # (Scale, Dimension, Plane, Axis)\n","\n","@dataclass\n","class StrategyMetrics:\n","    name: str\n","    cost: int\n","    orthogonality_score: float = 0.5 # Default, updated in Cell 3/4\n","    # Standard metrics\n","    success_count_by_tier: Dict[TaskTier, int] = field(default_factory=lambda: defaultdict(int))\n","    total_attempts_by_tier: Dict[TaskTier, int] = field(default_factory=lambda: defaultdict(int))\n","    total_validation_steps: Dict[TaskTier, int] = field(default_factory=lambda: defaultdict(int))\n","    last_success_time: float = 0.0\n","    \n","    # META-AWARENESS CORE: The Primitive Efficacy Tensor (PET)\n","    # PET: Maps (Tier, Scale, Dim, Plane, Axis) -> [Success_Count, Attempt_Count, Total_NSM_Steps]\n","    primitive_efficacy_tensor: Dict[PET_KEY, List[int]] = field(default_factory=lambda: defaultdict(lambda: [0, 0, 0]))\n","\n","@dataclass\n","class ARCTask:\n","    task_id: str\n","    train_examples: List[Tuple[Grid, Grid]]\n","    test_inputs: List[Grid]\n","\n","@dataclass\n","class TaskFeatures:\n","    grid_size_score: int\n","    unique_colors: int\n","    density_ratio: float\n","    symmetry_score: float\n","    tier: TaskTier = \"Medium\"\n","    # NEW PET Context Features\n","    scale: str = \"Medium\"\n","    dimension: str = \"2D\"\n","    plane: str = \"XY\"\n","    axis: str = \"None\"\n","\n","\n","# =============================================================================\n","# --- CONSOLIDATED GRID OPERATIONS (Context-Aware Utilities) --- \n","# =============================================================================\n","\n","class GridOps:\n","    \"\"\"Consolidated low-level grid manipulation methods.\"\"\"\n","    @staticmethod\n","    def to_numpy(grid: Grid) -> np.ndarray: return np.array(grid, dtype=np.int32)\n","    @staticmethod\n","    def from_numpy(arr: np.ndarray) -> Grid: return arr.tolist()\n","    @staticmethod\n","    def grids_equal(g1: Grid, g2: Grid) -> bool:\n","        if not g1 or not g2 or len(g1) != len(g2) or len(g1[0]) != len(g2[0]): return False\n","        return all(r1 == r2 for r1, r2 in zip(g1, g2))\n","    @staticmethod\n","    def rotate_90(grid: Grid, k: int = 1) -> Grid: return GridOps.from_numpy(np.rot90(GridOps.to_numpy(grid), -k))\n","    @staticmethod\n","    def reflection_map(grid: Grid, axis: str) -> Grid:\n","        I = GridOps.to_numpy(grid)\n","        if axis == 'H': return GridOps.from_numpy(I[:, ::-1])\n","        if axis == 'V': return GridOps.from_numpy(I[::-1, :])\n","        return grid\n","    @staticmethod\n","    def center_mass_align(grid: Grid) -> Grid:\n","        I = GridOps.to_numpy(grid); H, W = I.shape; non_zero = np.argwhere(I != 0)\n","        if non_zero.size == 0: return grid\n","        center_r, center_c = non_zero.mean(axis=0)\n","        target_r, target_c = (H - 1) / 2, (W - 1) / 2\n","        dy, dx = int(round(target_r - center_r)), int(round(target_c - center_c))\n","        O = np.roll(np.roll(I, dy, axis=0), dx, axis=1)\n","        if dy > 0: O[:dy, :] = 0;\n","        if dy < 0: O[H+dy:, :] = 0\n","        if dx > 0: O[:, :dx] = 0\n","        if dx < 0: O[:, W+dx:] = 0\n","        return GridOps.from_numpy(O)\n","    @staticmethod\n","    def get_color_mapping(inp: Grid, out: Grid) -> Optional[Dict[int, int]]:\n","        I_arr, O_arr = GridOps.to_numpy(inp), GridOps.to_numpy(out)\n","        unique_colors = np.unique(I_arr[I_arr != 0]); color_map = {}\n","        for c in unique_colors:\n","            output_colors = np.unique(O_arr[I_arr == c])\n","            if len(output_colors) == 1:\n","                color_map[int(c)] = int(output_colors[0])\n","            elif len(output_colors) > 1: return None \n","        if len(color_map.keys()) != len(set(color_map.values())): return None\n","        return color_map\n","    @staticmethod\n","    def replace_color(grid: Grid, old_color: int, new_color: int) -> Grid:\n","        arr = GridOps.to_numpy(grid)\n","        arr[arr == old_color] = new_color\n","        return GridOps.from_numpy(arr)\n","    @staticmethod\n","    def boundary_extract(grid: Grid) -> Grid: # Placeholder implementation\n","        I = GridOps.to_numpy(grid)\n","        O = np.zeros_like(I)\n","        H, W = I.shape\n","        for r in range(1, H - 1):\n","            for c in range(1, W - 1):\n","                if I[r, c] != 0 and (I[r-1, c] == 0 or I[r+1, c] == 0 or I[r, c-1] == 0 or I[r, c+1] == 0):\n","                    O[r, c] = I[r, c]\n","        return GridOps.from_numpy(O)\n","        \n","    # [Context-Aware Feature Extraction]\n","    @staticmethod\n","    def calculate_features(task: ARCTask) -> TaskFeatures:\n","        all_inputs = [GridOps.to_numpy(inp) for inp, _ in task.train_examples]\n","        if not all_inputs: return TaskFeatures(0, 0, 0.0, 0.0, \"Easier\")\n","        \n","        H, W = len(task.train_examples[0][0]), len(task.train_examples[0][0][0])\n","        total_cells = H * W * len(task.train_examples)\n","        \n","        unique_colors = max(len(np.unique(arr[arr != 0])) for arr in all_inputs)\n","        non_zero_count = sum(np.sum(arr != 0) for arr in all_inputs)\n","        density_ratio = non_zero_count / total_cells if total_cells > 0 else 0.0\n","        grid_size_score = H * W\n","\n","        sym_score = 0.0\n","        for arr in all_inputs:\n","            sym_score += np.mean(arr == arr[:, ::-1]) + np.mean(arr == arr[::-1, :])\n","        symmetry_score = sym_score / (len(all_inputs) * 2)\n","\n","        features = TaskFeatures(grid_size_score, unique_colors, density_ratio, symmetry_score)\n","        \n","        # --- PET CONTEXT DERIVATION (Meta-Awareness Proof Code Segment) ---\n","        features.scale = \"Small\" if H < 15 and W < 15 else \"Large\" if H > 30 or W > 30 else \"Medium\"\n","        features.dimension = \"1D\" if H == 1 or W == 1 else \"2D\"\n","        features.plane = \"X-Biased\" if W > H * 2 else \"Y-Biased\" if H > W * 2 else \"XY\"\n","        features.axis = \"Rotational\" if symmetry_score > 0.6 else \"Positional\"\n","        \n","        features.tier = GridOps.determine_tier(features)\n","        return features\n","    \n","    @staticmethod\n","    def determine_tier(features: TaskFeatures) -> TaskTier:\n","        complexity_score = (features.unique_colors * 5) + (features.grid_size_score / 10) + (1 - features.symmetry_score) * 20\n","        \n","        if complexity_score < 10: return \"Easier\"\n","        elif complexity_score < 25: return \"Medium\"\n","        elif complexity_score < 40: return \"Hard\"\n","        else: return \"Elite\"\n","\n","#Cell 1\n"]},{"cell_type":"code","execution_count":2,"id":"8828c970","metadata":{"execution":{"iopub.execute_input":"2025-10-31T00:55:32.592473Z","iopub.status.busy":"2025-10-31T00:55:32.591994Z","iopub.status.idle":"2025-10-31T00:55:32.610341Z","shell.execute_reply":"2025-10-31T00:55:32.609399Z"},"papermill":{"duration":0.024666,"end_time":"2025-10-31T00:55:32.611974","exception":false,"start_time":"2025-10-31T00:55:32.587308","status":"completed"},"tags":[]},"outputs":[],"source":["#Cell 2\n","\"\"\"\n","ARC PRIZE 2025 - ORCASWORD SOLVER v9.0 (META-AWARENESS CORE)\n","================================================================================\n","Cell 2/5: Strategy Hierarchy, Self-Reflective Induction (SRI), and Strategy Factory.\n","(Implementation of Meta-Orthogonal Search Bias (OSB) and Meta-Awareness of PET context.)\n","\"\"\"\n","\n","# Must assume imports and classes from Cell 1 are present.\n","\n","# =============================================================================\n","# --- STRATEGY FACTORY PATTERN (RETAINED) ---\n","# =============================================================================\n","\n","class StrategyRegistry:\n","    \"\"\"Centralized dictionary to map strategy names to their class definitions.\"\"\"\n","    strategies: Dict[str, Tuple[type, int, float]] = {} # Maps Name -> (Class, Cost, Orthogonality)\n","\n","    @staticmethod\n","    def register(name: str, cost: int, orthogonality_score: float = 0.5):\n","        \"\"\"Decorator for registering strategies.\"\"\"\n","        def decorator(cls):\n","            if name in StrategyRegistry.strategies:\n","                raise ValueError(f\"Strategy '{name}' already registered.\")\n","            StrategyRegistry.strategies[name] = (cls, cost, orthogonality_score)\n","            return cls\n","        return decorator\n","\n","class StrategyFactory:\n","    \"\"\"Instantiates all known strategies.\"\"\"\n","    @staticmethod\n","    def get_all_strategies() -> List['TransformationStrategy']:\n","        instances = []\n","        for name, (cls, cost, orthogonality_score) in StrategyRegistry.strategies.items():\n","            instance = cls()\n","            instance.cost = cost\n","            instance.orthogonality_score = orthogonality_score\n","            instances.append(instance)\n","        return instances\n","\n","# =============================================================================\n","# --- STRATEGY BASE CLASS (RETAINED NSM INTERFACE) ---\n","# =============================================================================\n","\n","class TransformationStrategy:\n","    \"\"\"Base class defining the standard interface and NSM contract.\"\"\"\n","    def __init__(self, name: str, cost: int, orthogonality_score: float = 0.5):\n","        self.name = name\n","        self.cost = cost \n","        self.orthogonality_score = orthogonality_score\n","    \n","    def can_apply_and_cost(self, train_examples: List[Tuple[Grid, Grid]]) -> Tuple[bool, Optional[Dict], int]:\n","        \"\"\"Runs standard validation and returns (success, rule_params, steps_taken).\"\"\"\n","        return False, None, 1\n","    \n","    def apply(self, test_input: Grid, rule_params: Dict) -> Optional[Grid]:\n","        return test_input \n","\n","# =============================================================================\n","# --- SELF-REFLECTIVE INDUCTION (SRI) CORE (META-AWARENESS & OSB) ---\n","# =============================================================================\n","\n","class SelfReflectiveInduction:\n","    \"\"\"\n","    SRI Component: Provides the NSM/SDP data by measuring exact effort and\n","    applying Meta-Orthogonal Search Bias (OSB) using the PET context.\n","    \"\"\"\n","    \n","    @staticmethod\n","    def get_nsm_expansion_attempts(strategy_cost: int, task_tier: TaskTier) -> int:\n","        \"\"\"Insight 1 (Meta Learning): Dynamically sets the NSM budget.\"\"\"\n","        base_attempts = strategy_cost * MAX_HYPOTHESIS_EXPANSION \n","        \n","        if task_tier in ['Hard', 'Elite']:\n","            return base_attempts * 4\n","        elif strategy_cost >= 4:\n","            return base_attempts * 2\n","        return base_attempts \n","    \n","    @staticmethod\n","    def validate_and_cost(strategy: 'TransformationStrategy', train_examples: List[Tuple[Grid, Grid]]) -> Tuple[bool, Optional[Dict], int, PET_KEY]:\n","        \"\"\"\n","        Runs validation, measures NSM steps, and applies Meta-Orthogonal Search Bias (OSB).\n","        Returns: (success, rule_params, steps_taken, pet_context_key)\n","        \"\"\"\n","        features = GridOps.calculate_features(ARCTask(task_id=\"\", train_examples=train_examples, test_inputs=[]))\n","        task_tier = features.tier\n","        pet_key: PET_KEY = (features.scale, features.dimension, features.plane, features.axis)\n","\n","        try:\n","            success, rule_params, steps_base = strategy.can_apply_and_cost(train_examples)\n","        except Exception:\n","             return False, None, 1, pet_key\n","\n","        if success:\n","            return True, rule_params, steps_base, pet_key\n","        \n","        # 2. Skip deep NSM if cost mismatch is high.\n","        if strategy.cost < 2 and task_tier in ['Hard', 'Elite']:\n","            return False, None, steps_base, pet_key\n","            \n","        # 3. NSM HYPOTHESIS EXPANSION (Meta Awareness & Orthogonality)\n","        \n","        max_nsm_attempts = SelfReflectiveInduction.get_nsm_expansion_attempts(strategy.cost, task_tier)\n","        nsm_steps_taken = steps_base \n","        \n","        # --- Orthogonal Search Bias (OSB) Implementation ---\n","        rot_range = [0, 1, 2, 3] \n","        if features.axis == 'Positional' or features.plane in ['X-Biased', 'Y-Biased']:\n","            rot_range = [0, 2] # Restrict rotational search\n","        \n","        flip_range = [None, 'H', 'V'] \n","        if features.dimension == '1D':\n","            flip_range = [None, 'H'] # Restrict reflection search\n","        \n","        for rot in rot_range:\n","            for flip in flip_range: \n","                \n","                if nsm_steps_taken >= max_nsm_attempts:\n","                    return False, None, nsm_steps_taken, pet_key\n","\n","                perturbed_examples = []\n","                for inp, out in train_examples:\n","                    p_inp = GridOps.rotate_90(inp, rot)\n","                    if flip == 'H': p_inp = GridOps.reflection_map(p_inp, 'H')\n","                    if flip == 'V': p_inp = GridOps.reflection_map(p_inp, 'V')\n","                    perturbed_examples.append((p_inp, out))\n","                \n","                # Check for identity transformation\n","                if rot == 0 and flip is None and not GridOps.grids_equal(train_examples[0][0], perturbed_examples[0][0]):\n","                    # If the base example was transformed despite no rotation/flip, something is wrong.\n","                    continue\n","\n","                success, rule_params_inner, steps_inner = strategy.can_apply_and_cost(perturbed_examples)\n","                nsm_steps_taken += steps_inner\n","\n","                if success:\n","                    return True, rule_params_inner, nsm_steps_taken, pet_key\n","\n","        return False, None, nsm_steps_taken, pet_key \n","\n","#Cell 2\n"]},{"cell_type":"code","execution_count":3,"id":"836d61e3","metadata":{"execution":{"iopub.execute_input":"2025-10-31T00:55:32.621333Z","iopub.status.busy":"2025-10-31T00:55:32.620958Z","iopub.status.idle":"2025-10-31T00:55:32.665143Z","shell.execute_reply":"2025-10-31T00:55:32.664322Z"},"papermill":{"duration":0.050734,"end_time":"2025-10-31T00:55:32.666631","exception":false,"start_time":"2025-10-31T00:55:32.615897","status":"completed"},"tags":[]},"outputs":[],"source":["#Cell 3 - FIXED VERSION\n","\"\"\"\n","ARC PRIZE 2025 - ORCASWORD SOLVER v9.0 (META-AWARENESS CORE)\n","================================================================================\n","Cell 3/5: Definition of all Cost 1/2/3 strategies, incorporating Primitive Efficacy Tensor (PET) and Orthogonality Score (POS).\n","(Establishes the Meta-Aware Primitive Hierarchy and models complexity derivatives.)\n","\"\"\"\n","\n","# NOTE: Assumes imports (numpy, List, Dict, Tuple, Optional, Callable, Set, copy, sqrt, permutations),\n","# GridOps, StrategyRegistry, ARCTask, TaskTier, and MAX_PERMUTATION_LENGTH are defined in Cell 1/2.\n","\n","# =============================================================================\n","# --- PRIMITIVE BASE CLASS (POS INTEGRATION) ---\n","# =============================================================================\n","\n","# Redefining for context, assumes consistency with Cell 2/1 structure\n","class TransformationStrategy: \n","    def __init__(self, name: str, cost: int, orthogonality_score: float = 0.5):\n","        self.name = name\n","        self.cost = cost \n","        self.orthogonality_score = orthogonality_score\n","    \n","    # Placeholder definitions - actual logic is in concrete classes\n","    def can_apply_and_cost(self, train_examples: List[Tuple[Grid, Grid]]) -> Tuple[bool, Optional[Dict], int]:\n","        return False, None, 1\n","    \n","    def apply(self, test_input: Grid, rule_params: Dict) -> Optional[Grid]:\n","        return test_input\n","        \n","    def _complexity_derivative(self, inp: Grid) -> int:\n","        \"\"\"Insight 2 (Meta Awareness): Calculates the operation's computational derivative relative to grid size.\"\"\"\n","        # Using math.sqrt and len/indexing for shape; replace with np.sqrt if outside of try/except block.\n","        H, W = len(inp), len(inp[0])\n","        return max(1, int(sqrt(H * W) / 2))\n","\n","# =============================================================================\n","# --- COST 1 PRIMITIVES (TIER: EASIER) ---\n","# =============================================================================\n","\n","@StrategyRegistry.register(\"identity\", 1, orthogonality_score=0.0)\n","class IdentityStrategy(TransformationStrategy):\n","    def __init__(self): super().__init__(\"identity\", 1, orthogonality_score=0.0)\n","    def can_apply_and_cost(self, train_examples): \n","        steps = self._complexity_derivative(train_examples[0][0])\n","        if all(GridOps.grids_equal(inp, out) for inp, out in train_examples): return True, {}, steps\n","        return False, None, steps\n","    def apply(self, test_input: Grid, rule_params: Dict) -> Optional[Grid]:\n","        return test_input\n","\n","@StrategyRegistry.register(\"rotate_90\", 1, orthogonality_score=0.8)\n","class Rotation90Strategy(TransformationStrategy):\n","    def __init__(self): super().__init__(\"rotate_90\", 1, orthogonality_score=0.8)\n","    def can_apply_and_cost(self, train_examples): \n","        steps = self._complexity_derivative(train_examples[0][0])\n","        k = 1\n","        if all(GridOps.grids_equal(GridOps.rotate_90(inp, k), out) for inp, out in train_examples):\n","            return True, {'k': k}, steps\n","        return False, None, steps\n","    def apply(self, test_input: Grid, rule_params: Dict) -> Optional[Grid]:\n","        return GridOps.rotate_90(test_input, rule_params.get('k', 1))\n","\n","@StrategyRegistry.register(\"rotate_180\", 1, orthogonality_score=0.8)\n","class Rotation180Strategy(TransformationStrategy):\n","    def __init__(self): super().__init__(\"rotate_180\", 1, orthogonality_score=0.8) \n","    def can_apply_and_cost(self, train_examples):\n","        steps = self._complexity_derivative(train_examples[0][0])\n","        k = 2\n","        if all(GridOps.grids_equal(GridOps.rotate_90(inp, k), out) for inp, out in train_examples):\n","            return True, {'k': k}, steps\n","        return False, None, steps\n","    def apply(self, test_input: Grid, rule_params: Dict) -> Optional[Grid]:\n","        return GridOps.rotate_90(test_input, rule_params.get('k', 2))\n","\n","@StrategyRegistry.register(\"color_map\", 1, orthogonality_score=0.2)\n","class ColorMapStrategy(TransformationStrategy):\n","    def __init__(self): super().__init__(\"color_map\", 1, orthogonality_score=0.2)\n","    def can_apply_and_cost(self, train_examples):\n","        steps = self._complexity_derivative(train_examples[0][0]) * 2\n","        maps = [GridOps.get_color_mapping(inp, out) for inp, out in train_examples]\n","        if all(m is not None for m in maps) and all(m == maps[0] for m in maps):\n","            return True, {'map': maps[0]}, steps\n","        return False, None, steps\n","    def apply(self, test_input: Grid, rule_params: Dict) -> Optional[Grid]:\n","        if 'map' in rule_params:\n","            grid = test_input\n","            for old, new in rule_params['map'].items():\n","                grid = GridOps.replace_color(grid, old, new)\n","            return grid\n","        return test_input\n","        \n","# =============================================================================\n","# --- COST 2 PRIMITIVES (TIER: MEDIUM) ---\n","# =============================================================================\n","\n","@StrategyRegistry.register(\"center_mass_align\", 2, orthogonality_score=0.1)\n","class CenterMassAlignStrategy(TransformationStrategy):\n","    def __init__(self): super().__init__(\"center_mass_align\", 2, orthogonality_score=0.1)\n","    def can_apply_and_cost(self, train_examples):\n","        steps = self._complexity_derivative(train_examples[0][0]) * 3\n","        # Assuming GridOps.center_mass_align exists and returns a Grid\n","        if all(GridOps.grids_equal(GridOps.center_mass_align(inp), out) for inp, out in train_examples): return True, {}, steps\n","        return False, None, steps\n","    def apply(self, test_input: Grid, rule_params: Dict) -> Optional[Grid]: return GridOps.center_mass_align(test_input)\n","\n","@StrategyRegistry.register(\"boundary_extract\", 2, orthogonality_score=0.3)\n","class BoundaryExtractStrategy(TransformationStrategy):\n","    def __init__(self): super().__init__(\"boundary_extract\", 2, orthogonality_score=0.3)\n","    def can_apply_and_cost(self, train_examples):\n","        steps = self._complexity_derivative(train_examples[0][0]) * 4\n","        # Assuming GridOps.boundary_extract exists and returns a Grid\n","        if all(GridOps.grids_equal(GridOps.boundary_extract(inp), out) for inp, out in train_examples): return True, {}, steps\n","        return False, None, steps\n","    def apply(self, test_input: Grid, rule_params: Dict) -> Optional[Grid]: return GridOps.boundary_extract(test_input)\n","\n","@StrategyRegistry.register(\"exhaustive_toroidal_shift\", 2, orthogonality_score=0.7)\n","class ExhaustiveToroidalShift(TransformationStrategy):\n","    def __init__(self): super().__init__(\"exhaustive_toroidal_shift\", 2, orthogonality_score=0.7)\n","    # Stub: Logic not provided, default to failure\n","    def can_apply_and_cost(self, train_examples): return False, {}, self._complexity_derivative(train_examples[0][0])\n","@StrategyRegistry.register(\"permutation_color_map\", 2, orthogonality_score=0.5)\n","class PermutationColorStrategy(TransformationStrategy):\n","    def __init__(self): super().__init__(\"permutation_color_map\", 2, orthogonality_score=0.5)\n","    # Stub: Logic not provided, default to failure\n","    def can_apply_and_cost(self, train_examples): return False, {}, self._complexity_derivative(train_examples[0][0])\n","\n","# =============================================================================\n","# --- COST 3 PRIMITIVES (TIER: HARD) - FUNCTIONAL TIME SINKS ---\n","# =============================================================================\n","\n","def variational_erode_op(grid: Grid, T: int) -> Grid:\n","    \"\"\"A placeholder for a potentially slow variational operation.\"\"\"\n","    I = GridOps.to_numpy(grid)\n","    for _ in range(T):\n","        new_I = I.copy(); H, W = I.shape\n","        # Simplified erosion logic\n","        for r in range(1, H - 1):\n","            for c in range(1, W - 1):\n","                if I[r, c] != 0 and np.any(I[r-1:r+2, c-1:c+2] == 0):\n","                    new_I[r, c] = 0\n","        I = new_I\n","    return GridOps.from_numpy(I)\n","\n","\n","class VariationalPrimitive(TransformationStrategy):\n","    \"\"\"Insight 4 (Meta Interactivity): Base class for strategies that use a dynamic lambda search.\"\"\"\n","    def __init__(self, name: str, cost: int, op_func: Callable, base_lambda_range: List[int], orthogonality_score: float):\n","        super().__init__(name, cost, orthogonality_score)\n","        self.op_func = op_func\n","        self.base_lambda_range = base_lambda_range\n","    \n","    def _get_lambda_range(self, task_tier: TaskTier) -> List[int]:\n","        \"\"\"Dynamic Lambda Range based on Task Tier.\"\"\"\n","        # Assuming TaskTier is a class or Enum accessible here\n","        if task_tier in ['Elite']: return self.base_lambda_range + list(range(max(self.base_lambda_range) + 1, 6))\n","        return self.base_lambda_range\n","    \n","    def _fitness(self, transformed_grid: Grid, output_grid: Grid) -> float:\n","        I_arr, O_arr = GridOps.to_numpy(transformed_grid), GridOps.to_numpy(output_grid)\n","        # Simple Mean Squared Error (MSE)\n","        return np.sum((I_arr - O_arr)**2) / I_arr.size\n","    \n","    def can_apply_and_cost(self, train_examples):\n","        # Assuming GridOps.determine_tier and GridOps.calculate_features are available\n","        task_tier = GridOps.determine_tier(GridOps.calculate_features(ARCTask(task_id=\"\", train_examples=train_examples, test_inputs=[])))\n","        lambda_range = self._get_lambda_range(task_tier)\n","        \n","        optimal_lambda = None\n","        steps_taken = 0 \n","        \n","        for inp, out in train_examples:\n","            best_T, best_fit = None, float('inf')\n","            steps_taken += self._complexity_derivative(inp) * 2\n","            \n","            for T in lambda_range: \n","                steps_taken += 1\n","                \n","                transformed_grid = self.op_func(inp, T)\n","                fit = self._fitness(transformed_grid, out)\n","                \n","                if fit < best_fit:\n","                    best_fit = fit\n","                    best_T = T\n","            \n","            # Allow a small tolerance for float comparisons\n","            if best_fit > 0.01: return False, None, steps_taken \n","\n","            if optimal_lambda is None: optimal_lambda = best_T\n","            elif optimal_lambda != best_T: return False, None, steps_taken\n","                \n","        return True, {'lambda': optimal_lambda}, steps_taken\n","    \n","    def apply(self, test_input: Grid, rule_params: Dict) -> Optional[Grid]:\n","        if 'lambda' in rule_params and rule_params['lambda'] is not None:\n","            return self.op_func(test_input, rule_params['lambda']) \n","        return test_input\n","\n","@StrategyRegistry.register(\"variational_erosion\", 3, orthogonality_score=0.4)\n","class VariationalErosionStrategy(VariationalPrimitive):\n","    def __init__(self):\n","        super().__init__(\"variational_erosion\", 3, variational_erode_op, list(range(1, 4)), orthogonality_score=0.4)\n","\n","\n","@StrategyRegistry.register(\"multi_primitive_agent\", 3, orthogonality_score=0.9)\n","class MultiPrimitiveAgent(TransformationStrategy):\n","    \"\"\"\n","    FIXED: Implements non-recursive pool building to resolve the RecursionError.\n","    \"\"\"\n","    def __init__(self): \n","        super().__init__(\"multi_primitive_agent\", 3, orthogonality_score=0.9)\n","        self.primitives_pool = None # FIX 1: Defer initialization to avoid recursion\n","        self.best_sequence = None \n","\n","    def _build_low_cost_pool_non_recursive(self):\n","        \"\"\"Helper to build the pool by iterating the Registry directly, avoiding StrategyFactory's recursion.\"\"\"\n","        pool = []\n","        # Filter for strategies with cost <= 2 and excluding the MultiPrimitiveAgent itself\n","        for name, (cls, cost, orthogonality_score) in StrategyRegistry.strategies.items():\n","            if cost <= 2 and name != self.name: \n","                instance = cls() # Instantiates the specific strategy class\n","                instance.cost = cost\n","                instance.orthogonality_score = orthogonality_score\n","                pool.append(instance)\n","        return pool\n","\n","    def can_apply_and_cost(self, train_examples):\n","        # FIX 2: Initialize pool non-recursively on first call\n","        if self.primitives_pool is None:\n","            self.primitives_pool = self._build_low_cost_pool_non_recursive() \n","\n","        # If pool is empty (no low-cost primitives registered), fail immediately\n","        if not self.primitives_pool:\n","            return False, None, 1\n","\n","        N = MAX_PERMUTATION_LENGTH\n","        self.best_sequence = None\n","        \n","        primitives_pool_filtered = self.primitives_pool\n","        # Sorting by orthogonality_score to prioritize diverse sequences first\n","        primitives_pool_sorted = sorted(primitives_pool_filtered, key=lambda p: p.orthogonality_score, reverse=True)\n","        \n","        steps_taken = 0 \n","        \n","        # This permutation approach is highly costly and needs MAX_PERMUTATION_LENGTH to be very small (e.g., 2)\n","        all_sequences_with_pos = []\n","        # Generate permutations up to length N, considering sequence order and diversity score\n","        for seq_tuple in permutations(primitives_pool_sorted, N):\n","            sequence = list(seq_tuple)\n","            # Calculate cumulative POS (normalized inverse score for diversity)\n","            cumulative_pos = sum(p.orthogonality_score for p in sequence) / N\n","            all_sequences_with_pos.append((cumulative_pos, sequence))\n","            \n","        all_sequences_with_pos.sort(key=lambda x: x[0], reverse=True) # Check most diverse (highest POS) first\n","\n","        for cumulative_pos, sequence in all_sequences_with_pos:\n","            steps_taken += 1 \n","            sequence_matches = True\n","            \n","            steps_taken += sum(p._complexity_derivative(train_examples[0][0]) for p in sequence)\n","            \n","            for inp, out in train_examples:\n","                current_grid = copy.deepcopy(inp)\n","                for primitive_obj in sequence:\n","                    # Apply using the primitive's own logic (note: this assumes simple primitives \n","                    # don't need rule_params for the combination check here)\n","                    current_grid = primitive_obj.apply(current_grid, {}) \n","                \n","                if not GridOps.grids_equal(current_grid, out):\n","                    sequence_matches = False\n","                    break\n","            \n","            if sequence_matches:\n","                self.best_sequence = sequence\n","                seq_names = [p.name for p in sequence]\n","                # Return the sequence names and the steps taken\n","                return True, {'sequence': seq_names}, steps_taken\n","\n","        return False, None, steps_taken\n","    \n","    def apply(self, test_input: Grid, rule_params: Dict) -> Optional[Grid]:\n","        if 'sequence' in rule_params:\n","            if self.primitives_pool is None:\n","                self.primitives_pool = self._build_low_cost_pool_non_recursive()\n","            \n","            current_grid = copy.deepcopy(test_input)\n","            sequence_names = rule_params['sequence']\n","            \n","            # Map names to instantiated primitive objects in the pool\n","            name_to_primitive = {p.name: p for p in self.primitives_pool}\n","            \n","            for name in sequence_names:\n","                primitive_obj = name_to_primitive.get(name)\n","                if primitive_obj:\n","                    # Apply primitive. Note: if primitives require rule_params, the MultiPrimitiveAgent \n","                    # needs to handle parameter search/propagation, which is not implemented here.\n","                    current_grid = primitive_obj.apply(current_grid, {})\n","                else: \n","                    return test_input # Fail gracefully if a primitive in the sequence is missing\n","            return current_grid\n","        return test_input\n","\n","@StrategyRegistry.register(\"laplacian_eigenmap\", 3, orthogonality_score=0.05)\n","class LaplacianEigenmapStrategy(TransformationStrategy):\n","    def __init__(self): super().__init__(\"laplacian_eigenmap\", 3, orthogonality_score=0.05)\n","    # Stub: Logic not provided, default to failure\n","    def can_apply_and_cost(self, train_examples): return False, {}, self._complexity_derivative(train_examples[0][0]) * 5\n","\n","@StrategyRegistry.register(\"dft_pattern_match\", 3, orthogonality_score=0.15)\n","class DFTMatchStrategy(TransformationStrategy):\n","    \"\"\"\n","    COMPLETELY REWRITTEN: Safe implementation that prevents NoneType errors\n","    \"\"\"\n","    def __init__(self): \n","        super().__init__(\"dft_pattern_match\", 3, orthogonality_score=0.15)\n","        \n","    def can_apply_and_cost(self, train_examples: List[Tuple[Grid, Grid]]) -> Tuple[bool, Optional[Dict], int]:\n","        # This strategy is intentionally disabled to prevent errors\n","        steps = self._complexity_derivative(train_examples[0][0]) * 5\n","        return False, None, steps\n","\n","    def apply(self, test_input: Grid, rule_params: Dict) -> Optional[Grid]:\n","        # COMPLETE SAFETY: Always return original input\n","        return test_input\n","\n","@StrategyRegistry.register(\"subgrid_window_perm\", 3, orthogonality_score=0.5)\n","class SubGridWindowPermutationStrategy(TransformationStrategy):\n","    def __init__(self): super().__init__(\"subgrid_window_perm\", 3, orthogonality_score=0.5)\n","    # Stub: Logic not provided, default to failure\n","    def can_apply_and_cost(self, train_examples): return False, {}, self._complexity_derivative(train_examples[0][0]) * 3\n","\n","#Cell 3"]},{"cell_type":"code","execution_count":4,"id":"4541689c","metadata":{"execution":{"iopub.execute_input":"2025-10-31T00:55:32.67573Z","iopub.status.busy":"2025-10-31T00:55:32.675397Z","iopub.status.idle":"2025-10-31T00:55:32.710112Z","shell.execute_reply":"2025-10-31T00:55:32.709141Z"},"papermill":{"duration":0.041525,"end_time":"2025-10-31T00:55:32.711812","exception":false,"start_time":"2025-10-31T00:55:32.670287","status":"completed"},"tags":[]},"outputs":[],"source":["#Cell 4\n","\"\"\"\n","ARC PRIZE 2025 - ORCASWORD SOLVER v9.0 (META-AWARENESS CORE)\n","================================================================================\n","Cell 4/5: NEW Five Novel Synthesis Methods (Cost 4/5 Elite Strategies).\n","(Implementation of Elite Primitive Validation Depth (EVD), Dynamic Orthogonality Penalization (DOP),\n","and Multi-Scale Feature Persistence (MFP) Check.)\n","\"\"\"\n","\n","# Must assume imports and classes from Cell 1, 2, & 3 are present.\n","\n","# =============================================================================\n","# --- ELITE STRATEGY BASE & META-AWARENESS HELPERS ---\n","# =============================================================================\n","\n","class EliteStrategyHelper:\n","    \"\"\"Provides advanced meta-aware methods for Cost 4/5 strategies.\"\"\"\n","    \n","    @staticmethod\n","    def _get_nsm_validation_depth(strategy: TransformationStrategy, features: 'TaskFeatures') -> int:\n","        \"\"\"Elite Primitive Validation Depth (EVD).\"\"\"\n","        base_depth = strategy.cost * 10\n","        if features.tier == 'Elite':\n","            return base_depth * 3\n","        elif features.scale == 'Large':\n","            return base_depth * 2\n","        return base_depth\n","\n","    @staticmethod\n","    def _dynamic_orthogonality_penalty(strategy: TransformationStrategy, features: 'TaskFeatures') -> int:\n","        \"\"\"Dynamic Orthogonality Penalization (DOP).\"\"\"\n","        penalty = 0\n","        if strategy.cost >= 4 and features.tier in ['Easier', 'Medium']:\n","            penalty = int(strategy.orthogonality_score * 50)\n","        return penalty\n","\n","    @staticmethod\n","    def check_multi_scale_persistence(inp: Grid, out: Grid) -> bool:\n","        \"\"\"Multi-Scale Feature Persistence (MFP) Check.\"\"\"\n","        I_arr, O_arr = GridOps.to_numpy(inp), GridOps.to_numpy(out)\n","        \n","        # 1. Connected Component Check\n","        num_components_I, _ = label(I_arr)\n","        num_components_O, _ = label(O_arr)\n","        if np.max(num_components_I) != np.max(num_components_O):\n","            return False\n","\n","        # 2. Border Pixel Ratio Check\n","        I_boundary = GridOps.to_numpy(GridOps.boundary_extract(inp))\n","        O_boundary = GridOps.to_numpy(GridOps.boundary_extract(out))\n","        \n","        density_I_boundary = np.sum(I_boundary != 0) / np.sum(I_arr != 0) if np.sum(I_arr != 0) else 0\n","        density_O_boundary = np.sum(O_boundary != 0) / np.sum(O_arr != 0) if np.sum(O_arr != 0) else 0\n","        \n","        if abs(density_I_boundary - density_O_boundary) > 0.1:\n","            return False\n","            \n","        return True\n","\n","\n","# =============================================================================\n","# --- NOVEL SYNTHESIS METHODS (COST 4 - ELITE) ---\n","# =============================================================================\n","\n","@StrategyRegistry.register(\"graph_shortest_path\", 4, orthogonality_score=0.1)\n","class GraphShortestPathStrategy(TransformationStrategy):\n","    def __init__(self): super().__init__(\"graph_shortest_path\", 4, orthogonality_score=0.1)\n","    \n","    def can_apply_and_cost(self, train_examples):\n","        features = GridOps.calculate_features(ARCTask(task_id=\"\", train_examples=train_examples, test_inputs=[]))\n","        max_steps = EliteStrategyHelper._get_nsm_validation_depth(self, features)\n","        steps_taken = EliteStrategyHelper._dynamic_orthogonality_penalty(self, features)\n","        \n","        for inp, out in train_examples:\n","            steps_taken += self._complexity_derivative(inp) * 5\n","            if steps_taken >= max_steps: return False, None, steps_taken\n","            \n","            I, O = GridOps.to_numpy(inp), GridOps.to_numpy(out)\n","            H, W = I.shape\n","            \n","            out_colors = {(r, c): O[r, c] for r in range(H) for c in range(W) if O[r, c] != 0}\n","            if not out_colors: continue\n","\n","            consistency_map = {}\n","            for r_in in range(H):\n","                for c_in in range(W):\n","                    if I[r_in, c_in] != 0:\n","                        min_dist_sq = float('inf')\n","                        nearest_color = None\n","                        \n","                        for (r_out, c_out), color in out_colors.items():\n","                            dist_sq = (r_in - r_out)**2 + (c_in - c_out)**2\n","                            if dist_sq < min_dist_sq:\n","                                min_dist_sq = dist_sq\n","                                nearest_color = color\n","                        \n","                        if nearest_color is None: continue\n","\n","                        if I[r_in, c_in] in consistency_map and consistency_map[I[r_in, c_in]] != nearest_color:\n","                            return False, None, steps_taken\n","                        consistency_map[I[r_in, c_in]] = nearest_color\n","            \n","        return True, {'map': consistency_map}, steps_taken\n","    \n","    def apply(self, test_input, rule_params):\n","        I = GridOps.to_numpy(test_input); O = np.zeros_like(I)\n","        if 'map' in rule_params:\n","            for r in range(I.shape[0]):\n","                for c in range(I.shape[1]):\n","                    in_color = I[r, c]\n","                    if in_color != 0 and in_color in rule_params['map']:\n","                        O[r, c] = rule_params['map'][in_color]\n","        return GridOps.from_numpy(O)\n","\n","@StrategyRegistry.register(\"segmentation_color_fill\", 4, orthogonality_score=0.3)\n","class SegmentationColorFillStrategy(TransformationStrategy):\n","    def __init__(self): super().__init__(\"segmentation_color_fill\", 4, orthogonality_score=0.3)\n","    \n","    def can_apply_and_cost(self, train_examples):\n","        features = GridOps.calculate_features(ARCTask(task_id=\"\", train_examples=train_examples, test_inputs=[]))\n","        max_steps = EliteStrategyHelper._get_nsm_validation_depth(self, features)\n","        steps_taken = EliteStrategyHelper._dynamic_orthogonality_penalty(self, features)\n","        \n","        rule = None\n","        for inp, out in train_examples:\n","            steps_taken += self._complexity_derivative(inp) * 4\n","            if steps_taken >= max_steps: return False, None, steps_taken\n","\n","            I, O = GridOps.to_numpy(inp), GridOps.to_numpy(out)\n","            \n","            input_counts = {c: np.sum(I == c) for c in np.unique(I) if c != 0}\n","            if not input_counts: return False, None, steps_taken\n","            target_input_color = max(input_counts, key=input_counts.get)\n","            \n","            segment_mask = (I == target_input_color)\n","            output_colors_in_segment = O[segment_mask]\n","            \n","            output_counts = {c: np.sum(output_colors_in_segment == c) for c in np.unique(output_colors_in_segment) if c != 0}\n","            if not output_counts: continue\n","            target_output_color = max(output_counts, key=output_counts.get)\n","\n","            current_rule = (target_input_color, target_output_color)\n","            \n","            if rule is None: rule = current_rule\n","            elif rule != current_rule: return False, None, steps_taken\n","            \n","            O_test = O.copy()\n","            O_test[segment_mask] = target_output_color\n","            if np.sum(O_test != O) > 0: return False, None, steps_taken\n","            \n","        return True, {'in': rule[0], 'out': rule[1]}, steps_taken\n","    \n","    def apply(self, test_input, rule_params):\n","        I = GridOps.to_numpy(test_input); O = I.copy()\n","        \n","        target_input_color = rule_params['in']\n","        target_output_color = rule_params['out']\n","        \n","        segment_mask = (I == target_input_color)\n","        O[segment_mask] = target_output_color\n","        \n","        return GridOps.from_numpy(O)\n","\n","@StrategyRegistry.register(\"fft_pattern_filter\", 5, orthogonality_score=0.0)\n","class FFTPatternFilterStrategy(TransformationStrategy):\n","    def __init__(self): super().__init__(\"fft_pattern_filter\", 5, orthogonality_score=0.0)\n","    \n","    def can_apply_and_cost(self, train_examples):\n","        features = GridOps.calculate_features(ARCTask(task_id=\"\", train_examples=train_examples, test_inputs=[]))\n","        max_steps = EliteStrategyHelper._get_nsm_validation_depth(self, features)\n","        steps_taken = EliteStrategyHelper._dynamic_orthogonality_penalty(self, features)\n","\n","        rule = None\n","        for inp, out in train_examples:\n","            steps_taken += self._complexity_derivative(inp) * 8\n","            if steps_taken >= max_steps: return False, None, steps_taken\n","            \n","            I = GridOps.to_numpy(inp); O = GridOps.to_numpy(out)\n","            if I.shape != O.shape: continue\n","\n","            if not EliteStrategyHelper.check_multi_scale_persistence(inp, out):\n","                 return False, None, steps_taken\n","\n","            F_I = np.fft.fft2(I); F_O = np.fft.fft2(O)\n","            magnitude_I = np.abs(F_I); magnitude_O = np.abs(F_O)\n","            \n","            threshold = np.max(magnitude_I) * 0.1\n","            dominant_mask = (magnitude_I > threshold)\n","\n","            if np.sum(dominant_mask) == 0: continue\n","                \n","            ratios = magnitude_O[dominant_mask] / magnitude_I[dominant_mask]\n","            \n","            mean_ratio = np.mean(ratios)\n","            std_ratio = np.std(ratios)\n","\n","            if std_ratio > 0.1 * mean_ratio:\n","                return False, None, steps_taken\n","            \n","            current_rule = mean_ratio\n","            if rule is None: rule = current_rule\n","            elif abs(rule - current_rule) > 0.1: return False, None, steps_taken\n","            \n","        return True, {'mean_ratio': rule}, steps_taken\n","    \n","    def apply(self, test_input, rule_params):\n","        I = GridOps.to_numpy(test_input)\n","        F_I = np.fft.fft2(I)\n","        \n","        F_O = F_I * rule_params['mean_ratio'] \n","        \n","        O = np.fft.ifft2(F_O).real\n","        O = np.round(np.clip(O, 0, 9)).astype(np.int32) \n","        \n","        return GridOps.from_numpy(O)\n","\n","# =============================================================================\n","# --- NOVEL SYNTHESIS METHODS (COST 5 - EXTREME ELITE) ---\n","# =============================================================================\n","\n","@StrategyRegistry.register(\"topological_homology_match\", 5, orthogonality_score=0.05)\n","class TopologicalHomologyMatch(TransformationStrategy):\n","    def __init__(self): super().__init__(\"topological_homology_match\", 5, orthogonality_score=0.05)\n","    \n","    def can_apply_and_cost(self, train_examples):\n","        features = GridOps.calculate_features(ARCTask(task_id=\"\", train_examples=train_examples, test_inputs=[]))\n","        max_steps = EliteStrategyHelper._get_nsm_validation_depth(self, features)\n","        steps_taken = EliteStrategyHelper._dynamic_orthogonality_penalty(self, features)\n","        \n","        for inp, out in train_examples:\n","            steps_taken += self._complexity_derivative(inp) * 10\n","            if steps_taken >= max_steps: return False, None, steps_taken\n","            \n","            I, O = GridOps.to_numpy(inp), GridOps.to_numpy(out)\n","            \n","            num_components_I, _ = label(I)\n","            num_components_O, _ = label(O)\n","            \n","            if np.max(num_components_I) != np.max(num_components_O):\n","                return False, None, steps_taken\n","                \n","        return True, {'invariants_preserved': ['component_count']}, steps_taken\n","    \n","    def apply(self, test_input, rule_params):\n","        return test_input \n","\n","@StrategyRegistry.register(\"tensor_decomposition_factor\", 5, orthogonality_score=0.1)\n","class TensorDecompositionFactor(TransformationStrategy):\n","    def __init__(self): super().__init__(\"tensor_decomposition_factor\", 5, orthogonality_score=0.1)\n","    \n","    def can_apply_and_cost(self, train_examples):\n","        features = GridOps.calculate_features(ARCTask(task_id=\"\", train_examples=train_examples, test_inputs=[]))\n","        max_steps = EliteStrategyHelper._get_nsm_validation_depth(self, features)\n","        steps_taken = EliteStrategyHelper._dynamic_orthogonality_penalty(self, features)\n","        \n","        rule = None\n","        \n","        for inp, out in train_examples:\n","            steps_taken += self._complexity_derivative(inp) * 12\n","            if steps_taken >= max_steps: return False, None, steps_taken\n","            \n","            I, O = GridOps.to_numpy(inp), GridOps.to_numpy(out)\n","            \n","            if I.shape != O.shape: continue \n","                \n","            norm_I = np.linalg.norm(I); norm_O = np.linalg.norm(O)\n","            \n","            if norm_I == 0: continue\n","                \n","            scale_factor = norm_O / norm_I\n","            \n","            if rule is None: rule = scale_factor\n","            elif abs(rule - scale_factor) > 0.1: return False, None, steps_taken\n","            \n","        if rule:\n","            return True, {'scale': rule}, steps_taken\n","        return False, None, steps_taken\n","    \n","    def apply(self, test_input, rule_params):\n","        I = GridOps.to_numpy(test_input)\n","        O = I * rule_params['scale']\n","        O = np.round(np.clip(O, 0, 9)).astype(np.int32)\n","        return GridOps.from_numpy(O)\n","\n","#Cell 4\n"]},{"cell_type":"code","execution_count":5,"id":"f98e7296","metadata":{"execution":{"iopub.execute_input":"2025-10-31T00:55:32.721026Z","iopub.status.busy":"2025-10-31T00:55:32.720677Z","iopub.status.idle":"2025-10-31T02:41:18.848696Z","shell.execute_reply":"2025-10-31T02:41:18.8478Z"},"papermill":{"duration":6346.139404,"end_time":"2025-10-31T02:41:18.854873","exception":false,"start_time":"2025-10-31T00:55:32.715469","status":"completed"},"tags":[]},"outputs":[{"name":"stdout","output_type":"stream","text":["================================================================================\n","ARC PRIZE 2025 - ORCASWORD SOLVER v9.0 (NSM/SDP - FINAL META-CORE ARCHITECTURE)\n","================================================================================\n","\n"," Loading data...\n","   Loaded Train: 1000 | Test: 240 | Eval: 120 tasks.\n","\n","\n","--- PHASE 0: META-TRAINING (NSM/SDP PET Seeding) ---\n","\n","--- TRAINING CHALLENGES (P0 - DEEP PET SEED) | AGENT OMEGA | NORMAL ORDER (120 MIN BUDGET) ---\n","   Progress: 50/1000 | Elapsed: 154s | Speed: 0.32 tasks/sec\n","   Progress: 100/1000 | Elapsed: 382s | Speed: 0.26 tasks/sec\n","   Progress: 150/1000 | Elapsed: 597s | Speed: 0.25 tasks/sec\n","   Progress: 200/1000 | Elapsed: 834s | Speed: 0.24 tasks/sec\n","   Progress: 250/1000 | Elapsed: 1029s | Speed: 0.24 tasks/sec\n","   Progress: 300/1000 | Elapsed: 1246s | Speed: 0.24 tasks/sec\n","   Progress: 350/1000 | Elapsed: 1484s | Speed: 0.24 tasks/sec\n","   Progress: 400/1000 | Elapsed: 1651s | Speed: 0.24 tasks/sec\n","   Progress: 450/1000 | Elapsed: 1853s | Speed: 0.24 tasks/sec\n","   Progress: 500/1000 | Elapsed: 2102s | Speed: 0.24 tasks/sec\n","   Progress: 550/1000 | Elapsed: 2294s | Speed: 0.24 tasks/sec\n","   Progress: 600/1000 | Elapsed: 2506s | Speed: 0.24 tasks/sec\n","   Progress: 650/1000 | Elapsed: 2744s | Speed: 0.24 tasks/sec\n","   Progress: 700/1000 | Elapsed: 2968s | Speed: 0.24 tasks/sec\n","   Progress: 750/1000 | Elapsed: 3210s | Speed: 0.23 tasks/sec\n","   Progress: 800/1000 | Elapsed: 3392s | Speed: 0.24 tasks/sec\n","   Progress: 850/1000 | Elapsed: 3617s | Speed: 0.23 tasks/sec\n","   Progress: 900/1000 | Elapsed: 3834s | Speed: 0.23 tasks/sec\n","   Progress: 950/1000 | Elapsed: 4050s | Speed: 0.23 tasks/sec\n"," TRAINING CHALLENGES (P0 - DEEP PET SEED) COMPLETE!\n","   Tasks Attempted: 1000 / 1000\n","   Total Solutions Found: 145 / 1076 attempts\n","   Final Elapsed Time: 4306.21s\n","\n","   Elite Strategy Performance (Cost >= 4):\n","      fft_pattern_filter            : 4 solutions\n","      graph_shortest_path           : 110 solutions\n","      segmentation_color_fill       : 2 solutions\n","      tensor_decomposition_factor   : 7 solutions\n","--------------------------------------------------------------------------------\n","\n"," MetaLearner Knowledge Snapshot (Top Contextual Inductivity Scores):\n","   Target PET Context: ('Large', '2D', 'XY', 'Rotational')\n","      identity                       | CIS: 0.1000\n","      color_map                      | CIS: 0.0800\n","      center_mass_align              | CIS: 0.0450\n","      boundary_extract               | CIS: 0.0350\n","      laplacian_eigenmap             | CIS: 0.0317\n","\n","--- TEST (P1 - INITIAL ALPHA) | AGENT ALPHA | NORMAL ORDER (10 MIN BUDGET) ---\n","   Progress: 50/240 | Elapsed: 154s | Speed: 0.33 tasks/sec\n","   Progress: 100/240 | Elapsed: 381s | Speed: 0.26 tasks/sec\n","   Progress: 150/240 | Elapsed: 595s | Speed: 0.25 tasks/sec\n","   Time limit reached! Stopping at task 154/240.\n"," TEST (P1 - INITIAL ALPHA) COMPLETE!\n","   Tasks Attempted: 154 / 240\n","   Total Solutions Found: 26 / 163 attempts\n","   Final Elapsed Time: 602.40s\n","\n","   Elite Strategy Performance (Cost >= 4):\n","      graph_shortest_path           : 23 solutions\n","      tensor_decomposition_factor   : 1 solutions\n","--------------------------------------------------------------------------------\n","\n","--- EVAL (P2 - OMEGA BREAKTHROUGH) | AGENT OMEGA | REVERSED ORDER (10 MIN BUDGET) ---\n","   Time limit reached! Stopping at task 42/120.\n"," EVAL (P2 - OMEGA BREAKTHROUGH) COMPLETE!\n","   Tasks Attempted: 42 / 120\n","   Total Solutions Found: 2 / 59 attempts\n","   Final Elapsed Time: 627.36s\n","\n","   Elite Strategy Performance (Cost >= 4):\n","      fft_pattern_filter            : 1 solutions\n","      graph_shortest_path           : 1 solutions\n","--------------------------------------------------------------------------------\n","\n","--- EVAL (P3 - ALPHA CROSS-VAL) | AGENT ALPHA | NORMAL ORDER (5 MIN BUDGET) ---\n","   Time limit reached! Stopping at task 25/120.\n"," EVAL (P3 - ALPHA CROSS-VAL) COMPLETE!\n","   Tasks Attempted: 25 / 120\n","   Total Solutions Found: 4 / 38 attempts\n","   Final Elapsed Time: 302.20s\n","\n","   Elite Strategy Performance (Cost >= 4):\n","      graph_shortest_path           : 4 solutions\n","--------------------------------------------------------------------------------\n","\n","--- TEST (P4 - OMEGA BREAKTHROUGH) | AGENT OMEGA | REVERSED ORDER (5 MIN BUDGET) ---\n","   Progress: 50/240 | Elapsed: 199s | Speed: 0.25 tasks/sec\n","   Time limit reached! Stopping at task 69/240.\n"," TEST (P4 - OMEGA BREAKTHROUGH) COMPLETE!\n","   Tasks Attempted: 69 / 240\n","   Total Solutions Found: 11 / 77 attempts\n","   Final Elapsed Time: 302.62s\n","\n","   Elite Strategy Performance (Cost >= 4):\n","      fft_pattern_filter            : 1 solutions\n","      graph_shortest_path           : 9 solutions\n","      tensor_decomposition_factor   : 1 solutions\n","--------------------------------------------------------------------------------\n","\n","--- TEST (P5 - CONSOLIDATION SWEEP) | AGENT ALPHA | NORMAL ORDER (2 MIN BUDGET) ---\n","   Progress: 50/240 | Elapsed: 0s | Speed: 2447.29 tasks/sec\n","   Progress: 100/240 | Elapsed: 0s | Speed: 2433.84 tasks/sec\n","   Progress: 150/240 | Elapsed: 2s | Speed: 74.20 tasks/sec\n","   Progress: 200/240 | Elapsed: 82s | Speed: 2.43 tasks/sec\n"," TEST (P5 - CONSOLIDATION SWEEP) COMPLETE!\n","   Tasks Attempted: 240 / 240\n","   Total Solutions Found: 11 / 30 attempts\n","   Final Elapsed Time: 82.30s\n","\n","   Elite Strategy Performance (Cost >= 4):\n","      graph_shortest_path           : 9 solutions\n","      tensor_decomposition_factor   : 1 solutions\n","--------------------------------------------------------------------------------\n","\n","--- EVAL (P6 - FINAL COMPLEX SEARCH) | AGENT OMEGA | NORMAL ORDER (2 MIN BUDGET) ---\n","   Time limit reached! Stopping at task 11/120.\n"," EVAL (P6 - FINAL COMPLEX SEARCH) COMPLETE!\n","   Tasks Attempted: 11 / 120\n","   Total Solutions Found: 3 / 18 attempts\n","   Final Elapsed Time: 122.42s\n","\n","   Elite Strategy Performance (Cost >= 4):\n","      graph_shortest_path           : 3 solutions\n","--------------------------------------------------------------------------------\n","\n","================================================================================\n"," AGGREGATING AND GENERATING FINAL SUBMISSIONS (Phase 7: Submission)\n","\n"," Execution Complete. Final submissions written.\n","Total Unique Test Tasks Solved (Consolidated): 240\n","Total Unique Eval Tasks Solved (Consolidated): 67\n","================================================================================\n"]}],"source":["#Cell 5 - COMPLETE FIXED VERSION\n","\"\"\"\n","ARC PRIZE 2025 - ORCASWORD SOLVER v9.0 (META-AWARENESS CORE)\n","================================================================================\n","Cell 5/5: Meta-Learner (SDP/PET), Solver Core (SRI), and Main Execution Logic.\n","(Implements Contextual Inductivity Score, Task Refusal, and a 7-Phase Deployment.)\n","\"\"\"\n","\n","# Must assume imports and classes from Cell 1, 2, 3, & 4 are present.\n","\n","# =============================================================================\n","# --- META-LEARNER COMPONENT (SDP/PET ENHANCEMENT) ---\n","# =============================================================================\n","\n","class MetaLearner:\n","    \"\"\"Core of Meta-Awareness. Manages the Primitive Efficacy Tensor (PET) and determines dynamic strategy order using Contextual Inductivity Score (CIS).\"\"\"\n","    def __init__(self):\n","        self.all_strategies = StrategyFactory.get_all_strategies()\n","        # Initialize StrategyMetrics with orthogonality score from the factory\n","        self.metrics: Dict[str, StrategyMetrics] = {\n","            s.name: StrategyMetrics(s.name, s.cost, s.orthogonality_score) for s in self.all_strategies\n","        }\n","        self.global_solved_task_ids: Set[str] = set()\n","\n","    # ESSENTIAL PIECE 1: PET Update Mechanism\n","    def update_metrics(self, strategy_name: str, task_tier: TaskTier, success: bool, validation_steps_taken: int, pet_context_key: PET_KEY):\n","        \"\"\"Updates standard metrics and the multi-dimensional Primitive Efficacy Tensor (PET).\"\"\"\n","        metrics = self.metrics[strategy_name]\n","        \n","        metrics.total_attempts_by_tier[task_tier] += 1\n","        metrics.total_validation_steps[task_tier] += validation_steps_taken\n","        if success:\n","            metrics.success_count_by_tier[task_tier] += 1\n","            metrics.last_success_time = time.time()\n","            \n","        pet_entry = metrics.primitive_efficacy_tensor[pet_context_key]\n","        pet_entry[0] += 1 if success else 0\n","        pet_entry[1] += 1\n","        pet_entry[2] += validation_steps_taken\n","\n","    def get_success_rate(self, strategy_name: str, task_tier: TaskTier) -> float:\n","        metrics = self.metrics[strategy_name]\n","        attempts = metrics.total_attempts_by_tier[task_tier]\n","        successes = metrics.success_count_by_tier[task_tier]\n","        return successes / attempts if attempts > 0 else -1.0 \n","\n","    # ESSENTIAL PIECE 2: Contextual Inductivity Score (CIS) Calculation\n","    def calculate_cis(self, strategy_name: str, pet_context_key: PET_KEY) -> float:\n","        \"\"\"Calculates the Contextual Inductivity Score (CIS) using PET data.\"\"\"\n","        metrics = self.metrics[strategy_name]\n","        pet_entry = metrics.primitive_efficacy_tensor[pet_context_key]\n","        \n","        successes, attempts, total_steps = pet_entry\n","        orthogonality = metrics.orthogonality_score\n","        \n","        if attempts == 0:\n","            base_inductivity = 1.0 / (metrics.cost + 1e-6)\n","            return base_inductivity * (1 - orthogonality) * 0.1 \n","\n","        contextual_success_rate = successes / attempts\n","        induction_cost = total_steps / attempts\n","        raw_inductivity = contextual_success_rate / (induction_cost + 1e-6)\n","        \n","        # CIS: Higher is better (Success_Rate / Cost * Orthogonality_Bonus)\n","        cis = raw_inductivity * (1.0 + (1.0 - orthogonality))\n","        return cis\n","\n","    # ESSENTIAL PIECE 3: Dynamic Strategy Order with CIS Integration\n","    def get_dynamic_order(self, features: TaskFeatures, ideology: str) -> List[TransformationStrategy]:\n","        \"\"\"Dynamically sorts strategies using Tier-based success, Cost, and Contextual Inductivity (CIS).\"\"\"\n","        task_tier = features.tier\n","        pet_context_key: PET_KEY = (features.scale, features.dimension, features.plane, features.axis)\n","        \n","        def dynamic_sort_key(strategy: TransformationStrategy) -> Tuple[float, float, int]:\n","            success_rate = self.get_success_rate(strategy.name, task_tier)\n","            cost_factor = strategy.cost\n","            cis_score = self.calculate_cis(strategy.name, pet_context_key)\n","            \n","            if ideology == 'alpha':\n","                return (-success_rate, cost_factor, -cis_score)\n","            else: # Omega (Complex/Breakthrough)\n","                return (-cis_score, -success_rate, cost_factor) \n","\n","        sorted_strategies = sorted(self.all_strategies, key=dynamic_sort_key)\n","        \n","        if task_tier in ['Hard', 'Elite'] and ideology == 'omega':\n","             sorted_strategies.sort(key=lambda s: (-s.cost, -self.calculate_cis(s.name, pet_context_key)))\n","            \n","        return sorted_strategies\n","\n","# =============================================================================\n","# --- ENHANCED SOLVER CORE (MCAS DUAL-AGENT + SRI) ---\n","# =============================================================================\n","\n","class EnhancedARCSolver:\n","    \n","    def __init__(self, ideology: str = 'alpha', meta_learner: Optional[MetaLearner] = None):\n","        self.ideology = ideology\n","        self.meta_learner = meta_learner\n","        self.strategies = StrategyFactory.get_all_strategies()\n","        self.stats = {'total': 0, 'solved': 0, 'strategy_success': defaultdict(int)}\n","        self.log = []\n","\n","    # ESSENTIAL PIECE 4: Task Refusal Mechanism (Reliability Check)\n","    def should_refuse_task(self, features: TaskFeatures) -> bool:\n","        \"\"\"Task Refusal for Omega agent when confidence is low.\"\"\"\n","        if self.ideology == 'alpha': return False\n","        \n","        task_tier = features.tier\n","        best_rate = -1.0\n","        best_attempts = 0\n","        \n","        for name, metrics in self.meta_learner.metrics.items():\n","            if metrics.cost >= 3:\n","                rate = self.meta_learner.get_success_rate(name, task_tier)\n","                attempts = metrics.total_attempts_by_tier[task_tier]\n","                \n","                if rate > best_rate:\n","                    best_rate = rate\n","                    best_attempts = attempts\n","        \n","        if best_attempts > 50 and best_rate < 0.01:\n","            return True\n","        return False\n","\n","    def solve_task(self, task: ARCTask) -> List[Grid]:\n","        features = GridOps.calculate_features(task)\n","        task_tier = features.tier\n","        \n","        if self.meta_learner:\n","            if self.should_refuse_task(features):\n","                self.log.append(f\"REFUSAL|{task.task_id}|{task_tier}\")\n","                return [task.test_inputs[0]]\n","                \n","            self.strategies = self.meta_learner.get_dynamic_order(features, self.ideology)\n","        \n","        if self.ideology == 'alpha' and self.meta_learner and task.task_id in self.meta_learner.global_solved_task_ids:\n","            return [copy.deepcopy(t) for t in task.test_inputs] \n","\n","        predictions = []\n","        for test_input in task.test_inputs:\n","            predictions.append(self._solve_single(test_input, task.train_examples, task.task_id, features))\n","        return predictions\n","    \n","    def _solve_single(self, test_input: Grid, train_examples: List[Tuple[Grid, Grid]], task_id: str, features: TaskFeatures) -> Grid:\n","        \"\"\"CRITICAL FIX: Added missing _solve_single method with error handling\"\"\"\n","        self.stats['total'] += 1\n","        task_tier = features.tier\n","        pet_context_key: PET_KEY = (features.scale, features.dimension, features.plane, features.axis)\n","        \n","        for strategy in self.strategies:\n","            start_solve = time.time()\n","            \n","            try:\n","                success, rule_params, steps_taken, _ = SelfReflectiveInduction.validate_and_cost(strategy, train_examples)\n","            except Exception as e:\n","                self.log.append(f\"CRITICAL_FAILURE|{task_id}|{strategy.name}|{task_tier}|{e}\")\n","                success, rule_params, steps_taken = False, None, 1\n","            \n","            solve_time = time.time() - start_solve\n","            \n","            if success:\n","                # SAFETY WRAPPER: Prevent strategy application errors\n","                try:\n","                    result = strategy.apply(test_input, rule_params)\n","                except Exception as e:\n","                    self.log.append(f\"CRITICAL_APPLY_FAILURE|{task_id}|{strategy.name}|{task_tier}|{e}\")\n","                    result = test_input\n","                \n","                if result is not None and not GridOps.grids_equal(result, test_input):\n","                    self.stats['solved'] += 1\n","                    self.stats['strategy_success'][strategy.name] += 1\n","                    \n","                    if self.meta_learner:\n","                        self.meta_learner.update_metrics(strategy.name, task_tier, True, steps_taken, pet_context_key)\n","                    \n","                    # ESSENTIAL PIECE 6: Enhanced SDM Observability Log\n","                    self.log.append(f\"SUCCESS|{task_id}|{strategy.name}|{task_tier}|{steps_taken}|{solve_time:.4f}|{strategy.cost}|PET:{':'.join(pet_context_key)}|CIS:{self.meta_learner.calculate_cis(strategy.name, pet_context_key):.4f}\")\n","                    \n","                    return result\n","            \n","            if self.meta_learner:\n","                self.meta_learner.update_metrics(strategy.name, task_tier, False, steps_taken, pet_context_key)\n","            \n","            # ESSENTIAL PIECE 6: Enhanced SDM Observability Log\n","            self.log.append(f\"FAILURE|{task_id}|{strategy.name}|{task_tier}|{steps_taken}|{solve_time:.4f}|{strategy.cost}|PET:{':'.join(pet_context_key)}\")\n","\n","        return test_input\n","\n","# =============================================================================\n","# --- DATA LOADING & SUBMISSION UTILITIES (RETAINED) ---\n","# =============================================================================\n","\n","class ARCDataLoader:\n","    @staticmethod\n","    def load_tasks(challenges_path: str) -> List[ARCTask]:\n","        try:\n","            with open(challenges_path, 'r') as f: challenges = json.load(f)\n","        except FileNotFoundError: return []\n","        \n","        tasks = []\n","        for task_id, task_data in challenges.items():\n","            train_examples = [(ex['input'], ex['output']) for ex in task_data['train']]\n","            test_inputs = [ex['input'] for ex in task_data['test']]\n","            tasks.append(ARCTask(task_id=task_id, train_examples=train_examples, test_inputs=test_inputs))\n","        return tasks\n","\n","class SubmissionGenerator:\n","    # ESSENTIAL PIECE 7: Robust Submission Generation\n","    @staticmethod\n","    def generate(predictions: Dict[str, List[Grid]], output_path: str):\n","        submission = {}\n","        for task_id, pred_grids in predictions.items():\n","            sanitized_grids = []\n","            if pred_grids:\n","                first_pred = pred_grids[0]\n","                if isinstance(first_pred, list):\n","                     sanitized_grids.append(first_pred)\n","            \n","            final_pred = sanitized_grids[0] if sanitized_grids else [[0]] \n","            \n","            submission[task_id] = {\n","                \"attempt_1\": final_pred,\n","                \"attempt_2\": final_pred \n","            }\n","        \n","        if output_path:\n","            with open(output_path, 'w') as f: \n","                json.dump(submission, f, indent=2)\n","\n","# =============================================================================\n","# --- MAIN EXECUTION (SEVEN-PHASE NOVEL SYNTHESIS DEPLOYMENT) ---\n","# =============================================================================\n","\n","def merge_predictions(current_predictions: Dict, new_predictions: Dict, meta_learner: MetaLearner) -> Dict:\n","    # Merging logic (Retained for robustness)\n","    newly_solved_ids = set()\n","    for task_id, new_preds in new_predictions.items():\n","        if not new_preds: continue\n","        new_grid = new_preds[0]\n","        is_new_solution = new_grid and any(any(cell != 0 for cell in row) for row in new_grid) \n","\n","        if task_id not in current_predictions:\n","            current_predictions[task_id] = new_preds\n","            if is_new_solution: newly_solved_ids.add(task_id) \n","        else:\n","            current_grid = current_predictions[task_id][0]\n","            is_current_solution = current_grid and any(any(cell != 0 for cell in row) for row in current_grid)\n","            \n","            if is_new_solution and not is_current_solution:\n","                 current_predictions[task_id] = new_preds\n","                 newly_solved_ids.add(task_id)\n","            \n","    meta_learner.global_solved_task_ids.update(newly_solved_ids)\n","    return current_predictions\n","\n","# ESSENTIAL PIECE 5: Meta-Aware Retraining Loop\n","def run_prediction_phase(\n","    solver: EnhancedARCSolver, \n","    tasks: List[ARCTask], \n","    time_budget_minutes: int, \n","    phase_name: str,\n","    reverse_order: bool = False\n","):\n","    time_budget_seconds = time_budget_minutes * 60\n","    order_label = \"REVERSED\" if reverse_order else \"NORMAL\"\n","    print(f\"\\n--- {phase_name.upper()} | AGENT {solver.ideology.upper()} | {order_label} ORDER ({time_budget_minutes} MIN BUDGET) ---\")\n","    \n","    solver.stats = {'total': 0, 'solved': 0, 'strategy_success': defaultdict(int)}\n","    solver.log = []\n","    \n","    tasks_to_run = tasks[::-1] if reverse_order else tasks\n","    \n","    start_time = time.time()\n","    predictions = {}\n","    tasks_attempted = 0\n","    \n","    for i, task in enumerate(tasks_to_run):\n","        elapsed_time = time.time() - start_time\n","        \n","        if elapsed_time >= time_budget_seconds:\n","            print(f\"   Time limit reached! Stopping at task {i}/{len(tasks_to_run)}.\")\n","            break\n","            \n","        if i > 0 and i % 50 == 0:\n","            tasks_per_second = i / elapsed_time if elapsed_time > 0 else 0\n","            print(f\"   Progress: {i}/{len(tasks_to_run)} | Elapsed: {elapsed_time:.0f}s | Speed: {tasks_per_second:.2f} tasks/sec\")\n","            \n","        predictions[task.task_id] = solver.solve_task(task)\n","        tasks_attempted += 1\n","\n","    final_elapsed = time.time() - start_time\n","    \n","    print(f\" {phase_name.upper()} COMPLETE!\")\n","    print(f\"   Tasks Attempted: {tasks_attempted} / {len(tasks_to_run)}\")\n","    print(f\"   Total Solutions Found: {solver.stats['solved']} / {solver.stats['total']} attempts\")\n","    print(f\"   Final Elapsed Time: {final_elapsed:.2f}s\")\n","    \n","    # SDM Feature: Elite Strategy Performance Summary\n","    print(\"\\n   Elite Strategy Performance (Cost >= 4):\")\n","    for s_name in sorted(solver.stats['strategy_success'].keys()):\n","        if StrategyRegistry.strategies[s_name][1] >= 4 and solver.stats['strategy_success'][s_name] > 0:\n","            print(f\"      {s_name:<30}: {solver.stats['strategy_success'][s_name]} solutions\")\n","    print(\"-\" * 80)\n","    \n","    return predictions\n","\n","\n","def main():\n","    print(\"=\"*80)\n","    print(\"ARC PRIZE 2025 - ORCASWORD SOLVER v9.0 (NSM/SDP - FINAL META-CORE ARCHITECTURE)\")\n","    print(\"=\"*80)\n","    \n","    PHASE_BUDGETS = {\n","        'P0_TRAIN': TRAINING_TIME_LIMIT_MIN,\n","        'P1_ALPHA_TEST': 10,\n","        'P2_OMEGA_EVAL': 10,\n","        'P3_ALPHA_EVAL': 5,\n","        'P4_OMEGA_TEST': 5,\n","        'P5_CONSOL_TEST': 2,\n","        'P6_CONSOL_EVAL': 2,\n","    }\n","    \n","    KAGGLE_INPUT_DIR = '/kaggle/input/arc-prize-2025'\n","    KAGGLE_OUTPUT_DIR = '/kaggle/working'\n","    \n","    TRAIN_PATH = f'{KAGGLE_INPUT_DIR}/arc-agi_training_challenges.json'\n","    TEST_PATH = f'{KAGGLE_INPUT_DIR}/arc-agi_test_challenges.json'          \n","    EVAL_PATH = f'{KAGGLE_INPUT_DIR}/arc-agi_evaluation_challenges.json'  \n","    \n","    TEST_OUTPUT_PATH = f'{KAGGLE_OUTPUT_DIR}/submission_test.json'\n","    EVAL_OUTPUT_PATH = f'{KAGGLE_OUTPUT_DIR}/submission_eval.json'\n","    \n","    print(f\"\\n Loading data...\")\n","    train_tasks = ARCDataLoader.load_tasks(TRAIN_PATH)\n","    test_tasks = ARCDataLoader.load_tasks(TEST_PATH)\n","    eval_tasks = ARCDataLoader.load_tasks(EVAL_PATH)\n","    print(f\"   Loaded Train: {len(train_tasks)} | Test: {len(test_tasks)} | Eval: {len(eval_tasks)} tasks.\")\n","\n","    if not test_tasks and not eval_tasks: \n","        print(\"No test or evaluation tasks loaded. Exiting.\")\n","        return\n","\n","    meta_learner = MetaLearner()\n","\n","    # --- PHASE 0: META-TRAINING (PET & SDP Seeding) ---\n","    print(\"\\n\\n--- PHASE 0: META-TRAINING (NSM/SDP PET Seeding) ---\")\n","    \n","    meta_train_agent = EnhancedARCSolver(ideology='omega', meta_learner=meta_learner)\n","    \n","    p0_preds = run_prediction_phase(\n","        solver=meta_train_agent, tasks=train_tasks, time_budget_minutes=PHASE_BUDGETS['P0_TRAIN'], \n","        phase_name=\"TRAINING CHALLENGES (P0 - Deep PET Seed)\", reverse_order=False\n","    )\n","    \n","    print(\"\\n MetaLearner Knowledge Snapshot (Top Contextual Inductivity Scores):\")\n","    sample_key = ('Large', '2D', 'XY', 'Rotational')\n","    print(f\"   Target PET Context: {sample_key}\")\n","    \n","    cis_list = []\n","    for s_name in meta_learner.metrics.keys():\n","        cis = meta_learner.calculate_cis(s_name, sample_key)\n","        if meta_learner.metrics[s_name].total_attempts_by_tier.get('Elite', 0) > 0 and cis > 0.01:\n","             cis_list.append((s_name, cis))\n","    \n","    for s_name, cis in sorted(cis_list, key=lambda x: x[1], reverse=True)[:5]:\n","        print(f\"      {s_name:<30} | CIS: {cis:.4f}\")\n","\n","\n","    # --- PHASE 1-6: SEVEN-PHASE DYNAMIC DEPLOYMENT ---\n","\n","    final_test_predictions = {}\n","    final_eval_predictions = {}\n","    \n","    alpha_agent = EnhancedARCSolver(ideology='alpha', meta_learner=meta_learner)\n","    omega_agent = EnhancedARCSolver(ideology='omega', meta_learner=meta_learner)\n","    \n","    # P1: Initial Coverage (Alpha on Test)\n","    test_preds_run1 = run_prediction_phase(alpha_agent, test_tasks, PHASE_BUDGETS['P1_ALPHA_TEST'], \"TEST (P1 - Initial Alpha)\", reverse_order=False)\n","    final_test_predictions = merge_predictions(final_test_predictions, test_preds_run1, meta_learner)\n","    \n","    # P2: Complex Search (Omega on Eval, Reversed for anti-sequential bias)\n","    eval_preds_run2 = run_prediction_phase(omega_agent, eval_tasks, PHASE_BUDGETS['P2_OMEGA_EVAL'], \"EVAL (P2 - Omega Breakthrough)\", reverse_order=True)\n","    final_eval_predictions = merge_predictions(final_eval_predictions, eval_preds_run2, meta_learner)\n","    \n","    # P3: Alpha Cross-Validation (Alpha on Eval)\n","    eval_preds_run3 = run_prediction_phase(alpha_agent, eval_tasks, PHASE_BUDGETS['P3_ALPHA_EVAL'], \"EVAL (P3 - Alpha Cross-Val)\", reverse_order=False)\n","    final_eval_predictions = merge_predictions(final_eval_predictions, eval_preds_run3, meta_learner)\n","\n","    # P4: Omega Cross-Validation (Omega on Test, Reversed)\n","    test_preds_run4 = run_prediction_phase(omega_agent, test_tasks, PHASE_BUDGETS['P4_OMEGA_TEST'], \"TEST (P4 - Omega Breakthrough)\", reverse_order=True)\n","    final_test_predictions = merge_predictions(final_test_predictions, test_preds_run4, meta_learner)\n","\n","    # P5: Consolidation Sweep 1 (Alpha on Test, Final Low-Hanging Fruit)\n","    test_preds_run5 = run_prediction_phase(alpha_agent, test_tasks, PHASE_BUDGETS['P5_CONSOL_TEST'], \"TEST (P5 - Consolidation Sweep)\", reverse_order=False)\n","    final_test_predictions = merge_predictions(final_test_predictions, test_preds_run5, meta_learner)\n","\n","    # P6: Consolidation Sweep 2 (Omega on Eval, Final Complex Search)\n","    eval_preds_run6 = run_prediction_phase(omega_agent, eval_tasks, PHASE_BUDGETS['P6_CONSOL_EVAL'], \"EVAL (P6 - Final Complex Search)\", reverse_order=False)\n","    final_eval_predictions = merge_predictions(final_eval_predictions, eval_preds_run6, meta_learner)\n","\n","\n","    # --- PHASE 7: FINAL SUBMISSION GENERATION (Implicit Phase) ---\n","    print(\"\\n\" + \"=\"*80)\n","    print(\" AGGREGATING AND GENERATING FINAL SUBMISSIONS (Phase 7: Submission)\")\n","    \n","    SubmissionGenerator.generate(final_test_predictions, TEST_OUTPUT_PATH)\n","    SubmissionGenerator.generate(final_eval_predictions, EVAL_OUTPUT_PATH)\n","    \n","    print(\"\\n Execution Complete. Final submissions written.\")\n","    print(f\"Total Unique Test Tasks Solved (Consolidated): {len(final_test_predictions)}\")\n","    print(f\"Total Unique Eval Tasks Solved (Consolidated): {len(final_eval_predictions)}\")\n","    print(\"=\"*80)\n","\n","# Explicitly call main() for robust execution\n","if __name__ == '__main__':\n","    main()\n","#Cell 5"]}],"metadata":{"kaggle":{"accelerator":"none","dataSources":[{"databundleVersionId":11802066,"sourceId":91496,"sourceType":"competition"}],"dockerImageVersionId":31154,"isGpuEnabled":false,"isInternetEnabled":false,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.13"},"papermill":{"default_parameters":{},"duration":6352.256301,"end_time":"2025-10-31T02:41:19.28033","environment_variables":{},"exception":null,"input_path":"__notebook__.ipynb","output_path":"__notebook__.ipynb","parameters":{},"start_time":"2025-10-31T00:55:27.024029","version":"2.6.0"}},"nbformat":4,"nbformat_minor":5}