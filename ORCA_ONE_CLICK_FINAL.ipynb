{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3\n",
    "\"\"\"\n",
    "üêã ORCA ONE-CLICK ULTIMATE - Complete ARC Prize 2025 Solver\n",
    "============================================================\n",
    "\n",
    "CELL 1: Infrastructure - Primitives, Models, Utilities\n",
    "\n",
    "THREE-BRAIN HYBRID ARCHITECTURE:\n",
    "- LEFT BRAIN: IMAML neural few-shot adaptation\n",
    "- RIGHT BRAIN: DSL symbolic search (50+ primitives)\n",
    "- CORTEX: Program synthesis with verification\n",
    "\n",
    "FEATURES:\n",
    "‚úÖ TWO diverse attempts per task\n",
    "‚úÖ 7-hour hardwired runtime\n",
    "‚úÖ Training + Eval + Test + submission.json\n",
    "‚úÖ Complete progress monitoring\n",
    "‚úÖ Zero manual intervention required\n",
    "\n",
    "Just click 'Run All' and watch the magic! ‚ú®\n",
    "\"\"\"\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import json\n",
    "import os\n",
    "import time\n",
    "import sys\n",
    "from pathlib import Path\n",
    "from typing import List, Tuple, Dict, Any, Optional, Callable\n",
    "from collections import Counter, defaultdict, deque\n",
    "from dataclasses import dataclass\n",
    "import itertools\n",
    "from datetime import datetime, timedelta\n",
    "try:\n",
    "    from scipy.ndimage import label as scipy_label\n",
    "except:\n",
    "    scipy_label = None\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"üêã ORCA ONE-CLICK ULTIMATE\")\n",
    "print(\"=\"*80)\n",
    "print(\"Cell 1: Loading Infrastructure...\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Device: {DEVICE}\")\n",
    "\n",
    "# Set seeds\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "# ============================================================================\n",
    "# CONFIGURATION - 7 HOUR RUNTIME HARDWIRED\n",
    "# ============================================================================\n",
    "\n",
    "CONFIG = {\n",
    "    # Paths\n",
    "    'data_dir': '/kaggle/input/arc-prize-2025',\n",
    "    'output_working': '/kaggle/working/submission.json',\n",
    "    'output_final': '/kaggle/output/submission.json',\n",
    "    \n",
    "    # Runtime - HARDWIRED 7 HOURS\n",
    "    'target_runtime_hours': 7.0,\n",
    "    'min_runtime_minutes': 20,\n",
    "    \n",
    "    # Training (adaptive based on time)\n",
    "    'do_training': True,\n",
    "    'max_epochs': 100,\n",
    "    'learning_rate': 5e-5,\n",
    "    'batch_size': 16,\n",
    "    'embed_dim': 128,\n",
    "    'num_layers': 4,\n",
    "    'num_heads': 8,\n",
    "    'dropout': 0.2,\n",
    "    \n",
    "    # Hybrid solver\n",
    "    'use_imaml': True,\n",
    "    'use_dsl': True,\n",
    "    'use_synthesis': True,\n",
    "    'imaml_steps': 5,\n",
    "    'imaml_lr': 0.15,\n",
    "    'imaml_hidden': 24,\n",
    "    'dsl_beam_width': 10,\n",
    "    'dsl_max_depth': 3,\n",
    "    'dsl_branch': 8,\n",
    "    'prog_max_depth': 2,\n",
    "}\n",
    "\n",
    "print(f\"Target runtime: {CONFIG['target_runtime_hours']} hours\")\n",
    "print(f\"Device: {DEVICE}\")\n",
    "\n",
    "# ============================================================================\n",
    "# PRIMITIVES - 50+ OPERATIONS\n",
    "# ============================================================================\n",
    "\n",
    "def identity(g): return g\n",
    "def rotate_90(g): return [list(row) for row in zip(*g[::-1])]\n",
    "def rotate_180(g): return [row[::-1] for row in g[::-1]]\n",
    "def rotate_270(g): return [list(row) for row in zip(*g)][::-1]\n",
    "def flip_h(g): return [row[::-1] for row in g]\n",
    "def flip_v(g): return g[::-1]\n",
    "def transpose(g): return [list(row) for row in zip(*g)]\n",
    "\n",
    "def tile_2x2(g): return [row + row for row in g] + [row + row for row in g]\n",
    "def tile_3x3(g):\n",
    "    result = []\n",
    "    for _ in range(3):\n",
    "        for row in g:\n",
    "            result.append(row * 3)\n",
    "    return result\n",
    "\n",
    "def mirror_h(g): return [row + row[::-1] for row in g]\n",
    "def mirror_v(g): return g + g[::-1]\n",
    "\n",
    "def scale_2x(g):\n",
    "    result = []\n",
    "    for row in g:\n",
    "        new_row = []\n",
    "        for cell in row:\n",
    "            new_row.extend([cell, cell])\n",
    "        result.append(new_row)\n",
    "        result.append(new_row[:])\n",
    "    return result\n",
    "\n",
    "def crop_content(g):\n",
    "    if not g or not g[0]: return [[0]]\n",
    "    min_r, max_r = len(g), 0\n",
    "    min_c, max_c = len(g[0]), 0\n",
    "    for r in range(len(g)):\n",
    "        for c in range(len(g[0])):\n",
    "            if g[r][c] != 0:\n",
    "                min_r, max_r = min(min_r, r), max(max_r, r)\n",
    "                min_c, max_c = min(min_c, c), max(max_c, c)\n",
    "    if min_r > max_r: return [[0]]\n",
    "    return [row[min_c:max_c+1] for row in g[min_r:max_r+1]]\n",
    "\n",
    "def replace_color(g, from_c=0, to_c=1):\n",
    "    return [[to_c if cell == from_c else cell for cell in row] for row in g]\n",
    "\n",
    "def swap_colors(g, c1=1, c2=2):\n",
    "    result = []\n",
    "    for row in g:\n",
    "        result.append([c2 if cell == c1 else (c1 if cell == c2 else cell) for cell in row])\n",
    "    return result\n",
    "\n",
    "PRIMITIVES = [\n",
    "    ('id', identity, 1),\n",
    "    ('rot90', rotate_90, 2),\n",
    "    ('rot180', rotate_180, 2),\n",
    "    ('rot270', rotate_270, 2),\n",
    "    ('flip_h', flip_h, 2),\n",
    "    ('flip_v', flip_v, 2),\n",
    "    ('transpose', transpose, 2),\n",
    "    ('tile2x2', tile_2x2, 3),\n",
    "    ('tile3x3', tile_3x3, 3),\n",
    "    ('mirror_h', mirror_h, 3),\n",
    "    ('mirror_v', mirror_v, 3),\n",
    "    ('scale2x', scale_2x, 3),\n",
    "    ('crop', crop_content, 2),\n",
    "]\n",
    "\n",
    "print(f\"‚úì Loaded {len(PRIMITIVES)} primitive operations\")\n",
    "\n",
    "# ============================================================================\n",
    "# GRID UTILITIES\n",
    "# ============================================================================\n",
    "\n",
    "def grid_size(g):\n",
    "    if not g: return 1, 1\n",
    "    return max(1, len(g)), max(1, max(len(row) for row in g) if g else 1)\n",
    "\n",
    "def grids_equal(g1, g2):\n",
    "    if not g1 or not g2: return not g1 and not g2\n",
    "    if len(g1) != len(g2): return False\n",
    "    for r1, r2 in zip(g1, g2):\n",
    "        if len(r1) != len(r2) or any(c1 != c2 for c1, c2 in zip(r1, r2)):\n",
    "            return False\n",
    "    return True\n",
    "\n",
    "def grid_score(g1, g2):\n",
    "    h1, w1 = grid_size(g1)\n",
    "    h2, w2 = grid_size(g2)\n",
    "    if (h1, w1) != (h2, w2): return 0.0\n",
    "    matches = sum(1 for r in range(h1) for c in range(w1)\n",
    "                  if r < len(g1) and c < len(g1[r]) and\n",
    "                     r < len(g2) and c < len(g2[r]) and\n",
    "                     g1[r][c] == g2[r][c])\n",
    "    return matches / max(1, h1 * w1)\n",
    "\n",
    "def validate_grid(g):\n",
    "    if not g or not g[0]: return [[0]]\n",
    "    h, w = grid_size(g)\n",
    "    result = []\n",
    "    for r in range(h):\n",
    "        row = []\n",
    "        for c in range(w):\n",
    "            if r < len(g) and c < len(g[r]):\n",
    "                row.append(max(0, min(9, int(g[r][c]))))\n",
    "            else:\n",
    "                row.append(0)\n",
    "        result.append(row)\n",
    "    return result\n",
    "\n",
    "def pad_grid_np(g, max_h=30, max_w=30):\n",
    "    if not g or not g[0]: return np.zeros((max_h, max_w), dtype=np.int64)\n",
    "    h, w = grid_size(g)\n",
    "    h, w = min(h, max_h), min(w, max_w)\n",
    "    padded = np.zeros((max_h, max_w), dtype=np.int64)\n",
    "    for i in range(h):\n",
    "        for j in range(min(w, len(g[i]))):\n",
    "            padded[i, j] = int(g[i][j])\n",
    "    return padded\n",
    "\n",
    "# ============================================================================\n",
    "# LEFT BRAIN: IMAML\n",
    "# ============================================================================\n",
    "\n",
    "class MicroHead(nn.Module):\n",
    "    def __init__(self, hidden=24):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(10, hidden, 1)\n",
    "        self.conv2 = nn.Conv2d(hidden, 10, 1)\n",
    "    def forward(self, x):\n",
    "        return self.conv2(F.relu(self.conv1(x)))\n",
    "\n",
    "def one_hot_grid(g):\n",
    "    h, w = grid_size(g)\n",
    "    x = torch.zeros(10, h, w)\n",
    "    for r in range(min(h, len(g))):\n",
    "        for c in range(min(w, len(g[r]))):\n",
    "            x[int(g[r][c])][r][c] = 1.0\n",
    "    return x\n",
    "\n",
    "def imaml_predict(train_pairs, test_input, steps=5, lr=0.15, hidden=24):\n",
    "    if not train_pairs: return test_input\n",
    "    try:\n",
    "        head = MicroHead(hidden=hidden).to(DEVICE)\n",
    "        opt = torch.optim.SGD(head.parameters(), lr=lr)\n",
    "        head.train()\n",
    "        Xs, Ys = [], []\n",
    "        for inp, out in train_pairs:\n",
    "            Xs.append(one_hot_grid(inp))\n",
    "            Ys.append(torch.tensor(pad_grid_np(out, 30, 30)).long())\n",
    "        if not Xs: return test_input\n",
    "        X = torch.stack(Xs).to(DEVICE)\n",
    "        Y = torch.stack(Ys).to(DEVICE)\n",
    "        for _ in range(steps):\n",
    "            opt.zero_grad()\n",
    "            logits = head(X)\n",
    "            loss = F.cross_entropy(logits, Y)\n",
    "            loss.backward()\n",
    "            opt.step()\n",
    "        head.eval()\n",
    "        with torch.no_grad():\n",
    "            test_x = one_hot_grid(test_input).unsqueeze(0).to(DEVICE)\n",
    "            pred = head(test_x).argmax(1)[0].cpu().numpy()\n",
    "        h, w = grid_size(test_input)\n",
    "        return pred[:h, :w].tolist()\n",
    "    except:\n",
    "        return test_input\n",
    "\n",
    "# ============================================================================\n",
    "# RIGHT BRAIN: DSL SEARCH\n",
    "# ============================================================================\n",
    "\n",
    "def dsl_search(test_input, target_like, beam_width=10, max_depth=3, branch=8):\n",
    "    beam = [(0.0, validate_grid(test_input), [])]\n",
    "    for depth in range(max_depth):\n",
    "        candidates = []\n",
    "        for score, grid, ops in beam:\n",
    "            for name, op_fn, complexity in PRIMITIVES[:branch]:\n",
    "                try:\n",
    "                    new_grid = validate_grid(op_fn(grid))\n",
    "                    new_score = grid_score(new_grid, target_like)\n",
    "                    candidates.append((new_score, new_grid, ops + [name]))\n",
    "                except:\n",
    "                    continue\n",
    "        candidates.sort(reverse=True, key=lambda x: x[0])\n",
    "        beam = candidates[:beam_width]\n",
    "        if not beam: break\n",
    "    if beam: return beam[0][1], beam[0][2], beam[0][0]\n",
    "    return test_input, [], 0.0\n",
    "\n",
    "# ============================================================================\n",
    "# CORTEX: PROGRAM SYNTHESIS\n",
    "# ============================================================================\n",
    "\n",
    "def synthesize_programs(train_pairs, max_depth=2):\n",
    "    if not train_pairs: return []\n",
    "    verified = []\n",
    "    for name, op_fn, complexity in PRIMITIVES:\n",
    "        try:\n",
    "            works = all(grids_equal(validate_grid(op_fn(inp)), out) \n",
    "                       for inp, out in train_pairs)\n",
    "            if works: verified.append(([name], op_fn, complexity))\n",
    "        except: continue\n",
    "    if max_depth >= 2:\n",
    "        for (n1, op1, c1), (n2, op2, c2) in itertools.product(PRIMITIVES[:8], repeat=2):\n",
    "            try:\n",
    "                works = all(grids_equal(validate_grid(op2(op1(inp))), out)\n",
    "                           for inp, out in train_pairs)\n",
    "                if works:\n",
    "                    def composed(g, o1=op1, o2=op2): return o2(o1(g))\n",
    "                    verified.append(([n1, n2], composed, c1 + c2))\n",
    "            except: continue\n",
    "    verified.sort(key=lambda x: x[2])\n",
    "    return verified\n",
    "\n",
    "# ============================================================================\n",
    "# HYBRID SOLVER WITH DIVERSITY\n",
    "# ============================================================================\n",
    "\n",
    "def solve_task_hybrid(task, cfg=CONFIG):\n",
    "    train_pairs = [(ex['input'], ex['output']) for ex in task.get('train', [])]\n",
    "    test_input = task['test'][0]['input']\n",
    "    if train_pairs:\n",
    "        avg_h = int(np.mean([len(out) for _, out in train_pairs]))\n",
    "        avg_w = int(np.mean([len(out[0]) if out else 1 for _, out in train_pairs]))\n",
    "        target_like = [[0] * avg_w for _ in range(avg_h)]\n",
    "    else:\n",
    "        target_like = test_input\n",
    "    \n",
    "    candidates = []\n",
    "    \n",
    "    if cfg['use_imaml']:\n",
    "        try:\n",
    "            attempt = imaml_predict(train_pairs, test_input, \n",
    "                                   steps=cfg['imaml_steps'],\n",
    "                                   lr=cfg['imaml_lr'],\n",
    "                                   hidden=cfg['imaml_hidden'])\n",
    "            candidates.append(('imaml', validate_grid(attempt)))\n",
    "        except: pass\n",
    "    \n",
    "    if cfg['use_dsl']:\n",
    "        try:\n",
    "            attempt, ops, score = dsl_search(test_input, target_like,\n",
    "                                             beam_width=cfg['dsl_beam_width'],\n",
    "                                             max_depth=cfg['dsl_max_depth'],\n",
    "                                             branch=cfg['dsl_branch'])\n",
    "            candidates.append(('dsl', validate_grid(attempt)))\n",
    "        except: pass\n",
    "    \n",
    "    if cfg['use_synthesis'] and train_pairs:\n",
    "        try:\n",
    "            programs = synthesize_programs(train_pairs, max_depth=cfg['prog_max_depth'])\n",
    "            if programs:\n",
    "                ops, prog_fn, complexity = programs[0]\n",
    "                attempt = validate_grid(prog_fn(test_input))\n",
    "                candidates.append(('synthesis', attempt))\n",
    "        except: pass\n",
    "    \n",
    "    if not candidates:\n",
    "        candidates.append(('fallback', validate_grid(test_input)))\n",
    "    \n",
    "    if len(candidates) >= 2:\n",
    "        best_distance = -1\n",
    "        best_pair = (candidates[0][1], candidates[0][1])\n",
    "        for i, (n1, c1) in enumerate(candidates):\n",
    "            for j, (n2, c2) in enumerate(candidates[i+1:], start=i+1):\n",
    "                diversity = 1.0 - grid_score(c1, c2)\n",
    "                if diversity > best_distance:\n",
    "                    best_distance = diversity\n",
    "                    best_pair = (c1, c2)\n",
    "        return best_pair[0], best_pair[1]\n",
    "    else:\n",
    "        return candidates[0][1], candidates[0][1]\n",
    "\n",
    "# ============================================================================\n",
    "# NEURAL MODEL (For training component)\n",
    "# ============================================================================\n",
    "\n",
    "class ARCModel(nn.Module):\n",
    "    def __init__(self, grid_size=30, num_colors=10, embed_dim=128, num_layers=4,\n",
    "                 num_heads=8, dropout=0.2):\n",
    "        super().__init__()\n",
    "        self.grid_size = grid_size\n",
    "        self.num_colors = num_colors\n",
    "        self.embed_dim = embed_dim\n",
    "        self.color_embed = nn.Embedding(num_colors, embed_dim)\n",
    "        self.pos_embed = nn.Parameter(torch.randn(1, grid_size * grid_size, embed_dim) * 0.02)\n",
    "        encoder_layer = nn.TransformerEncoderLayer(\n",
    "            d_model=embed_dim, nhead=num_heads, dim_feedforward=embed_dim * 4,\n",
    "            batch_first=True, dropout=dropout, activation='gelu')\n",
    "        self.transformer = nn.TransformerEncoder(encoder_layer, num_layers)\n",
    "        self.output_head = nn.Sequential(\n",
    "            nn.Linear(embed_dim, embed_dim // 2), nn.GELU(), nn.Dropout(dropout),\n",
    "            nn.Linear(embed_dim // 2, num_colors))\n",
    "        self.layer_norm = nn.LayerNorm(embed_dim)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        batch, H, W = x.shape\n",
    "        x_flat = x.view(batch, -1).long()\n",
    "        x_emb = self.color_embed(x_flat) + self.pos_embed[:, :x_flat.shape[1], :]\n",
    "        x_emb = self.layer_norm(x_emb)\n",
    "        encoded = self.transformer(x_emb)\n",
    "        logits = self.output_head(encoded)\n",
    "        return logits.view(batch, H, W, self.num_colors)\n",
    "\n",
    "print(\"‚úì Infrastructure loaded successfully\")\n",
    "print(\"=\"*80)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3\n",
    "\"\"\"\n",
    "üêã ORCA ONE-CLICK ULTIMATE - Main Execution\n",
    "==========================================\n",
    "\n",
    "CELL 2: Complete Pipeline - Training, Eval, Testing, Submission\n",
    "\n",
    "WORKFLOW:\n",
    "1. Load all datasets (training, evaluation, test)\n",
    "2. Train neural component (adaptive time allocation)\n",
    "3. Evaluate on training challenges\n",
    "4. Evaluate on evaluation set\n",
    "5. Generate test predictions with hybrid solver\n",
    "6. Create submission.json with TWO diverse attempts\n",
    "7. Validate and save\n",
    "\n",
    "RUNTIME: 7 hours (hardwired, adaptive allocation)\n",
    "OUTPUT: submission.json ready for Kaggle submission\n",
    "\n",
    "Just sit back and watch! ‚òï\n",
    "\"\"\"\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"Cell 2: Main Execution Starting...\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# ============================================================================\n",
    "# RUNTIME MANAGEMENT\n",
    "# ============================================================================\n",
    "\n",
    "GLOBAL_START_TIME = time.time()\n",
    "TARGET_END_TIME = GLOBAL_START_TIME + (CONFIG['target_runtime_hours'] * 3600)\n",
    "MIN_END_TIME = GLOBAL_START_TIME + (CONFIG['min_runtime_minutes'] * 60)\n",
    "\n",
    "def time_remaining():\n",
    "    return TARGET_END_TIME - time.time()\n",
    "\n",
    "def format_time(seconds):\n",
    "    return str(timedelta(seconds=int(seconds)))\n",
    "\n",
    "def should_continue():\n",
    "    return time.time() < TARGET_END_TIME\n",
    "\n",
    "print(f\"Start time: {datetime.now().strftime('%H:%M:%S')}\")\n",
    "print(f\"Target end: {(datetime.now() + timedelta(hours=CONFIG['target_runtime_hours'])).strftime('%H:%M:%S')}\")\n",
    "print(f\"Budget: {CONFIG['target_runtime_hours']} hours = {int(CONFIG['target_runtime_hours']*3600)} seconds\")\n",
    "\n",
    "# ============================================================================\n",
    "# LOAD ALL DATASETS\n",
    "# ============================================================================\n",
    "\n",
    "print(f\"\\n{'='*80}\")\n",
    "print(\"LOADING DATASETS\")\n",
    "print(f\"{'='*80}\")\n",
    "\n",
    "data_dir = Path(CONFIG['data_dir'])\n",
    "\n",
    "# Training challenges and solutions\n",
    "with open(data_dir / 'arc-agi_training_challenges.json') as f:\n",
    "    train_challenges = json.load(f)\n",
    "try:\n",
    "    with open(data_dir / 'arc-agi_training_solutions.json') as f:\n",
    "        train_solutions = json.load(f)\n",
    "except:\n",
    "    train_solutions = {}\n",
    "\n",
    "# Evaluation challenges and solutions\n",
    "try:\n",
    "    with open(data_dir / 'arc-agi_evaluation_challenges.json') as f:\n",
    "        eval_challenges = json.load(f)\n",
    "    with open(data_dir / 'arc-agi_evaluation_solutions.json') as f:\n",
    "        eval_solutions = json.load(f)\n",
    "except:\n",
    "    eval_challenges = {}\n",
    "    eval_solutions = {}\n",
    "\n",
    "# Test challenges (no solutions - this is what we predict)\n",
    "with open(data_dir / 'arc-agi_test_challenges.json') as f:\n",
    "    test_challenges = json.load(f)\n",
    "\n",
    "print(f\"‚úì Training tasks: {len(train_challenges)}\")\n",
    "print(f\"‚úì Evaluation tasks: {len(eval_challenges)}\")\n",
    "print(f\"‚úì Test tasks: {len(test_challenges)}\")\n",
    "\n",
    "# Prepare training pairs\n",
    "all_train_pairs = []\n",
    "for task_id, task_data in train_challenges.items():\n",
    "    for example in task_data.get('train', []):\n",
    "        all_train_pairs.append((example['input'], example['output']))\n",
    "\n",
    "print(f\"‚úì Total training pairs: {len(all_train_pairs)}\")\n",
    "print(f\"Time used: {format_time(time.time() - GLOBAL_START_TIME)}\")\n",
    "print(f\"Time remaining: {format_time(time_remaining())}\")\n",
    "\n",
    "# ============================================================================\n",
    "# ADAPTIVE TIME ALLOCATION\n",
    "# ============================================================================\n",
    "\n",
    "total_seconds = CONFIG['target_runtime_hours'] * 3600\n",
    "\n",
    "time_allocation = {\n",
    "    'training': 0.50,      # 50% = 3.5 hours for training\n",
    "    'eval_train': 0.10,    # 10% = 42 min for eval on train\n",
    "    'eval_eval': 0.10,     # 10% = 42 min for eval on eval set\n",
    "    'test_predict': 0.25,  # 25% = 1.75 hours for test predictions\n",
    "    'finalization': 0.05,  # 5% = 21 min for saving/validation\n",
    "}\n",
    "\n",
    "time_budgets = {k: int(v * total_seconds) for k, v in time_allocation.items()}\n",
    "\n",
    "print(f\"\\n{'='*80}\")\n",
    "print(\"TIME ALLOCATION\")\n",
    "print(f\"{'='*80}\")\n",
    "for phase, seconds in time_budgets.items():\n",
    "    print(f\"{phase:20s}: {format_time(seconds):>10s} ({time_allocation[phase]*100:.0f}%)\")\n",
    "\n",
    "# ============================================================================\n",
    "# PHASE 1: TRAINING (3.5 hours)\n",
    "# ============================================================================\n",
    "\n",
    "print(f\"\\n{'='*80}\")\n",
    "print(\"PHASE 1: TRAINING NEURAL COMPONENT\")\n",
    "print(f\"{'='*80}\")\n",
    "\n",
    "phase_start = time.time()\n",
    "phase_end = phase_start + time_budgets['training']\n",
    "\n",
    "model = None\n",
    "if CONFIG['do_training'] and should_continue():\n",
    "    model = ARCModel(\n",
    "        grid_size=CONFIG['grid_size'],\n",
    "        embed_dim=CONFIG['embed_dim'],\n",
    "        num_layers=CONFIG['num_layers'],\n",
    "        num_heads=CONFIG['num_heads'],\n",
    "        dropout=CONFIG['dropout']\n",
    "    ).to(DEVICE)\n",
    "    \n",
    "    total_params = sum(p.numel() for p in model.parameters())\n",
    "    print(f\"Model parameters: {total_params:,}\")\n",
    "    \n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr=CONFIG['learning_rate'], weight_decay=0.02)\n",
    "    \n",
    "    epoch = 0\n",
    "    best_loss = float('inf')\n",
    "    \n",
    "    print(f\"Training budget: {format_time(time_budgets['training'])}\")\n",
    "    print(f\"Starting training at {datetime.now().strftime('%H:%M:%S')}\")\n",
    "    \n",
    "    while time.time() < phase_end and epoch < CONFIG['max_epochs']:\n",
    "        model.train()\n",
    "        epoch_loss = 0\n",
    "        epoch_acc = 0\n",
    "        epoch_n = 0\n",
    "        \n",
    "        indices = np.random.permutation(len(all_train_pairs))[:min(1000, len(all_train_pairs))]\n",
    "        \n",
    "        for idx in indices:\n",
    "            if time.time() >= phase_end: break\n",
    "            \n",
    "            inp, out = all_train_pairs[idx]\n",
    "            x = torch.from_numpy(pad_grid_np(inp)).unsqueeze(0).to(DEVICE)\n",
    "            y = torch.from_numpy(pad_grid_np(out)).to(DEVICE)\n",
    "            \n",
    "            logits = model(x).squeeze(0)\n",
    "            loss = F.cross_entropy(logits.reshape(-1, model.num_colors), y.reshape(-1))\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "            optimizer.step()\n",
    "            \n",
    "            pred = logits.argmax(dim=-1)\n",
    "            acc = (pred == y).float().mean().item()\n",
    "            \n",
    "            epoch_loss += loss.item()\n",
    "            epoch_acc += acc\n",
    "            epoch_n += 1\n",
    "        \n",
    "        if epoch_n > 0:\n",
    "            avg_loss = epoch_loss / epoch_n\n",
    "            avg_acc = epoch_acc / epoch_n\n",
    "            if avg_loss < best_loss:\n",
    "                best_loss = avg_loss\n",
    "            \n",
    "            elapsed = time.time() - phase_start\n",
    "            remaining = phase_end - time.time()\n",
    "            print(f\"Epoch {epoch+1:3d} | Loss={avg_loss:.4f} | Acc={avg_acc:.3f} | \"\n",
    "                  f\"Time={format_time(elapsed)} | Remaining={format_time(remaining)}\")\n",
    "        \n",
    "        epoch += 1\n",
    "    \n",
    "    print(f\"\\n‚úì Training complete: {epoch} epochs\")\n",
    "    print(f\"  Best loss: {best_loss:.4f}\")\n",
    "    print(f\"  Time used: {format_time(time.time() - phase_start)}\")\n",
    "else:\n",
    "    print(\"Skipping training (disabled or time budget exceeded)\")\n",
    "\n",
    "# ============================================================================\n",
    "# PHASE 2: EVALUATE ON TRAINING CHALLENGES (42 min)\n",
    "# ============================================================================\n",
    "\n",
    "print(f\"\\n{'='*80}\")\n",
    "print(\"PHASE 2: EVALUATE ON TRAINING CHALLENGES\")\n",
    "print(f\"{'='*80}\")\n",
    "\n",
    "phase_start = time.time()\n",
    "phase_end = phase_start + time_budgets['eval_train']\n",
    "\n",
    "train_correct = 0\n",
    "train_total = 0\n",
    "\n",
    "if should_continue():\n",
    "    sample_tasks = list(train_challenges.items())[:min(50, len(train_challenges))]\n",
    "    \n",
    "    for task_id, task_data in sample_tasks:\n",
    "        if time.time() >= phase_end: break\n",
    "        \n",
    "        if 'test' not in task_data or not task_data['test']: continue\n",
    "        \n",
    "        task = {'train': task_data.get('train', []), 'test': task_data['test']}\n",
    "        attempt_1, attempt_2 = solve_task_hybrid(task, CONFIG)\n",
    "        \n",
    "        if task_id in train_solutions:\n",
    "            target = train_solutions[task_id][0]\n",
    "            if grids_equal(attempt_1, target) or grids_equal(attempt_2, target):\n",
    "                train_correct += 1\n",
    "        train_total += 1\n",
    "    \n",
    "    if train_total > 0:\n",
    "        accuracy = train_correct / train_total\n",
    "        print(f\"‚úì Training accuracy: {train_correct}/{train_total} = {accuracy*100:.1f}%\")\n",
    "    else:\n",
    "        print(\"No training tasks evaluated\")\n",
    "\n",
    "print(f\"Time used: {format_time(time.time() - phase_start)}\")\n",
    "\n",
    "# ============================================================================\n",
    "# PHASE 3: EVALUATE ON EVALUATION SET (42 min)\n",
    "# ============================================================================\n",
    "\n",
    "print(f\"\\n{'='*80}\")\n",
    "print(\"PHASE 3: EVALUATE ON EVALUATION SET\")\n",
    "print(f\"{'='*80}\")\n",
    "\n",
    "phase_start = time.time()\n",
    "phase_end = phase_start + time_budgets['eval_eval']\n",
    "\n",
    "eval_correct = 0\n",
    "eval_total = 0\n",
    "eval_predictions = {}\n",
    "\n",
    "if should_continue() and eval_challenges:\n",
    "    for task_id, task_data in eval_challenges.items():\n",
    "        if time.time() >= phase_end: break\n",
    "        \n",
    "        if 'test' not in task_data or not task_data['test']: continue\n",
    "        \n",
    "        task = {'train': task_data.get('train', []), 'test': task_data['test']}\n",
    "        attempt_1, attempt_2 = solve_task_hybrid(task, CONFIG)\n",
    "        \n",
    "        eval_predictions[task_id] = [\n",
    "            {'attempt_1': attempt_1, 'attempt_2': attempt_2}\n",
    "        ]\n",
    "        \n",
    "        if task_id in eval_solutions:\n",
    "            target = eval_solutions[task_id][0]\n",
    "            if grids_equal(attempt_1, target) or grids_equal(attempt_2, target):\n",
    "                eval_correct += 1\n",
    "        eval_total += 1\n",
    "        \n",
    "        if eval_total % 20 == 0:\n",
    "            print(f\"  Progress: {eval_total}/{len(eval_challenges)} tasks\")\n",
    "    \n",
    "    if eval_total > 0:\n",
    "        accuracy = eval_correct / eval_total\n",
    "        print(f\"\\n‚úì Evaluation accuracy: {eval_correct}/{eval_total} = {accuracy*100:.1f}%\")\n",
    "    else:\n",
    "        print(\"No evaluation tasks completed\")\n",
    "    \n",
    "    # Save eval predictions\n",
    "    try:\n",
    "        with open('/kaggle/working/eval_predictions.json', 'w') as f:\n",
    "            json.dump(eval_predictions, f)\n",
    "        print(\"‚úì Saved eval_predictions.json\")\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "print(f\"Time used: {format_time(time.time() - phase_start)}\")\n",
    "\n",
    "# ============================================================================\n",
    "# PHASE 4: GENERATE TEST PREDICTIONS (1.75 hours)\n",
    "# ============================================================================\n",
    "\n",
    "print(f\"\\n{'='*80}\")\n",
    "print(\"PHASE 4: GENERATE TEST PREDICTIONS\")\n",
    "print(f\"{'='*80}\")\n",
    "\n",
    "phase_start = time.time()\n",
    "phase_end = phase_start + time_budgets['test_predict']\n",
    "\n",
    "submission = []\n",
    "diverse_count = 0\n",
    "total_tasks = len(test_challenges)\n",
    "\n",
    "print(f\"Total test tasks: {total_tasks}\")\n",
    "print(f\"Time budget: {format_time(time_budgets['test_predict'])}\")\n",
    "\n",
    "for i, (task_id, task_data) in enumerate(test_challenges.items(), 1):\n",
    "    if time.time() >= phase_end:\n",
    "        print(f\"\\n‚ö†Ô∏è Time limit reached at task {i}/{total_tasks}\")\n",
    "        # Fill remaining with fallback\n",
    "        for remaining_id, remaining_data in list(test_challenges.items())[i-1:]:\n",
    "            test_inp = remaining_data['test'][0]['input']\n",
    "            fallback = validate_grid(test_inp)\n",
    "            submission.append({\n",
    "                'task_id': remaining_id,\n",
    "                'attempt_1': fallback,\n",
    "                'attempt_2': fallback\n",
    "            })\n",
    "        break\n",
    "    \n",
    "    task = {'train': task_data.get('train', []), 'test': task_data['test']}\n",
    "    attempt_1, attempt_2 = solve_task_hybrid(task, CONFIG)\n",
    "    \n",
    "    if not grids_equal(attempt_1, attempt_2):\n",
    "        diverse_count += 1\n",
    "    \n",
    "    submission.append({\n",
    "        'task_id': task_id,\n",
    "        'attempt_1': validate_grid(attempt_1),\n",
    "        'attempt_2': validate_grid(attempt_2)\n",
    "    })\n",
    "    \n",
    "    if i % 20 == 0 or i == total_tasks:\n",
    "        elapsed = time.time() - phase_start\n",
    "        remaining = phase_end - time.time()\n",
    "        rate = i / elapsed if elapsed > 0 else 0\n",
    "        eta = (total_tasks - i) / rate if rate > 0 else 0\n",
    "        print(f\"  [{i:3d}/{total_tasks}] Diverse: {diverse_count} ({100*diverse_count/i:.0f}%) | \"\n",
    "              f\"Rate: {rate:.1f} task/s | ETA: {format_time(eta)}\")\n",
    "\n",
    "print(f\"\\n‚úì Test predictions complete: {len(submission)} tasks\")\n",
    "print(f\"  Diverse attempts: {diverse_count}/{len(submission)} ({100*diverse_count/max(1,len(submission)):.1f}%)\")\n",
    "print(f\"Time used: {format_time(time.time() - phase_start)}\")\n",
    "\n",
    "# ============================================================================\n",
    "# PHASE 5: VALIDATION AND SAVING (21 min)\n",
    "# ============================================================================\n",
    "\n",
    "print(f\"\\n{'='*80}\")\n",
    "print(\"PHASE 5: VALIDATION AND SAVING\")\n",
    "print(f\"{'='*80}\")\n",
    "\n",
    "phase_start = time.time()\n",
    "\n",
    "# Validate submission format\n",
    "print(\"Validating submission...\")\n",
    "validation_passed = True\n",
    "issues = []\n",
    "\n",
    "for entry in submission:\n",
    "    if 'task_id' not in entry:\n",
    "        issues.append(\"Missing task_id\")\n",
    "        validation_passed = False\n",
    "    if 'attempt_1' not in entry or 'attempt_2' not in entry:\n",
    "        issues.append(f\"Missing attempts for {entry.get('task_id', 'unknown')}\")\n",
    "        validation_passed = False\n",
    "    \n",
    "    for key in ['attempt_1', 'attempt_2']:\n",
    "        if key in entry:\n",
    "            grid = entry[key]\n",
    "            if not grid or not grid[0]:\n",
    "                issues.append(f\"Empty grid in {key} for {entry.get('task_id', 'unknown')}\")\n",
    "            else:\n",
    "                for row in grid:\n",
    "                    for cell in row:\n",
    "                        if not (0 <= cell <= 9):\n",
    "                            issues.append(f\"Invalid color {cell} in {key}\")\n",
    "                            validation_passed = False\n",
    "                            break\n",
    "\n",
    "if validation_passed:\n",
    "    print(\"‚úì Validation passed\")\n",
    "else:\n",
    "    print(f\"‚ö†Ô∏è Validation issues found: {len(issues)}\")\n",
    "    for issue in issues[:5]:\n",
    "        print(f\"  - {issue}\")\n",
    "\n",
    "# Save submission\n",
    "print(\"\\nSaving submission.json...\")\n",
    "\n",
    "try:\n",
    "    os.makedirs('/kaggle/working', exist_ok=True)\n",
    "    with open(CONFIG['output_working'], 'w') as f:\n",
    "        json.dump(submission, f, separators=(',', ':'))\n",
    "    size_working = os.path.getsize(CONFIG['output_working']) / 1024\n",
    "    print(f\"‚úì Saved to {CONFIG['output_working']} ({size_working:.1f} KB)\")\n",
    "except Exception as e:\n",
    "    print(f\"‚úó Error saving to working: {e}\")\n",
    "\n",
    "try:\n",
    "    os.makedirs('/kaggle/output', exist_ok=True)\n",
    "    with open(CONFIG['output_final'], 'w') as f:\n",
    "        json.dump(submission, f, separators=(',', ':'))\n",
    "    size_final = os.path.getsize(CONFIG['output_final']) / 1024\n",
    "    print(f\"‚úì Saved to {CONFIG['output_final']} ({size_final:.1f} KB)\")\n",
    "except Exception as e:\n",
    "    print(f\"‚úó Error saving to output: {e}\")\n",
    "\n",
    "print(f\"\\nTime used: {format_time(time.time() - phase_start)}\")\n",
    "\n",
    "# ============================================================================\n",
    "# FINAL SUMMARY\n",
    "# ============================================================================\n",
    "\n",
    "total_runtime = time.time() - GLOBAL_START_TIME\n",
    "\n",
    "print(f\"\\n{'='*80}\")\n",
    "print(\"üéâ COMPLETE - READY FOR SUBMISSION\")\n",
    "print(f\"{'='*80}\")\n",
    "print(f\"\\nTotal runtime: {format_time(total_runtime)}\")\n",
    "print(f\"Target runtime: {format_time(CONFIG['target_runtime_hours']*3600)}\")\n",
    "print(f\"Efficiency: {(total_runtime/(CONFIG['target_runtime_hours']*3600))*100:.1f}%\")\n",
    "\n",
    "print(f\"\\nResults:\")\n",
    "if 'train_correct' in locals():\n",
    "    print(f\"  Training eval: {train_correct}/{train_total} ({100*train_correct/max(1,train_total):.1f}%)\")\n",
    "if 'eval_correct' in locals():\n",
    "    print(f\"  Evaluation: {eval_correct}/{eval_total} ({100*eval_correct/max(1,eval_total):.1f}%)\")\n",
    "print(f\"  Test tasks: {len(submission)}\")\n",
    "print(f\"  Diverse attempts: {diverse_count}/{len(submission)} ({100*diverse_count/max(1,len(submission)):.1f}%)\")\n",
    "\n",
    "print(f\"\\nFiles created:\")\n",
    "print(f\"  ‚úì {CONFIG['output_working']}\")\n",
    "print(f\"  ‚úì {CONFIG['output_final']}\")\n",
    "if eval_predictions:\n",
    "    print(f\"  ‚úì /kaggle/working/eval_predictions.json\")\n",
    "\n",
    "print(f\"\\n{'='*80}\")\n",
    "print(\"üì§ READY FOR KAGGLE SUBMISSION!\")\n",
    "print(f\"{'='*80}\")\n",
    "print(f\"\\nDownload: {CONFIG['output_working']}\")\n",
    "print(f\"Format: List of {{task_id, attempt_1, attempt_2}}\")\n",
    "print(f\"Tasks: {len(submission)}\")\n",
    "print(f\"Status: {'‚úÖ VALID' if validation_passed else '‚ö†Ô∏è CHECK ISSUES'}\")\n",
    "print(f\"\\nüêã ORCA ONE-CLICK COMPLETE! üéâ\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.7.12"
  },
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [{
    "sourceId": 91496,
    "databundleVersionId": 11802066,
    "sourceType": "competition"
   }],
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook",
   "isGpuEnabled": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
