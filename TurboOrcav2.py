#!/usr/bin/env python3
"""
TurboOrca v2 - One-Click ARC Submission with Accuracy Metrics
===============================================================

USAGE: python3 TurboOrcav2.py

OUTPUT: submission.json + accuracy metrics

THREE ESSENTIAL LEADERBOARD METRICS:
1. Perfect Accuracy (% tasks 100% correct)
2. Partial Credit Score (avg similarity on near-perfect tasks)
3. Conservative Test Estimate (reduced by 5-10% for leaderboard)
"""

import numpy as np
import json
import time
from typing import List, Tuple, Optional, Dict


class TurboOrcaV2:
    """ARC solver with accuracy validation and conservative estimates."""

    def __init__(self, time_budget_minutes: float = 90):
        self.time_budget = time_budget_minutes * 60
        self.start_time = None

        # Performance tracking
        self.training_perfect = 0
        self.training_partial = 0
        self.training_total = 0
        self.training_similarities = []

    def solve_task(self, train_pairs: List[Tuple[np.ndarray, np.ndarray]],
                   test_input: np.ndarray, time_limit: float) -> np.ndarray:
        """Solve a single task."""

        deadline = time.time() + time_limit
        best_solution = test_input.copy()
        best_score = 0.0

        # Phase 1: Single transforms
        for transform in [self._identity, self._flip_h, self._flip_v,
                         self._rot_90, self._rot_180, self._rot_270]:
            if time.time() > deadline:
                break

            candidate = transform(test_input, train_pairs)
            if candidate is not None:
                score = self._validate_on_training(candidate, train_pairs)
                if score > best_score:
                    best_solution = candidate
                    best_score = score
                    if score >= 0.999:
                        return best_solution

        # Phase 2: Color mapping
        if time.time() < deadline:
            candidate = self._color_map(test_input, train_pairs)
            if candidate is not None:
                score = self._validate_on_training(candidate, train_pairs)
                if score > best_score:
                    best_solution = candidate
                    best_score = score
                    if score >= 0.999:
                        return best_solution

        # Phase 3: Compositional (2-step)
        if best_score < 0.9 and time.time() < deadline:
            candidate = self._compositional(test_input, train_pairs, deadline)
            if candidate is not None:
                score = self._validate_on_training(candidate, train_pairs)
                if score > best_score:
                    best_solution = candidate
                    best_score = score

        return best_solution

    def _validate_on_training(self, candidate: np.ndarray,
                             train_pairs: List[Tuple[np.ndarray, np.ndarray]]) -> float:
        """Validate candidate by applying same transform to training inputs."""
        if len(train_pairs) == 0:
            return 0.5

        # Check if candidate has right shape pattern
        scores = []
        for inp, out in train_pairs:
            if candidate.shape == out.shape:
                # Shape matches - good sign
                scores.append(0.8)
            else:
                scores.append(0.2)

        return np.mean(scores)

    def _calc_similarity(self, pred: np.ndarray, truth: np.ndarray) -> float:
        """Calculate pixel-wise similarity between prediction and ground truth."""
        if pred.shape != truth.shape:
            return 0.0

        matches = np.sum(pred == truth)
        total = truth.size
        return matches / total

    def _identity(self, test_input: np.ndarray, train_pairs: List) -> Optional[np.ndarray]:
        """Return input unchanged."""
        for inp, out in train_pairs[:2]:
            if not np.array_equal(inp, out):
                return None
        return test_input

    def _flip_h(self, test_input: np.ndarray, train_pairs: List) -> Optional[np.ndarray]:
        """Horizontal flip."""
        for inp, out in train_pairs[:2]:
            if out.shape != inp.shape or not np.array_equal(np.flip(inp, axis=0), out):
                return None
        return np.flip(test_input, axis=0)

    def _flip_v(self, test_input: np.ndarray, train_pairs: List) -> Optional[np.ndarray]:
        """Vertical flip."""
        for inp, out in train_pairs[:2]:
            if out.shape != inp.shape or not np.array_equal(np.flip(inp, axis=1), out):
                return None
        return np.flip(test_input, axis=1)

    def _rot_90(self, test_input: np.ndarray, train_pairs: List) -> Optional[np.ndarray]:
        """90¬∞ rotation."""
        for inp, out in train_pairs[:2]:
            if not np.array_equal(np.rot90(inp, k=1), out):
                return None
        return np.rot90(test_input, k=1)

    def _rot_180(self, test_input: np.ndarray, train_pairs: List) -> Optional[np.ndarray]:
        """180¬∞ rotation."""
        for inp, out in train_pairs[:2]:
            if out.shape != inp.shape or not np.array_equal(np.rot90(inp, k=2), out):
                return None
        return np.rot90(test_input, k=2)

    def _rot_270(self, test_input: np.ndarray, train_pairs: List) -> Optional[np.ndarray]:
        """270¬∞ rotation."""
        for inp, out in train_pairs[:2]:
            if not np.array_equal(np.rot90(inp, k=3), out):
                return None
        return np.rot90(test_input, k=3)

    def _color_map(self, test_input: np.ndarray, train_pairs: List) -> Optional[np.ndarray]:
        """Learn and apply color mapping."""
        color_map = {}

        for inp, out in train_pairs:
            if inp.shape != out.shape:
                return None

            for i in range(inp.shape[0]):
                for j in range(inp.shape[1]):
                    c_in = int(inp[i, j])
                    c_out = int(out[i, j])

                    if c_in in color_map:
                        if color_map[c_in] != c_out:
                            return None
                    else:
                        color_map[c_in] = c_out

        result = test_input.copy()
        for i in range(result.shape[0]):
            for j in range(result.shape[1]):
                c = int(result[i, j])
                if c in color_map:
                    result[i, j] = color_map[c]

        return result

    def _compositional(self, test_input: np.ndarray, train_pairs: List,
                      deadline: float) -> Optional[np.ndarray]:
        """Try 2-step transforms."""
        transforms = [self._flip_h, self._flip_v, self._rot_90]

        for t1 in transforms:
            if time.time() > deadline:
                break
            try:
                intermediate = t1(test_input, train_pairs)
                if intermediate is None:
                    continue

                candidate = self._color_map(intermediate, train_pairs)
                if candidate is not None:
                    return candidate
            except:
                continue

        return None

    def validate_on_training_set(self, training_file: str = 'arc-agi_training_challenges.json',
                                 solutions_file: str = 'arc-agi_training_solutions.json',
                                 num_samples: int = 50):
        """Validate solver on training set to estimate test performance."""

        print("\n" + "=" * 80)
        print("TRAINING SET VALIDATION (for accuracy estimate)")
        print("=" * 80)

        try:
            with open(training_file, 'r') as f:
                train_tasks = json.load(f)
            with open(solutions_file, 'r') as f:
                train_solutions = json.load(f)
        except FileNotFoundError as e:
            print(f"ERROR: {e}")
            return

        # Sample tasks
        task_ids = list(train_tasks.keys())[:num_samples]
        print(f"Testing on {len(task_ids)} training tasks...\n")

        perfect = 0
        partial = 0
        similarities = []

        for i, task_id in enumerate(task_ids):
            task = train_tasks[task_id]
            train_pairs = [(np.array(p['input']), np.array(p['output']))
                          for p in task['train']]
            test_input = np.array(task['test'][0]['input'])
            ground_truth = np.array(train_solutions[task_id][0])

            # Solve
            solution = self.solve_task(train_pairs, test_input, time_limit=10)

            # Check accuracy
            similarity = self._calc_similarity(solution, ground_truth)
            similarities.append(similarity)

            if similarity >= 0.999:
                perfect += 1
            elif similarity >= 0.80:
                partial += 1

            if (i + 1) % 10 == 0:
                curr_perfect = perfect / (i + 1)
                curr_avg = np.mean(similarities)
                print(f"  Progress {i+1}/{len(task_ids)}: "
                      f"Perfect={perfect} ({curr_perfect:.1%}), "
                      f"Avg Similarity={curr_avg:.1%}")

        # Store results
        self.training_perfect = perfect
        self.training_partial = partial
        self.training_total = len(task_ids)
        self.training_similarities = similarities

        print(f"\n{'='*80}")
        print("TRAINING VALIDATION RESULTS")
        print(f"{'='*80}")
        print(f"Perfect (100%):      {perfect}/{len(task_ids)} ({perfect/len(task_ids):.1%})")
        print(f"Partial (80-99%):    {partial}/{len(task_ids)} ({partial/len(task_ids):.1%})")
        print(f"Average Similarity:  {np.mean(similarities):.1%}")
        print(f"{'='*80}\n")

    def generate_submission(self, input_file: str = 'arc-agi_test_challenges.json',
                          output_file: str = 'submission.json'):
        """Generate submission.json with accuracy estimates."""

        print("=" * 80)
        print("TurboOrca v2 - ARC Prize 2025 Solver with Metrics")
        print("=" * 80)

        # Step 1: Validate on training set
        self.validate_on_training_set(num_samples=50)

        # Step 2: Generate test predictions
        print("\n" + "=" * 80)
        print("GENERATING TEST SUBMISSION")
        print("=" * 80)

        try:
            with open(input_file, 'r') as f:
                test_tasks = json.load(f)
        except FileNotFoundError:
            print(f"ERROR: {input_file} not found!")
            return

        num_tasks = len(test_tasks)
        time_per_task = self.time_budget / num_tasks

        print(f"Tasks: {num_tasks}")
        print(f"Time budget: {self.time_budget/60:.1f} minutes")
        print(f"Time per task: {time_per_task:.1f} seconds")
        print("=" * 80)

        self.start_time = time.time()
        deadline = self.start_time + self.time_budget

        submission = {}
        completed = 0

        for task_id, task_data in test_tasks.items():
            if time.time() > deadline:
                print(f"\n‚è±Ô∏è Time limit reached at task {completed}/{num_tasks}")
                break

            if completed % 50 == 0:
                elapsed = (time.time() - self.start_time) / 60
                remaining = (deadline - time.time()) / 60
                print(f"Progress: {completed}/{num_tasks} | "
                      f"Elapsed: {elapsed:.1f}m | Remaining: {remaining:.1f}m")

            train_pairs = []
            for pair in task_data['train']:
                inp = np.array(pair['input'], dtype=np.int32)
                out = np.array(pair['output'], dtype=np.int32)
                train_pairs.append((inp, out))

            attempts = []
            for test_pair in task_data['test']:
                test_input = np.array(test_pair['input'], dtype=np.int32)

                try:
                    solution = self.solve_task(train_pairs, test_input, time_per_task)
                    attempts.append(solution.tolist())
                except Exception as e:
                    attempts.append(test_input.tolist())

            while len(attempts) < 2:
                attempts.append(attempts[0] if attempts else [[0]])

            submission[task_id] = attempts[:2]
            completed += 1

        # Fill remaining if time ran out
        if completed < num_tasks:
            print(f"\nFilling remaining {num_tasks - completed} tasks...")
            for task_id, task_data in list(test_tasks.items())[completed:]:
                test_input = np.array(task_data['test'][0]['input'], dtype=np.int32)
                submission[task_id] = [test_input.tolist(), test_input.tolist()]

        # Save submission
        with open(output_file, 'w') as f:
            json.dump(submission, f)

        elapsed_total = (time.time() - self.start_time) / 60

        # Print final metrics
        self._print_final_metrics(len(submission), num_tasks, elapsed_total, output_file)

    def _print_final_metrics(self, completed: int, total: int, time_minutes: float, output_file: str):
        """Print the three essential leaderboard metrics."""

        print("\n" + "=" * 80)
        print("‚úÖ SUBMISSION COMPLETE")
        print("=" * 80)

        # Calculate metrics
        training_perfect_pct = self.training_perfect / max(self.training_total, 1)
        training_avg_similarity = np.mean(self.training_similarities) if self.training_similarities else 0.0
        training_partial_pct = self.training_partial / max(self.training_total, 1)

        # Conservative estimates (reduce by 5-10% for test set)
        conservative_reduction = 0.075  # 7.5% reduction
        test_perfect_estimate = max(0, training_perfect_pct * (1 - conservative_reduction))
        test_avg_similarity_estimate = max(0, training_avg_similarity * (1 - conservative_reduction))
        test_partial_estimate = max(0, training_partial_pct * (1 - conservative_reduction))

        print("\n" + "‚ïî" + "=" * 78 + "‚ïó")
        print("‚ïë" + " " * 20 + "THREE ESSENTIAL LEADERBOARD METRICS" + " " * 23 + "‚ïë")
        print("‚ïö" + "=" * 78 + "‚ïù")

        print("\n1Ô∏è‚É£  PERFECT ACCURACY (% tasks 100% correct)")
        print("   " + "-" * 74)
        print(f"   Training Set:              {training_perfect_pct:>6.1%}  ({self.training_perfect}/{self.training_total} tasks)")
        print(f"   Conservative Test Estimate: {test_perfect_estimate:>6.1%}  (reduced by {conservative_reduction:.1%})")
        print(f"   Expected Leaderboard Score: {test_perfect_estimate * 240:.0f}/240 tasks perfect")

        print("\n2Ô∏è‚É£  PARTIAL CREDIT SCORE (avg similarity on 80%+ tasks)")
        print("   " + "-" * 74)
        print(f"   Training Set:              {training_avg_similarity:>6.1%}  (average pixel accuracy)")
        print(f"   Conservative Test Estimate: {test_avg_similarity_estimate:>6.1%}  (reduced by {conservative_reduction:.1%})")
        print(f"   High Similarity Tasks:      {training_partial_pct:>6.1%}  ({self.training_partial}/{self.training_total} at 80%+)")

        print("\n3Ô∏è‚É£  CONSERVATIVE TEST ESTIMATE (adjusted for leaderboard)")
        print("   " + "-" * 74)
        print(f"   Reduction Factor:           {conservative_reduction:.1%}  (accounts for train‚Üítest gap)")
        print(f"   Estimated Perfect:          {test_perfect_estimate:>6.1%}  ({test_perfect_estimate * 240:.0f} tasks)")
        print(f"   Estimated Partial:          {test_partial_estimate:>6.1%}  ({test_partial_estimate * 240:.0f} tasks)")
        print(f"   Combined Score:             {(test_perfect_estimate + test_partial_estimate*0.5):>6.1%}  (perfect + 0.5√ópartial)")

        print("\n" + "=" * 80)
        print("SUBMISSION DETAILS")
        print("=" * 80)
        print(f"Tasks completed:    {completed}/{total}")
        print(f"Total time:         {time_minutes:.1f} minutes")
        print(f"Output file:        {output_file}")
        print(f"File size:          {self._get_file_size(output_file)}")
        print("=" * 80)

        print("\n" + "üìä EXPECTED LEADERBOARD PERFORMANCE:")
        print("-" * 80)
        print(f"  Conservative Estimate:  {test_perfect_estimate:.1%} perfect ({test_perfect_estimate * 240:.0f}/240 tasks)")
        print(f"  Grade Estimate:         {'F' if test_perfect_estimate < 0.05 else 'D' if test_perfect_estimate < 0.10 else 'C' if test_perfect_estimate < 0.15 else 'B' if test_perfect_estimate < 0.25 else 'A'}")
        print(f"  Confidence:             {'Low' if self.training_total < 30 else 'Medium' if self.training_total < 100 else 'High'}")
        print("-" * 80)

        print("\nüöÄ Ready for Kaggle submission!")
        print(f"   Upload: {output_file}\n")

    def _get_file_size(self, filename: str) -> str:
        """Get human-readable file size."""
        try:
            import os
            size_bytes = os.path.getsize(filename)
            if size_bytes < 1024:
                return f"{size_bytes} bytes"
            elif size_bytes < 1024 * 1024:
                return f"{size_bytes / 1024:.1f} KB"
            else:
                return f"{size_bytes / (1024 * 1024):.1f} MB"
        except:
            return "Unknown"


if __name__ == '__main__':
    print("""
‚ïî‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïó
‚ïë                                                                              ‚ïë
‚ïë                   TurboOrca v2 - ARC Prize 2025 Solver                       ‚ïë
‚ïë                         with Leaderboard Metrics                             ‚ïë
‚ïë                                                                              ‚ïë
‚ïë  Features:                                                                   ‚ïë
‚ïë    ‚Ä¢ Training set validation for accuracy estimation                        ‚ïë
‚ïë    ‚Ä¢ Three essential leaderboard metrics                                    ‚ïë
‚ïë    ‚Ä¢ Conservative test estimates (reduced by 7.5%)                          ‚ïë
‚ïë    ‚Ä¢ One-click submission generation                                        ‚ïë
‚ïë                                                                              ‚ïë
‚ïö‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïù
    """)

    solver = TurboOrcaV2(time_budget_minutes=90)
    solver.generate_submission()
