{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ü•É OrcaWhiskey v1: The Distillation\n",
    "\n",
    "**Three Minds, One Truth**\n",
    "\n",
    "A complete cognitive system for ARC-AGI combining:\n",
    "- **Agent A**: HRM-27M (Visual Pattern Reasoning)\n",
    "- **Agent B**: LLM-3.8B (Abstract Language Reasoning)  \n",
    "- **VAE Mediator**: 5M (2/3 Vote Arbitration)\n",
    "\n",
    "**With full epistemic reasoning:**\n",
    "- Induction + Deduction + Abstraction + Inference + Assumption + Reasoning\n",
    "- Skepticism + Doubt + Fear + Humility + Confidence\n",
    "\n",
    "**Distilled from:** v1-v6 failures, HRM research, brutal validation truth\n",
    "\n",
    "**Expected:** 45-55% accuracy (vs baseline ~5%, v5-Lite 0%, v6 0.4%)\n",
    "\n",
    "---\n",
    "\n",
    "**File Size Warning:** This notebook is ~800-900KB (4,200+ lines of code)\n",
    "\n",
    "**Training Time:** 6+ hours (3 phases: Individual ‚Üí Collaborative ‚Üí Adversarial)\n",
    "\n",
    "**Novel Insights:** Every line\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CELL 1: IMPORTS & CONFIGURATION\n",
    "# Lines: ~100\n",
    "# Purpose: Setup environment, logging, config\n",
    "\n",
    "import json\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch import optim\n",
    "import os\n",
    "import time\n",
    "import random\n",
    "from typing import Dict, List, Tuple, Optional, Callable, Any\n",
    "from dataclasses import dataclass, field\n",
    "from collections import Counter, defaultdict\n",
    "from datetime import datetime\n",
    "import math\n",
    "from pathlib import Path\n",
    "\n",
    "# Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import ListedColormap\n",
    "from IPython.display import display, HTML, clear_output\n",
    "\n",
    "# Set random seeds for reproducibility\n",
    "SEED = 42\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed(SEED)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "\n",
    "print(f\"ü•É OrcaWhiskey v1 Initialized | {datetime.now().strftime('%H:%M:%S')}\")\n",
    "print(f\"üî• Device: {torch.device('cuda' if torch.cuda.is_available() else 'cpu')}\")\n",
    "\n",
    "# Configuration\n",
    "@dataclass\n",
    "class OrcaWhiskeyConfig:\n",
    "    \"\"\"Global configuration for the entire system\"\"\"\n",
    "    \n",
    "    # Environment\n",
    "    is_kaggle: bool = os.path.exists('/kaggle/input')\n",
    "    device: str = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "    seed: int = 42\n",
    "    \n",
    "    # Data paths\n",
    "    train_challenges: str = '/kaggle/input/arc-prize-2025/arc-agi_training_challenges.json' if is_kaggle else 'arc-agi_training_challenges.json'\n",
    "    train_solutions: str = '/kaggle/input/arc-prize-2025/arc-agi_training_solutions.json' if is_kaggle else 'arc-agi_training_solutions.json'\n",
    "    test_challenges: str = '/kaggle/input/arc-prize-2025/arc-agi_test_challenges.json' if is_kaggle else 'data/arc-agi_test_challenges.json'\n",
    "    output_path: str = '/kaggle/working/submission.json' if is_kaggle else 'submission.json'\n",
    "    log_path: str = '/kaggle/working/orcawhiskey_log.txt' if is_kaggle else 'orcawhiskey_log.txt'\n",
    "    \n",
    "    # Model configs\n",
    "    hrm_hidden_size: int = 512\n",
    "    hrm_num_layers_h: int = 6  # High-level reasoning\n",
    "    hrm_num_layers_l: int = 6  # Low-level execution\n",
    "    hrm_num_heads: int = 8\n",
    "    hrm_h_cycles: int = 4  # High-level cycles\n",
    "    hrm_l_cycles: int = 8  # Low-level cycles\n",
    "    \n",
    "    llm_hidden_size: int = 3072  # Phi-3-mini size\n",
    "    llm_num_layers: int = 32\n",
    "    llm_num_heads: int = 32\n",
    "    llm_vocab_size: int = 32064\n",
    "    \n",
    "    vae_latent_dim: int = 128\n",
    "    vae_hidden_dim: int = 256\n",
    "    \n",
    "    # Training hyperparameters\n",
    "    batch_size: int = 16\n",
    "    learning_rate_hrm: float = 7e-5\n",
    "    learning_rate_llm: float = 5e-5\n",
    "    learning_rate_vae: float = 1e-4\n",
    "    weight_decay: float = 0.1\n",
    "    \n",
    "    # Training phases\n",
    "    phase1_epochs: int = 50   # Individual training\n",
    "    phase2_epochs: int = 100  # Collaborative training\n",
    "    phase3_epochs: int = 30   # Adversarial diversity\n",
    "    \n",
    "    # Epistemic parameters\n",
    "    max_confidence: float = 0.95  # Never 100% certain\n",
    "    min_confidence: float = 0.05\n",
    "    small_sample_penalty: float = 0.7  # Confidence penalty for <3 examples\n",
    "    unseen_feature_penalty: float = 0.8\n",
    "    \n",
    "    # Visualization\n",
    "    viz_every_n_batches: int = 10\n",
    "    arc_colors: List[str] = field(default_factory=lambda: [\n",
    "        \"#000000\",  # 0: Black\n",
    "        \"#0074D9\",  # 1: Blue\n",
    "        \"#FF4136\",  # 2: Red\n",
    "        \"#2ECC40\",  # 3: Green\n",
    "        \"#FFDC00\",  # 4: Yellow\n",
    "        \"#AAAAAA\",  # 5: Grey\n",
    "        \"#F012BE\",  # 6: Magenta\n",
    "        \"#FF851B\",  # 7: Orange\n",
    "        \"#7FDBFF\",  # 8: Cyan\n",
    "        \"#870C25\",  # 9: Maroon\n",
    "    ])\n",
    "    \n",
    "    # Grid parameters\n",
    "    max_grid_size: int = 30\n",
    "    vocab_size: int = 12  # 0-9 colors + padding + EOS\n",
    "\n",
    "config = OrcaWhiskeyConfig()\n",
    "\n",
    "print(f\"üìù Config loaded:\")\n",
    "print(f\"   Environment: {'Kaggle' if config.is_kaggle else 'Local'}\")\n",
    "print(f\"   Device: {config.device}\")\n",
    "print(f\"   HRM params: {config.hrm_hidden_size}d, {config.hrm_num_layers_h}H+{config.hrm_num_layers_l}L layers\")\n",
    "print(f\"   LLM params: {config.llm_hidden_size}d, {config.llm_num_layers} layers\")\n",
    "print(f\"   Training: Phase1({config.phase1_epochs}) + Phase2({config.phase2_epochs}) + Phase3({config.phase3_epochs})\")\n",
    "print(f\"   Total epochs: {config.phase1_epochs + config.phase2_epochs + config.phase3_epochs}\")\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CELL 2: DATA LOADING & ARC UTILITIES\n",
    "# Lines: ~200\n",
    "# Purpose: Load ARC data, grid utilities, dataset classes\n",
    "\n",
    "class ARCDataLoader:\n",
    "    \"\"\"Load and manage ARC-AGI dataset\"\"\"\n",
    "    \n",
    "    def __init__(self, config: OrcaWhiskeyConfig):\n",
    "        self.config = config\n",
    "        self.train_challenges = None\n",
    "        self.train_solutions = None\n",
    "        self.test_challenges = None\n",
    "        \n",
    "    def load_training_data(self) -> Tuple[Dict, Dict]:\n",
    "        \"\"\"Load training challenges and solutions\"\"\"\n",
    "        print(\"üìÇ Loading training data...\")\n",
    "        \n",
    "        with open(self.config.train_challenges, 'r') as f:\n",
    "            self.train_challenges = json.load(f)\n",
    "        \n",
    "        with open(self.config.train_solutions, 'r') as f:\n",
    "            self.train_solutions = json.load(f)\n",
    "        \n",
    "        print(f\"   ‚úÖ Loaded {len(self.train_challenges)} training tasks\")\n",
    "        return self.train_challenges, self.train_solutions\n",
    "    \n",
    "    def load_test_data(self) -> Dict:\n",
    "        \"\"\"Load test challenges\"\"\"\n",
    "        print(\"üìÇ Loading test data...\")\n",
    "        \n",
    "        with open(self.config.test_challenges, 'r') as f:\n",
    "            self.test_challenges = json.load(f)\n",
    "        \n",
    "        print(f\"   ‚úÖ Loaded {len(self.test_challenges)} test tasks\")\n",
    "        return self.test_challenges\n",
    "\n",
    "class GridUtils:\n",
    "    \"\"\"Utilities for grid manipulation and encoding\"\"\"\n",
    "    \n",
    "    @staticmethod\n",
    "    def pad_grid(grid: List[List[int]], max_size: int = 30, pad_value: int = 10) -> np.ndarray:\n",
    "        \"\"\"Pad grid to max_size x max_size\"\"\"\n",
    "        arr = np.array(grid)\n",
    "        h, w = arr.shape\n",
    "        \n",
    "        if h > max_size or w > max_size:\n",
    "            # Crop if too large\n",
    "            arr = arr[:max_size, :max_size]\n",
    "            h, w = arr.shape\n",
    "        \n",
    "        # Pad to max_size\n",
    "        padded = np.full((max_size, max_size), pad_value, dtype=np.int32)\n",
    "        padded[:h, :w] = arr\n",
    "        \n",
    "        return padded\n",
    "    \n",
    "    @staticmethod\n",
    "    def unpad_grid(grid: np.ndarray, pad_value: int = 10) -> np.ndarray:\n",
    "        \"\"\"Remove padding from grid\"\"\"\n",
    "        # Find actual content bounds\n",
    "        mask = (grid != pad_value)\n",
    "        if not mask.any():\n",
    "            return np.array([[0]])\n",
    "        \n",
    "        rows = np.any(mask, axis=1)\n",
    "        cols = np.any(mask, axis=0)\n",
    "        \n",
    "        return grid[rows][:, cols]\n",
    "    \n",
    "    @staticmethod\n",
    "    def encode_grid_flat(grid: List[List[int]], max_size: int = 30) -> np.ndarray:\n",
    "        \"\"\"Encode grid as flattened sequence\"\"\"\n",
    "        padded = GridUtils.pad_grid(grid, max_size)\n",
    "        return padded.flatten()\n",
    "    \n",
    "    @staticmethod\n",
    "    def decode_grid_flat(flat: np.ndarray, grid_size: int = 30) -> np.ndarray:\n",
    "        \"\"\"Decode flattened sequence back to grid\"\"\"\n",
    "        grid = flat.reshape(grid_size, grid_size)\n",
    "        return GridUtils.unpad_grid(grid)\n",
    "    \n",
    "    @staticmethod\n",
    "    def grid_to_text(grid: List[List[int]]) -> str:\n",
    "        \"\"\"Convert grid to text representation for LLM\"\"\"\n",
    "        arr = np.array(grid)\n",
    "        h, w = arr.shape\n",
    "        \n",
    "        text = f\"Grid {h}x{w}:\\n\"\n",
    "        for row in arr:\n",
    "            text += \" \".join(str(c) for c in row) + \"\\n\"\n",
    "        \n",
    "        return text\n",
    "    \n",
    "    @staticmethod\n",
    "    def text_to_grid(text: str) -> Optional[List[List[int]]]:\n",
    "        \"\"\"Parse text back to grid (for LLM output)\"\"\"\n",
    "        try:\n",
    "            lines = text.strip().split('\\n')\n",
    "            # Skip header line if present\n",
    "            if 'Grid' in lines[0]:\n",
    "                lines = lines[1:]\n",
    "            \n",
    "            grid = []\n",
    "            for line in lines:\n",
    "                if line.strip():\n",
    "                    row = [int(c) for c in line.split()]\n",
    "                    grid.append(row)\n",
    "            \n",
    "            return grid if grid else None\n",
    "        except:\n",
    "            return None\n",
    "\n",
    "class ARCDataset(Dataset):\n",
    "    \"\"\"PyTorch Dataset for ARC training\"\"\"\n",
    "    \n",
    "    def __init__(self, \n",
    "                 challenges: Dict, \n",
    "                 solutions: Dict,\n",
    "                 config: OrcaWhiskeyConfig):\n",
    "        self.challenges = challenges\n",
    "        self.solutions = solutions\n",
    "        self.config = config\n",
    "        self.task_ids = list(challenges.keys())\n",
    "    \n",
    "    def __len__(self) -> int:\n",
    "        return len(self.task_ids)\n",
    "    \n",
    "    def __getitem__(self, idx: int) -> Dict[str, Any]:\n",
    "        task_id = self.task_ids[idx]\n",
    "        task_data = self.challenges[task_id]\n",
    "        \n",
    "        # Training pairs\n",
    "        train_inputs = [pair['input'] for pair in task_data['train']]\n",
    "        train_outputs = [pair['output'] for pair in task_data['train']]\n",
    "        \n",
    "        # Test inputs and solutions\n",
    "        test_inputs = [pair['input'] for pair in task_data['test']]\n",
    "        test_solutions = self.solutions[task_id] if task_id in self.solutions else None\n",
    "        \n",
    "        return {\n",
    "            'task_id': task_id,\n",
    "            'train_inputs': train_inputs,\n",
    "            'train_outputs': train_outputs,\n",
    "            'test_inputs': test_inputs,\n",
    "            'test_solutions': test_solutions,\n",
    "            'num_train_pairs': len(train_inputs)\n",
    "        }\n",
    "\n",
    "# Initialize data loader\n",
    "data_loader = ARCDataLoader(config)\n",
    "grid_utils = GridUtils()\n",
    "\n",
    "print(\"‚úÖ Data utilities initialized\")\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "source": "# CELL 12: MAIN EXECUTION - ORCHESTRATE EVERYTHING\n# Lines: ~250\n# Purpose: Run complete pipeline with sanity checks\n\ndef run_sanity_checks():\n    \"\"\"\n    CRITICAL: Sanity checks before training (from AAR)\n    \n    Validates:\n    1. Forward pass works\n    2. Backward pass doesn't NaN\n    3. Bridge preserves information\n    4. VAE votes make sense\n    \"\"\"\n    print(\"\\n\" + \"=\"*60)\n    print(\"üîç RUNNING SANITY CHECKS\")\n    print(\"=\"*60 + \"\\n\")\n    \n    # Load one sample\n    challenges, solutions = data_loader.load_training_data()\n    task_id = list(challenges.keys())[0]\n    task = challenges[task_id]\n    \n    train_inputs = [pair['input'] for pair in task['train']]\n    train_outputs = [pair['output'] for pair in task['train']]\n    test_input = task['test'][0]['input']\n    target = solutions[task_id][0]\n    \n    print(f\"üìù Test task: {task_id}\")\n    print(f\"   Train pairs: {len(train_inputs)}\")\n    print(f\"   Test input shape: {len(test_input)}x{len(test_input[0])}\")\n    \n    # CHECK 1: Forward pass\n    print(\"\\n‚úì Check 1: Forward pass without errors...\")\n    try:\n        with torch.no_grad():\n            result_a = agent_a.forward(train_inputs, train_outputs, test_input)\n            result_b = agent_b.forward(train_inputs, train_outputs, test_input)\n            result_vae = vae_mediator.forward(\n                result_a['prediction'],\n                result_a['confidence'],\n                result_b['prediction'],\n                result_b['confidence']\n            )\n        print(\"   ‚úÖ All agents forward pass successful\")\n    except Exception as e:\n        print(f\"   ‚ùå FATAL: Forward pass failed: {e}\")\n        raise\n    \n    # CHECK 2: Backward pass without NaN\n    print(\"\\n‚úì Check 2: Backward pass without NaN...\")\n    try:\n        loss_a = agent_a.compute_loss(train_inputs, train_outputs, target)\n        loss_b = agent_b.compute_loss(train_inputs, train_outputs, target)\n        loss_vae = vae_mediator.compute_loss(\n            result_a['prediction'],\n            result_b['prediction'],\n            target\n        )\n        \n        total_loss = loss_a + loss_b + loss_vae\n        total_loss.backward()\n        \n        # Check for NaN\n        has_nan = False\n        for name, param in agent_a.named_parameters():\n            if param.grad is not None and torch.isnan(param.grad).any():\n                print(f\"   ‚ùå NaN gradient in agent_a.{name}\")\n                has_nan = True\n        \n        if not has_nan:\n            print(\"   ‚úÖ Backward pass clean (no NaN)\")\n        else:\n            raise ValueError(\"NaN gradients detected!\")\n            \n    except Exception as e:\n        print(f\"   ‚ùå FATAL: Backward pass failed: {e}\")\n        raise\n    \n    # CHECK 3: Bridge information preservation\n    print(\"\\n‚úì Check 3: Bridge preserves information...\")\n    try:\n        # Get HRM latent\n        with torch.no_grad():\n            result_a_full = agent_a.forward(train_inputs, train_outputs, test_input, return_traces=True)\n            hrm_latent = result_a_full['high_level_state']\n            \n            # Project to LLM space and back\n            llm_emb = orchestrator.bridge.hrm_to_llm_space(hrm_latent)\n            hrm_reconstructed = orchestrator.bridge.llm_to_hrm_space(llm_emb)\n            \n            # Measure reconstruction error\n            recon_error = F.mse_loss(hrm_latent, hrm_reconstructed).item()\n            \n            if recon_error < 0.5:\n                print(f\"   ‚úÖ Bridge reconstruction error: {recon_error:.4f} (good)\")\n            else:\n                print(f\"   ‚ö†Ô∏è  Bridge reconstruction error: {recon_error:.4f} (high - may be lossy)\")\n    except Exception as e:\n        print(f\"   ‚ö†Ô∏è  Bridge check failed: {e}\")\n    \n    # CHECK 4: VAE votes make sense\n    print(\"\\n‚úì Check 4: VAE voting logic...\")\n    try:\n        with torch.no_grad():\n            # Create synthetic cases\n            # Case 1: Agents agree\n            same_pred = [[1, 2], [3, 4]]\n            result_agree = vae_mediator.forward(same_pred, 0.8, same_pred, 0.8)\n            \n            if result_agree['agreement']:\n                print(f\"   ‚úÖ VAE detects agreement: {result_agree['decision']}\")\n            else:\n                print(f\"   ‚ö†Ô∏è  VAE should detect agreement but got: {result_agree['decision']}\")\n            \n            # Case 2: Agents disagree\n            diff_pred_a = [[1, 2], [3, 4]]\n            diff_pred_b = [[5, 6], [7, 8]]\n            result_disagree = vae_mediator.forward(diff_pred_a, 0.6, diff_pred_b, 0.7)\n            \n            if not result_disagree['agreement']:\n                print(f\"   ‚úÖ VAE detects disagreement: {result_disagree['decision']}\")\n            else:\n                print(f\"   ‚ö†Ô∏è  VAE should detect disagreement\")\n                \n    except Exception as e:\n        print(f\"   ‚ö†Ô∏è  VAE voting check failed: {e}\")\n    \n    print(\"\\n\" + \"=\"*60)\n    print(\"‚úÖ SANITY CHECKS COMPLETE\")\n    print(\"=\"*60 + \"\\n\")\n\n\ndef main(train_full: bool = True, run_phases: str = \"all\"):\n    \"\"\"\n    Main execution pipeline\n    \n    Args:\n        train_full: If True, train on full dataset. If False, use subset for testing.\n        run_phases: \"all\", \"phase1\", \"phase2\", \"phase3\", or \"eval_only\"\n    \"\"\"\n    print(\"\\n\" + \"=\"*80)\n    print(\"ü•É ORCAWHISKEY V1 - MAIN EXECUTION\")\n    print(\"=\"*80)\n    print(f\"Started: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n    print(f\"Device: {config.device}\")\n    print(f\"Training mode: {'Full dataset' if train_full else 'Subset (testing)'}\")\n    print(f\"Phases: {run_phases}\")\n    print(\"=\"*80 + \"\\n\")\n    \n    # Sanity checks\n    run_sanity_checks()\n    \n    # Load data\n    challenges, solutions = data_loader.load_training_data()\n    \n    # Create dataset\n    dataset = ARCDataset(challenges, solutions, config)\n    \n    # Subset for testing if needed\n    if not train_full:\n        dataset.task_ids = dataset.task_ids[:100]  # Use first 100 tasks\n        print(f\"‚ö†Ô∏è  Using subset: {len(dataset)} tasks\\n\")\n    \n    dataloader = DataLoader(dataset, batch_size=1, shuffle=True)\n    \n    # ==================================================\n    # TRAINING\n    # ==================================================\n    \n    if run_phases in [\"all\", \"phase1\"]:\n        trainer1 = Phase1Trainer(config)\n        metrics1 = trainer1.train(dataloader, visualize_every=10)\n    \n    if run_phases in [\"all\", \"phase2\"]:\n        trainer2 = Phase2Trainer(config)\n        metrics2 = trainer2.train(dataloader)\n    \n    if run_phases in [\"all\", \"phase3\"]:\n        trainer3 = Phase3Trainer(config)\n        metrics3 = trainer3.train(dataloader)\n    \n    # ==================================================\n    # EVALUATION\n    # ==================================================\n    \n    # Evaluate on training set\n    eval_results = evaluator.evaluate_training_set(dataset, num_samples=None)\n    \n    # Visualize samples\n    print(\"\\nüé® Visualizing sample predictions...\")\n    visualizer.show_sample_predictions(dataset, num_samples=3, verbose=False)\n    \n    # Generate test submission if test data exists\n    if os.path.exists(config.test_challenges):\n        test_challenges = data_loader.load_test_data()\n        submission = evaluator.generate_submission(test_challenges)\n        evaluator.save_submission(submission, config.output_path)\n    \n    # ==================================================\n    # FINAL SUMMARY\n    # ==================================================\n    \n    print(\"\\n\" + \"=\"*80)\n    print(\"üèÅ ORCAWHISKEY V1 - EXECUTION COMPLETE\")\n    print(\"=\"*80)\n    print(f\"Finished: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n    print(f\"\\nüìä FINAL RESULTS:\")\n    print(f\"   System Accuracy: {eval_results['accuracy']*100:.2f}%\")\n    print(f\"   Agent A Accuracy: {eval_results['accuracy_a']*100:.2f}%\")\n    print(f\"   Agent B Accuracy: {eval_results['accuracy_b']*100:.2f}%\")\n    print(f\"   Tasks Evaluated: {eval_results['total']}\")\n    print(f\"\\nüéØ Target: 45-55% accuracy\")\n    if eval_results['accuracy'] >= 0.45:\n        print(\"   ‚úÖ TARGET ACHIEVED!\")\n    else:\n        print(f\"   ‚ö†Ô∏è  Below target (delta: {(0.45 - eval_results['accuracy'])*100:.1f}%)\")\n    print(\"=\"*80 + \"\\n\")\n    \n    return eval_results\n\n\n# ==================================================\n# EXECUTION\n# ==================================================\n\nprint(\"üöÄ OrcaWhiskey v1 ready to run!\")\nprint(\"\\nTo execute:\")\nprint(\"   main(train_full=False, run_phases='all')  # Test run (100 tasks)\")\nprint(\"   main(train_full=True, run_phases='all')   # Full training\")\nprint(\"   main(train_full=True, run_phases='eval_only')  # Evaluation only\")\nprint(\"\\n\" + \"=\"*60)\nprint(\"‚ö†Ô∏è  REMINDER: This will take 6+ hours for full training\")\nprint(\"=\"*60 + \"\\n\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "# CELL 11: EVALUATION & SUBMISSION\n# Lines: ~300\n# Purpose: Generate predictions for test set and create submission.json\n\nclass Evaluator:\n    \"\"\"\n    Evaluate system and generate submission\n    \n    Submission format:\n    {\n      \"task_id\": {\n        \"attempt_1\": [[grid]],\n        \"attempt_2\": [[grid]]\n      },\n      ...\n    }\n    \"\"\"\n    \n    def __init__(self, config: OrcaWhiskeyConfig):\n        self.config = config\n        \n    def evaluate_training_set(self, dataset: ARCDataset, num_samples: Optional[int] = None) -> Dict[str, Any]:\n        \"\"\"\n        Evaluate on training set (where we have ground truth)\n        \"\"\"\n        print(\"\\n\" + \"=\"*60)\n        print(\"üìä EVALUATING ON TRAINING SET\")\n        print(\"=\"*60 + \"\\n\")\n        \n        agent_a.eval()\n        agent_b.eval()\n        vae_mediator.eval()\n        \n        total = 0\n        correct = 0\n        correct_a = 0\n        correct_b = 0\n        vae_decisions = defaultdict(int)\n        \n        samples = num_samples if num_samples else len(dataset)\n        \n        for i in range(min(samples, len(dataset))):\n            sample = dataset[i]\n            task_id = sample['task_id']\n            \n            # Solve\n            with torch.no_grad():\n                result = executor.execute(\n                    sample['train_inputs'],\n                    sample['train_outputs'],\n                    sample['test_inputs'][0],\n                    verbose=False\n                )\n            \n            prediction = result['prediction']\n            ground_truth = sample['test_solutions'][0] if sample['test_solutions'] else None\n            \n            if ground_truth is None:\n                continue\n            \n            # Check accuracy\n            if np.array_equal(prediction, ground_truth):\n                correct += 1\n            \n            if np.array_equal(result['result_a']['prediction'], ground_truth):\n                correct_a += 1\n            \n            if np.array_equal(result['result_b']['prediction'], ground_truth):\n                correct_b += 1\n            \n            vae_decisions[result['vae_result']['decision']] += 1\n            \n            total += 1\n            \n            if (i + 1) % 100 == 0:\n                print(f\"   Evaluated {i+1}/{samples} tasks | Accuracy: {correct/total*100:.1f}%\")\n        \n        accuracy = correct / max(total, 1)\n        accuracy_a = correct_a / max(total, 1)\n        accuracy_b = correct_b / max(total, 1)\n        \n        print(\"\\n\" + \"=\"*60)\n        print(\"üìà TRAINING SET RESULTS\")\n        print(\"=\"*60)\n        print(f\"Total tasks: {total}\")\n        print(f\"System Accuracy: {accuracy*100:.2f}% ({correct}/{total})\")\n        print(f\"Agent A Accuracy: {accuracy_a*100:.2f}% ({correct_a}/{total})\")\n        print(f\"Agent B Accuracy: {accuracy_b*100:.2f}% ({correct_b}/{total})\")\n        print(\"\\nVAE Decisions:\")\n        for decision, count in vae_decisions.items():\n            print(f\"   {decision}: {count} ({count/total*100:.1f}%)\")\n        print(\"=\"*60 + \"\\n\")\n        \n        return {\n            'accuracy': accuracy,\n            'accuracy_a': accuracy_a,\n            'accuracy_b': accuracy_b,\n            'correct': correct,\n            'total': total,\n            'vae_decisions': dict(vae_decisions)\n        }\n    \n    def generate_submission(self, test_challenges: Dict) -> Dict[str, Any]:\n        \"\"\"\n        Generate submission for test set\n        \"\"\"\n        print(\"\\n\" + \"=\"*60)\n        print(\"üöÄ GENERATING TEST PREDICTIONS\")\n        print(\"=\"*60 + \"\\n\")\n        \n        agent_a.eval()\n        agent_b.eval()\n        vae_mediator.eval()\n        \n        submission = {}\n        \n        for task_id, task_data in test_challenges.items():\n            train_inputs = [pair['input'] for pair in task_data['train']]\n            train_outputs = [pair['output'] for pair in task_data['train']]\n            test_inputs = [pair['input'] for pair in task_data['test']]\n            \n            task_predictions = []\n            \n            for test_input in test_inputs:\n                # Generate prediction\n                with torch.no_grad():\n                    result = executor.execute(\n                        train_inputs,\n                        train_outputs,\n                        test_input,\n                        verbose=False\n                    )\n                \n                task_predictions.append(result['prediction'])\n            \n            # Submission format: attempt_1 and attempt_2 (same for now)\n            submission[task_id] = {\n                'attempt_1': task_predictions,\n                'attempt_2': task_predictions  # Could use agent_a or agent_b here for diversity\n            }\n            \n            if len(submission) % 10 == 0:\n                print(f\"   Generated predictions for {len(submission)} tasks...\")\n        \n        print(f\"\\n‚úÖ Generated predictions for {len(submission)} tasks\")\n        print(\"=\"*60 + \"\\n\")\n        \n        return submission\n    \n    def save_submission(self, submission: Dict, path: str):\n        \"\"\"Save submission to JSON\"\"\"\n        with open(path, 'w') as f:\n            json.dump(submission, f, indent=2)\n        \n        print(f\"üíæ Submission saved to: {path}\")\n        \n        # Check file size\n        file_size = os.path.getsize(path) / (1024 * 1024)  # MB\n        print(f\"   File size: {file_size:.2f} MB\")\n\n\n# Initialize evaluator\nevaluator = Evaluator(config)\n\nprint(\"üìä Evaluator initialized\")\nprint(\"   Training eval: accuracy, per-agent breakdown, VAE decisions\")\nprint(\"   Test prediction: attempt_1 and attempt_2 for each task\")\nprint(\"   Output format: ARC submission JSON\")\nprint()",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "# CELL 10: TRAINING PHASES 2-3 - COLLABORATIVE & ADVERSARIAL\n# Lines: ~500\n# Purpose: Train agents to work together, then diversify\n\nclass Phase2Trainer:\n    \"\"\"\n    Phase 2: Collaborative Training (100 epochs)\n    \n    Train agents + VAE together:\n    - Agents collaborate via observation protocol\n    - VAE learns to arbitrate\n    - Reward if EITHER agent correct (collaborative reward)\n    \"\"\"\n    \n    def __init__(self, config: OrcaWhiskeyConfig):\n        self.config = config\n        \n        # Optimizers (all three components now)\n        self.opt_a = optim.AdamW(agent_a.parameters(), lr=config.learning_rate_hrm * 0.5, weight_decay=config.weight_decay)\n        self.opt_b = optim.AdamW(agent_b.parameters(), lr=config.learning_rate_llm * 0.5, weight_decay=config.weight_decay)\n        self.opt_vae = optim.AdamW(vae_mediator.parameters(), lr=config.learning_rate_vae, weight_decay=config.weight_decay)\n        self.opt_bridge = optim.AdamW(orchestrator.bridge.parameters(), lr=1e-4, weight_decay=config.weight_decay)\n        \n        # Schedulers\n        self.sched_a = optim.lr_scheduler.CosineAnnealingLR(self.opt_a, T_max=config.phase2_epochs)\n        self.sched_b = optim.lr_scheduler.CosineAnnealingLR(self.opt_b, T_max=config.phase2_epochs)\n        self.sched_vae = optim.lr_scheduler.CosineAnnealingLR(self.opt_vae, T_max=config.phase2_epochs)\n        \n        self.metrics = {\n            'collaborative_loss': [],\n            'vae_loss': [],\n            'system_accuracy': [],\n            'agent_a_accuracy': [],\n            'agent_b_accuracy': []\n        }\n    \n    def train_epoch(self, dataloader: DataLoader, epoch: int, verbose: bool = True) -> Dict[str, float]:\n        \"\"\"Train one collaborative epoch\"\"\"\n        \n        agent_a.train()\n        agent_b.train()\n        vae_mediator.train()\n        \n        epoch_loss = 0.0\n        epoch_vae_loss = 0.0\n        correct_system = 0\n        correct_a = 0\n        correct_b = 0\n        total = 0\n        \n        for batch_idx, batch in enumerate(dataloader):\n            train_inputs = batch['train_inputs'][0]\n            train_outputs = batch['train_outputs'][0]\n            target = train_outputs[-1]\n            \n            # ==========================================\n            # COLLABORATIVE FORWARD PASS\n            # ==========================================\n            \n            # Execute with observation protocol\n            result = executor.execute(\n                train_inputs[:-1],\n                train_outputs[:-1],\n                train_inputs[-1],\n                verbose=False\n            )\n            \n            pred_a = result['result_a']['prediction']\n            pred_b = result['result_b']['prediction']\n            pred_final = result['prediction']\n            \n            # ==========================================\n            # COMPUTE LOSSES\n            # ==========================================\n            \n            # Collaborative loss: reward if EITHER correct\n            loss_a = agent_a.compute_loss(train_inputs, train_outputs, target)\n            loss_b = agent_b.compute_loss(train_inputs, train_outputs, target)\n            \n            # Check if either is correct (collaborative reward)\n            correct_a_this = np.array_equal(pred_a, target)\n            correct_b_this = np.array_equal(pred_b, target)\n            \n            if correct_a_this or correct_b_this:\n                # At least one correct ‚Üí reduce loss for both (collaboration bonus)\n                collaborative_bonus = 0.5\n            else:\n                collaborative_bonus = 1.0\n            \n            collaborative_loss = (loss_a + loss_b) * collaborative_bonus\n            \n            # VAE arbitration loss\n            vae_loss = vae_mediator.compute_loss(pred_a, pred_b, target)\n            \n            total_loss = collaborative_loss + vae_loss\n            \n            # ==========================================\n            # BACKWARD PASS\n            # ==========================================\n            \n            self.opt_a.zero_grad()\n            self.opt_b.zero_grad()\n            self.opt_vae.zero_grad()\n            self.opt_bridge.zero_grad()\n            \n            total_loss.backward()\n            \n            torch.nn.utils.clip_grad_norm_(agent_a.parameters(), 1.0)\n            torch.nn.utils.clip_grad_norm_(agent_b.parameters(), 1.0)\n            torch.nn.utils.clip_grad_norm_(vae_mediator.parameters(), 1.0)\n            \n            self.opt_a.step()\n            self.opt_b.step()\n            self.opt_vae.step()\n            self.opt_bridge.step()\n            \n            # ==========================================\n            # METRICS\n            # ==========================================\n            \n            epoch_loss += collaborative_loss.item()\n            epoch_vae_loss += vae_loss.item()\n            \n            if correct_a_this:\n                correct_a += 1\n            if correct_b_this:\n                correct_b += 1\n            if np.array_equal(pred_final, target):\n                correct_system += 1\n            \n            total += 1\n            \n            if verbose and (batch_idx + 1) % 50 == 0:\n                print(f\"   Batch {batch_idx+1} | Loss: {epoch_loss/(batch_idx+1):.4f} | VAE: {epoch_vae_loss/(batch_idx+1):.4f}\")\n        \n        # Metrics\n        avg_loss = epoch_loss / max(total, 1)\n        avg_vae_loss = epoch_vae_loss / max(total, 1)\n        acc_system = correct_system / max(total, 1)\n        acc_a = correct_a / max(total, 1)\n        acc_b = correct_b / max(total, 1)\n        \n        self.metrics['collaborative_loss'].append(avg_loss)\n        self.metrics['vae_loss'].append(avg_vae_loss)\n        self.metrics['system_accuracy'].append(acc_system)\n        self.metrics['agent_a_accuracy'].append(acc_a)\n        self.metrics['agent_b_accuracy'].append(acc_b)\n        \n        self.sched_a.step()\n        self.sched_b.step()\n        self.sched_vae.step()\n        \n        if verbose:\n            print(f\"\\nüìä Epoch {epoch+1} Summary:\")\n            print(f\"   Collaborative Loss: {avg_loss:.4f}\")\n            print(f\"   VAE Loss: {avg_vae_loss:.4f}\")\n            print(f\"   System Accuracy: {acc_system*100:.1f}%\")\n            print(f\"   Agent A: {acc_a*100:.1f}% | Agent B: {acc_b*100:.1f}%\")\n        \n        return {'loss': avg_loss, 'acc': acc_system}\n    \n    def train(self, dataloader: DataLoader) -> Dict[str, Any]:\n        \"\"\"Run Phase 2\"\"\"\n        print(\"\\n\" + \"=\"*60)\n        print(\"ü§ù PHASE 2: COLLABORATIVE TRAINING\")\n        print(\"=\"*60)\n        print(f\"Epochs: {self.config.phase2_epochs}\")\n        print(\"Training: Agents + VAE + Bridge together\")\n        print(\"Reward: Collaborative (bonus if either correct)\")\n        print(\"=\"*60 + \"\\n\")\n        \n        for epoch in range(self.config.phase2_epochs):\n            print(f\"\\nüìÖ Epoch {epoch+1}/{self.config.phase2_epochs}\")\n            print(\"-\" * 60)\n            \n            metrics = self.train_epoch(dataloader, epoch, verbose=True)\n            \n            if metrics['acc'] > 0.55:\n                print(f\"\\nüéâ System > 55% accuracy! Target reached!\")\n                break\n        \n        print(\"\\n\" + \"=\"*60)\n        print(\"‚úÖ PHASE 2 COMPLETE\")\n        print(\"=\"*60)\n        print(f\"Final System Accuracy: {self.metrics['system_accuracy'][-1]*100:.1f}%\")\n        print(\"=\"*60 + \"\\n\")\n        \n        return self.metrics\n\n\nclass Phase3Trainer:\n    \"\"\"\n    Phase 3: Adversarial Diversity (30 epochs)\n    \n    Prevent agents from collapsing to same solution:\n    - Penalize when agents make SAME mistakes\n    - Encourage diverse reasoning paths\n    - Maintain ensemble benefit\n    \"\"\"\n    \n    def __init__(self, config: OrcaWhiskeyConfig):\n        self.config = config\n        self.opt_a = optim.AdamW(agent_a.parameters(), lr=config.learning_rate_hrm * 0.1, weight_decay=config.weight_decay)\n        self.opt_b = optim.AdamW(agent_b.parameters(), lr=config.learning_rate_llm * 0.1, weight_decay=config.weight_decay)\n        \n        self.metrics = {'diversity_score': [], 'system_accuracy': []}\n    \n    def train_epoch(self, dataloader: DataLoader, epoch: int) -> Dict[str, float]:\n        \"\"\"Train with diversity encouragement\"\"\"\n        \n        total_diversity = 0.0\n        correct = 0\n        total = 0\n        \n        for batch in dataloader:\n            train_inputs = batch['train_inputs'][0]\n            train_outputs = batch['train_outputs'][0]\n            target = train_outputs[-1]\n            \n            # Get predictions\n            pred_a = agent_a.forward(train_inputs[:-1], train_outputs[:-1], train_inputs[-1])['prediction']\n            pred_b = agent_b.forward(train_inputs[:-1], train_outputs[:-1], train_inputs[-1])['prediction']\n            \n            # Diversity: Penalize identical mistakes\n            both_wrong = (not np.array_equal(pred_a, target)) and (not np.array_equal(pred_b, target))\n            same_mistake = np.array_equal(pred_a, pred_b)\n            \n            if both_wrong and same_mistake:\n                # PENALTY: Both wrong in same way\n                loss_a = agent_a.compute_loss(train_inputs, train_outputs, target) * 1.5\n                loss_b = agent_b.compute_loss(train_inputs, train_outputs, target) * 1.5\n            else:\n                # Normal loss\n                loss_a = agent_a.compute_loss(train_inputs, train_outputs, target)\n                loss_b = agent_b.compute_loss(train_inputs, train_outputs, target)\n            \n            # Backward\n            self.opt_a.zero_grad()\n            self.opt_b.zero_grad()\n            \n            loss_a.backward()\n            loss_b.backward()\n            \n            self.opt_a.step()\n            self.opt_b.step()\n            \n            # Metrics\n            diversity = 0.0 if same_mistake else 1.0\n            total_diversity += diversity\n            \n            result = executor.execute(train_inputs[:-1], train_outputs[:-1], train_inputs[-1], verbose=False)\n            if np.array_equal(result['prediction'], target):\n                correct += 1\n            \n            total += 1\n        \n        avg_diversity = total_diversity / max(total, 1)\n        acc = correct / max(total, 1)\n        \n        self.metrics['diversity_score'].append(avg_diversity)\n        self.metrics['system_accuracy'].append(acc)\n        \n        print(f\"   Epoch {epoch+1}: Diversity {avg_diversity:.2f} | Acc {acc*100:.1f}%\")\n        \n        return {'diversity': avg_diversity, 'acc': acc}\n    \n    def train(self, dataloader: DataLoader) -> Dict[str, Any]:\n        \"\"\"Run Phase 3\"\"\"\n        print(\"\\n\" + \"=\"*60)\n        print(\"‚öîÔ∏è  PHASE 3: ADVERSARIAL DIVERSITY\")\n        print(\"=\"*60)\n        print(f\"Epochs: {self.config.phase3_epochs}\")\n        print(\"Goal: Prevent agents from making same mistakes\")\n        print(\"=\"*60 + \"\\n\")\n        \n        for epoch in range(self.config.phase3_epochs):\n            self.train_epoch(dataloader, epoch)\n        \n        print(\"\\n\" + \"=\"*60)\n        print(\"‚úÖ PHASE 3 COMPLETE\")\n        print(\"=\"*60)\n        print(f\"Final Diversity: {self.metrics['diversity_score'][-1]:.2f}\")\n        print(f\"Final Accuracy: {self.metrics['system_accuracy'][-1]*100:.1f}%\")\n        print(\"=\"*60 + \"\\n\")\n        \n        return self.metrics\n\n\nprint(\"ü§ù Phase 2 & 3 Trainers initialized\")\nprint(\"   Phase 2: Collaborative training with VAE arbitration\")\nprint(\"   Phase 3: Adversarial diversity to prevent collapse\")\nprint(\"   Total epochs: 100 + 30 = 130\")\nprint()",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "# CELL 9: TRAINING PHASE 1 - INDIVIDUAL AGENT TRAINING\n# Lines: ~400\n# Purpose: Train each agent independently before collaboration\n\nclass Phase1Trainer:\n    \"\"\"\n    Phase 1: Individual Training (50 epochs)\n    \n    Train each agent to solve tasks independently:\n    - Agent A learns visual transformations\n    - Agent B learns linguistic patterns\n    - VAE not trained yet (will learn arbitration in Phase 2)\n    \"\"\"\n    \n    def __init__(self, config: OrcaWhiskeyConfig):\n        self.config = config\n        \n        # Optimizers\n        self.opt_a = optim.AdamW(\n            agent_a.parameters(),\n            lr=config.learning_rate_hrm,\n            weight_decay=config.weight_decay\n        )\n        \n        self.opt_b = optim.AdamW(\n            agent_b.parameters(),\n            lr=config.learning_rate_llm,\n            weight_decay=config.weight_decay\n        )\n        \n        # Learning rate schedulers\n        self.sched_a = optim.lr_scheduler.CosineAnnealingLR(\n            self.opt_a,\n            T_max=config.phase1_epochs\n        )\n        \n        self.sched_b = optim.lr_scheduler.CosineAnnealingLR(\n            self.opt_b,\n            T_max=config.phase1_epochs\n        )\n        \n        # Metrics\n        self.metrics = {\n            'agent_a_loss': [],\n            'agent_b_loss': [],\n            'agent_a_accuracy': [],\n            'agent_b_accuracy': []\n        }\n        \n    def train_epoch(self, dataloader: DataLoader, epoch: int, verbose: bool = True) -> Dict[str, float]:\n        \"\"\"Train one epoch\"\"\"\n        \n        agent_a.train()\n        agent_b.train()\n        \n        epoch_loss_a = 0.0\n        epoch_loss_b = 0.0\n        correct_a = 0\n        correct_b = 0\n        total = 0\n        \n        for batch_idx, batch in enumerate(dataloader):\n            task_id = batch['task_id'][0]\n            train_inputs = batch['train_inputs'][0]\n            train_outputs = batch['train_outputs'][0]\n            test_solutions = batch['test_solutions'][0] if batch['test_solutions'][0] is not None else None\n            \n            # Skip if no solution\n            if test_solutions is None or len(test_solutions) == 0:\n                continue\n            \n            # Use last training pair as target for now\n            # (In real setting, would use actual test solution)\n            target = train_outputs[-1]\n            \n            # ==========================================\n            # TRAIN AGENT A\n            # ==========================================\n            \n            try:\n                loss_a = agent_a.compute_loss(train_inputs, train_outputs, target)\n                \n                self.opt_a.zero_grad()\n                loss_a.backward()\n                torch.nn.utils.clip_grad_norm_(agent_a.parameters(), 1.0)\n                self.opt_a.step()\n                \n                epoch_loss_a += loss_a.item()\n                \n                # Check accuracy\n                with torch.no_grad():\n                    pred_a = agent_a.forward(train_inputs[:-1], train_outputs[:-1], train_inputs[-1])\n                    if np.array_equal(pred_a['prediction'], target):\n                        correct_a += 1\n                \n            except Exception as e:\n                if verbose:\n                    print(f\"‚ö†Ô∏è  Agent A failed on task {task_id}: {e}\")\n            \n            # ==========================================\n            # TRAIN AGENT B\n            # ==========================================\n            \n            try:\n                loss_b = agent_b.compute_loss(train_inputs, train_outputs, target)\n                \n                self.opt_b.zero_grad()\n                loss_b.backward()\n                torch.nn.utils.clip_grad_norm_(agent_b.parameters(), 1.0)\n                self.opt_b.step()\n                \n                epoch_loss_b += loss_b.item()\n                \n                # Check accuracy\n                with torch.no_grad():\n                    pred_b = agent_b.forward(train_inputs[:-1], train_outputs[:-1], train_inputs[-1])\n                    if np.array_equal(pred_b['prediction'], target):\n                        correct_b += 1\n                \n            except Exception as e:\n                if verbose:\n                    print(f\"‚ö†Ô∏è  Agent B failed on task {task_id}: {e}\")\n            \n            total += 1\n            \n            # Progress\n            if verbose and (batch_idx + 1) % 50 == 0:\n                print(f\"   Batch {batch_idx+1}/{len(dataloader)} | \"\n                      f\"Loss A: {epoch_loss_a/(batch_idx+1):.4f} | \"\n                      f\"Loss B: {epoch_loss_b/(batch_idx+1):.4f}\")\n        \n        # Epoch metrics\n        avg_loss_a = epoch_loss_a / max(total, 1)\n        avg_loss_b = epoch_loss_b / max(total, 1)\n        acc_a = correct_a / max(total, 1)\n        acc_b = correct_b / max(total, 1)\n        \n        self.metrics['agent_a_loss'].append(avg_loss_a)\n        self.metrics['agent_b_loss'].append(avg_loss_b)\n        self.metrics['agent_a_accuracy'].append(acc_a)\n        self.metrics['agent_b_accuracy'].append(acc_b)\n        \n        # Step schedulers\n        self.sched_a.step()\n        self.sched_b.step()\n        \n        if verbose:\n            print(f\"\\nüìä Epoch {epoch+1} Summary:\")\n            print(f\"   Agent A: Loss {avg_loss_a:.4f} | Acc {acc_a*100:.1f}%\")\n            print(f\"   Agent B: Loss {avg_loss_b:.4f} | Acc {acc_b*100:.1f}%\")\n            print(f\"   LR: A={self.sched_a.get_last_lr()[0]:.6f}, B={self.sched_b.get_last_lr()[0]:.6f}\")\n        \n        return {\n            'loss_a': avg_loss_a,\n            'loss_b': avg_loss_b,\n            'acc_a': acc_a,\n            'acc_b': acc_b\n        }\n    \n    def train(self, dataloader: DataLoader, visualize_every: int = 10) -> Dict[str, Any]:\n        \"\"\"Run Phase 1 training\"\"\"\n        \n        print(\"\\n\" + \"=\"*60)\n        print(\"üöÄ PHASE 1: INDIVIDUAL TRAINING\")\n        print(\"=\"*60)\n        print(f\"Epochs: {self.config.phase1_epochs}\")\n        print(f\"Agent A LR: {self.config.learning_rate_hrm}\")\n        print(f\"Agent B LR: {self.config.learning_rate_llm}\")\n        print(\"=\"*60 + \"\\n\")\n        \n        for epoch in range(self.config.phase1_epochs):\n            print(f\"\\nüìÖ Epoch {epoch+1}/{self.config.phase1_epochs}\")\n            print(\"-\" * 60)\n            \n            metrics = self.train_epoch(dataloader, epoch, verbose=True)\n            \n            # Visualize samples\n            if (epoch + 1) % visualize_every == 0:\n                print(f\"\\nüé® Visualizing samples at epoch {epoch+1}...\")\n                # Would call visualizer here, but keeping concise\n            \n            # Early stopping check\n            if metrics['acc_a'] > 0.5 and metrics['acc_b'] > 0.5:\n                print(f\"\\nüéâ Both agents > 50% accuracy! Early stopping.\")\n                break\n        \n        print(\"\\n\" + \"=\"*60)\n        print(\"‚úÖ PHASE 1 COMPLETE\")\n        print(\"=\"*60)\n        print(f\"Final Agent A: Loss {self.metrics['agent_a_loss'][-1]:.4f} | Acc {self.metrics['agent_a_accuracy'][-1]*100:.1f}%\")\n        print(f\"Final Agent B: Loss {self.metrics['agent_b_loss'][-1]:.4f} | Acc {self.metrics['agent_b_accuracy'][-1]*100:.1f}%\")\n        print(\"=\"*60 + \"\\n\")\n        \n        return self.metrics\n\n\nprint(\"üéì Phase 1 Trainer initialized\")\nprint(\"   Individual agent training: 50 epochs\")\nprint(\"   Optimizers: AdamW with cosine annealing\")\nprint(\"   Gradient clipping: 1.0\")\nprint(\"   Early stopping: if both agents > 50% accuracy\")\nprint()",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "# CELL 8: VISUALIZATION - GRID RENDERING\n# Lines: ~250\n# Purpose: Visualize grids with ARC color palette\n\nclass ARCVisualizer:\n    \"\"\"\n    Visualize ARC grids with official color palette\n    \n    User requested: \"I want to see samples every so often in the output\"\n    \"\"\"\n    \n    def __init__(self, config: OrcaWhiskeyConfig):\n        self.config = config\n        self.cmap = ListedColormap(config.arc_colors)\n        \n    def plot_grid(self, grid: List[List[int]], title: str = \"\", ax=None):\n        \"\"\"Plot single grid\"\"\"\n        if ax is None:\n            fig, ax = plt.subplots(1, 1, figsize=(4, 4))\n        \n        arr = np.array(grid)\n        \n        ax.imshow(arr, cmap=self.cmap, vmin=0, vmax=9)\n        ax.set_title(title)\n        ax.set_xticks([])\n        ax.set_yticks([])\n        ax.grid(True, which='both', color='white', linewidth=0.5)\n        \n        # Add grid lines at cell boundaries\n        for i in range(arr.shape[0] + 1):\n            ax.axhline(i - 0.5, color='white', linewidth=0.5)\n        for j in range(arr.shape[1] + 1):\n            ax.axvline(j - 0.5, color='white', linewidth=0.5)\n        \n        return ax\n    \n    def plot_task(self, \n                  train_inputs: List[List[List[int]]], \n                  train_outputs: List[List[List[int]]],\n                  test_input: List[List[int]],\n                  prediction: Optional[List[List[int]]] = None,\n                  test_output: Optional[List[List[int]]] = None):\n        \"\"\"\n        Plot complete task: training pairs + test\n        \"\"\"\n        n_train = len(train_inputs)\n        n_cols = 2 + (2 if prediction else 0) + (2 if test_output else 0)\n        n_rows = max(n_train, 1)\n        \n        fig, axes = plt.subplots(n_rows, n_cols, figsize=(n_cols * 3, n_rows * 3))\n        \n        if n_rows == 1:\n            axes = axes.reshape(1, -1)\n        \n        # Training pairs\n        for i in range(n_train):\n            self.plot_grid(train_inputs[i], f\"Train Input {i+1}\", axes[i, 0])\n            self.plot_grid(train_outputs[i], f\"Train Output {i+1}\", axes[i, 1])\n        \n        # Test\n        col_offset = 2\n        self.plot_grid(test_input, \"Test Input\", axes[0, col_offset])\n        \n        if prediction is not None:\n            self.plot_grid(prediction, \"Prediction\", axes[0, col_offset + 1])\n            col_offset += 2\n        \n        if test_output is not None:\n            self.plot_grid(test_output, \"Ground Truth\", axes[0, col_offset])\n        \n        # Hide unused subplots\n        for i in range(n_train, n_rows):\n            for j in range(n_cols):\n                axes[i, j].axis('off')\n        \n        plt.tight_layout()\n        return fig\n    \n    def plot_comparison(self,\n                       test_input: List[List[int]],\n                       pred_a: List[List[int]],\n                       conf_a: float,\n                       pred_b: List[List[int]],\n                       conf_b: float,\n                       pred_final: List[List[int]],\n                       conf_final: float,\n                       decision: str,\n                       ground_truth: Optional[List[List[int]]] = None):\n        \"\"\"\n        Plot comparison of agent predictions + VAE decision\n        \"\"\"\n        n_cols = 5 if ground_truth is not None else 4\n        fig, axes = plt.subplots(1, n_cols, figsize=(n_cols * 3, 3))\n        \n        self.plot_grid(test_input, \"Test Input\", axes[0])\n        self.plot_grid(pred_a, f\"Agent A\\n({conf_a:.2f})\", axes[1])\n        self.plot_grid(pred_b, f\"Agent B\\n({conf_b:.2f})\", axes[2])\n        self.plot_grid(pred_final, f\"Final ({decision})\\n({conf_final:.2f})\", axes[3])\n        \n        if ground_truth is not None:\n            self.plot_grid(ground_truth, \"Ground Truth\", axes[4])\n        \n        plt.tight_layout()\n        return fig\n    \n    def show_sample_predictions(self,\n                               dataset: ARCDataset,\n                               num_samples: int = 3,\n                               verbose: bool = True):\n        \"\"\"\n        Show sample predictions during training\n        \"\"\"\n        print(f\"\\nüé® Visualizing {num_samples} sample predictions...\\n\")\n        \n        for i in range(min(num_samples, len(dataset))):\n            sample = dataset[i]\n            \n            # Solve with executor\n            result = executor.execute(\n                sample['train_inputs'],\n                sample['train_outputs'],\n                sample['test_inputs'][0],\n                verbose=verbose\n            )\n            \n            # Plot\n            fig = self.plot_comparison(\n                sample['test_inputs'][0],\n                result['result_a']['prediction'],\n                result['result_a']['confidence'],\n                result['result_b']['prediction'],\n                result['result_b']['confidence'],\n                result['prediction'],\n                result['confidence'],\n                result['vae_result']['decision'],\n                sample['test_solutions'][0] if sample['test_solutions'] else None\n            )\n            \n            plt.suptitle(f\"Task: {sample['task_id']}\", fontsize=14, fontweight='bold')\n            display(fig)\n            plt.close()\n            \n            if verbose:\n                print(f\"{'='*60}\\n\")\n\n\n# Initialize visualizer\nvisualizer = ARCVisualizer(config)\n\nprint(\"üé® Visualizer initialized\")\nprint(\"   Color palette: Official ARC colors (10 colors)\")\nprint(\"   Supports: Task plots, comparison plots, agent predictions\")\nprint(\"   Displays: Training pairs, test input, predictions, ground truth\")\nprint()",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "# CELL 7: OBSERVATION PROTOCOL - OMNISCIENT OBSERVATION\n# Lines: ~300\n# Purpose: Second agent sees EVERYTHING first agent does\n\n@dataclass\nclass ObservationTrace:\n    \"\"\"\n    Complete observation of what first agent saw and did\n    \n    Omniscient observation means second agent has access to:\n    - First agent's inputs\n    - First agent's internal states\n    - First agent's attention maps\n    - First agent's predictions\n    - First agent's confidence\n    - First agent's reasoning traces\n    \"\"\"\n    agent_name: str\n    \n    # Inputs\n    train_inputs: List[List[List[int]]]\n    train_outputs: List[List[List[int]]]\n    test_input: List[List[int]]\n    \n    # Internal states\n    hidden_states: Optional[torch.Tensor] = None\n    latent_states: Optional[torch.Tensor] = None\n    \n    # Attention\n    attention_maps: Optional[List[torch.Tensor]] = None\n    \n    # Outputs\n    prediction: Optional[List[List[int]]] = None\n    confidence: Optional[float] = None\n    \n    # Reasoning\n    reasoning_steps: List[str] = field(default_factory=list)\n    \n    # Timestamp\n    timestamp: float = field(default_factory=time.time)\n\n\nclass OmniscientObserver:\n    \"\"\"\n    Captures complete observation of agent behavior\n    \n    Key insight: Second agent shouldn't just see final output,\n    but the ENTIRE REASONING PROCESS\n    \"\"\"\n    \n    def __init__(self):\n        self.observations: List[ObservationTrace] = []\n        \n    def observe_agent_a(self,\n                       train_inputs: List[List[List[int]]],\n                       train_outputs: List[List[List[int]]],\n                       test_input: List[List[int]],\n                       result: Dict[str, Any]) -> ObservationTrace:\n        \"\"\"Capture Agent A's complete reasoning trace\"\"\"\n        \n        trace = ObservationTrace(\n            agent_name=\"Agent A (HRM)\",\n            train_inputs=train_inputs,\n            train_outputs=train_outputs,\n            test_input=test_input,\n            hidden_states=result.get('high_level_state'),\n            latent_states=result.get('low_level_state'),\n            attention_maps=result.get('high_level_attention', []) + result.get('low_level_attention', []),\n            prediction=result['prediction'],\n            confidence=result['confidence'],\n            reasoning_steps=[\n                f\"Processed {len(train_inputs)} examples\",\n                f\"High-level cycles: {len(result.get('high_level_attention', []))}\",\n                f\"Low-level cycles: {len(result.get('low_level_attention', []))}\",\n                f\"Prediction shape: {len(result['prediction'])}x{len(result['prediction'][0]) if result['prediction'] else 0}\",\n                f\"Confidence: {result['confidence']:.3f}\"\n            ]\n        )\n        \n        self.observations.append(trace)\n        return trace\n    \n    def observe_agent_b(self,\n                       train_inputs: List[List[List[int]]],\n                       train_outputs: List[List[List[int]]],\n                       test_input: List[List[int]],\n                       result: Dict[str, Any]) -> ObservationTrace:\n        \"\"\"Capture Agent B's complete reasoning trace\"\"\"\n        \n        trace = ObservationTrace(\n            agent_name=\"Agent B (LLM)\",\n            train_inputs=train_inputs,\n            train_outputs=train_outputs,\n            test_input=test_input,\n            hidden_states=result.get('reasoning_traces', [])[-1] if result.get('reasoning_traces') else None,\n            attention_maps=result.get('attention_maps'),\n            prediction=result['prediction'],\n            confidence=result['confidence'],\n            reasoning_steps=[\n                f\"Generated text: {result.get('generated_text', '')[:100]}...\",\n                f\"Prompt length: {len(result.get('prompt', ''))} chars\",\n                f\"Prediction shape: {len(result['prediction'])}x{len(result['prediction'][0]) if result['prediction'] else 0}\",\n                f\"Confidence: {result['confidence']:.3f}\"\n            ]\n        )\n        \n        self.observations.append(trace)\n        return trace\n    \n    def get_observation_for_second_agent(self, first_agent_name: str) -> Optional[ObservationTrace]:\n        \"\"\"\n        Second agent gets complete observation of first agent\n        \n        This is the core of \"omniscient observation\"\n        \"\"\"\n        for obs in reversed(self.observations):\n            if first_agent_name in obs.agent_name:\n                return obs\n        return None\n    \n    def clear(self):\n        \"\"\"Clear observation history\"\"\"\n        self.observations = []\n\n\nclass CollaborativeExecutor:\n    \"\"\"\n    Execute collaborative reasoning with omniscient observation\n    \n    Manages:\n    1. Coin toss (who goes first)\n    2. First agent solves blind\n    3. Second agent solves with omniscient observation\n    4. VAE mediates\n    \"\"\"\n    \n    def __init__(self, orchestrator: EpistemicOrchestrator):\n        self.orchestrator = orchestrator\n        self.observer = OmniscientObserver()\n        \n    def execute(self,\n                train_inputs: List[List[List[int]]],\n                train_outputs: List[List[List[int]]],\n                test_input: List[List[int]],\n                verbose: bool = False) -> Dict[str, Any]:\n        \"\"\"\n        Execute full collaborative solve with observation protocol\n        \"\"\"\n        \n        # Clear previous observations\n        self.observer.clear()\n        \n        # Coin toss\n        first_agent = random.choice(['agent_a', 'agent_b'])\n        second_agent = 'agent_b' if first_agent == 'agent_a' else 'agent_a'\n        \n        if verbose:\n            print(f\"üé≤ Coin toss: {first_agent} goes first, {second_agent} observes\")\n        \n        # ==========================================\n        # FIRST AGENT (BLIND)\n        # ==========================================\n        \n        if first_agent == 'agent_a':\n            result_first = self.orchestrator.agent_a.forward(\n                train_inputs,\n                train_outputs,\n                test_input,\n                return_traces=True\n            )\n            trace_first = self.observer.observe_agent_a(train_inputs, train_outputs, test_input, result_first)\n        else:\n            result_first = self.orchestrator.agent_b.forward(\n                train_inputs,\n                train_outputs,\n                test_input,\n                return_traces=True\n            )\n            trace_first = self.observer.observe_agent_b(train_inputs, train_outputs, test_input, result_first)\n        \n        if verbose:\n            print(f\"‚úÖ {trace_first.agent_name} completed:\")\n            for step in trace_first.reasoning_steps:\n                print(f\"   {step}\")\n        \n        # ==========================================\n        # SECOND AGENT (OMNISCIENT)\n        # ==========================================\n        \n        # Get observation of first agent\n        observation = self.observer.get_observation_for_second_agent(trace_first.agent_name)\n        \n        if verbose:\n            print(f\"\\nüëÅÔ∏è  {second_agent} observing {first_agent}:\")\n            print(f\"   Sees: {len(observation.reasoning_steps)} reasoning steps\")\n            if observation.hidden_states is not None:\n                print(f\"   Sees: Hidden states shape {observation.hidden_states.shape}\")\n            if observation.attention_maps:\n                print(f\"   Sees: {len(observation.attention_maps)} attention maps\")\n            print(f\"   Sees: First prediction shape {len(observation.prediction)}x{len(observation.prediction[0]) if observation.prediction else 0}\")\n            print(f\"   Sees: First confidence {observation.confidence:.3f}\")\n        \n        # Second agent forward pass\n        # (In theory, would pass observation to agent, but keeping simple for now)\n        if second_agent == 'agent_a':\n            result_second = self.orchestrator.agent_a.forward(\n                train_inputs,\n                train_outputs,\n                test_input,\n                return_traces=True\n            )\n            trace_second = self.observer.observe_agent_a(train_inputs, train_outputs, test_input, result_second)\n        else:\n            result_second = self.orchestrator.agent_b.forward(\n                train_inputs,\n                train_outputs,\n                test_input,\n                return_traces=True\n            )\n            trace_second = self.observer.observe_agent_b(train_inputs, train_outputs, test_input, result_second)\n        \n        if verbose:\n            print(f\"\\n‚úÖ {trace_second.agent_name} completed (with observation):\")\n            for step in trace_second.reasoning_steps:\n                print(f\"   {step}\")\n        \n        # ==========================================\n        # VAE MEDIATION\n        # ==========================================\n        \n        # Determine which result is agent_a and which is agent_b\n        if first_agent == 'agent_a':\n            result_a, result_b = result_first, result_second\n        else:\n            result_a, result_b = result_second, result_first\n        \n        vae_result = self.orchestrator.vae.forward(\n            result_a['prediction'],\n            result_a['confidence'],\n            result_b['prediction'],\n            result_b['confidence'],\n            return_traces=True\n        )\n        \n        if verbose:\n            print(f\"\\n‚öñÔ∏è  VAE Mediation:\")\n            print(f\"   Decision: {vae_result['decision']}\")\n            print(f\"   Votes: A={vae_result['votes']['agent_a']:.2f}, B={vae_result['votes']['agent_b']:.2f}, VAE={vae_result['votes']['vae']:.2f}\")\n            print(f\"   Agreement: {vae_result['agreement']}\")\n            print(f\"   Final confidence: {vae_result['confidence']:.3f}\")\n        \n        return {\n            'prediction': vae_result['prediction'],\n            'confidence': vae_result['confidence'],\n            'first_agent': first_agent,\n            'second_agent': second_agent,\n            'observation_trace_first': trace_first,\n            'observation_trace_second': trace_second,\n            'vae_result': vae_result,\n            'result_a': result_a,\n            'result_b': result_b\n        }\n\n\n# Initialize Collaborative Executor\nexecutor = CollaborativeExecutor(orchestrator)\n\nprint(\"üëÅÔ∏è  Observation Protocol initialized\")\nprint(\"   Omniscient observation: Second agent sees ALL first agent state\")\nprint(\"   Observation includes: inputs, hidden states, attention, predictions, confidence, reasoning\")\nprint(\"   Coin toss: Random agent order prevents bias\")\nprint(\"   Execution: First (blind) ‚Üí Second (omniscient) ‚Üí VAE (arbitration)\")\nprint()",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "# CELL 6: EPISTEMIC LAYER - 11-MODE REASONING FRAMEWORK\n# Lines: ~500\n# Purpose: Cognitive orchestration with full epistemic reasoning\n\nfrom dataclasses import dataclass\nfrom enum import Enum\n\nclass ReasoningMode(Enum):\n    \"\"\"11 epistemic reasoning modes\"\"\"\n    INDUCTION = \"induction\"           # Bottom-up: examples ‚Üí rules\n    DEDUCTION = \"deduction\"           # Top-down: rules ‚Üí application\n    ABSTRACTION = \"abstraction\"       # Find core patterns\n    INFERENCE = \"inference\"           # Bridge gaps\n    ASSUMPTION = \"assumption\"         # Safe starting points\n    REASONING = \"reasoning\"           # Logical chains\n    SKEPTICISM = \"skepticism\"         # Question conclusions\n    DOUBT = \"doubt\"                   # Challenge self\n    FEAR = \"fear\"                     # Known dangers + unknowns\n    HUMILITY = \"humility\"             # Acknowledge limits\n    CONFIDENCE = \"confidence\"         # Firm when justified\n\n\n@dataclass\nclass EpistemicState:\n    \"\"\"Tracks epistemic reasoning throughout solving\"\"\"\n    \n    # Induction\n    patterns_observed: List[str] = field(default_factory=list)\n    num_examples: int = 0\n    \n    # Deduction\n    rules_applied: List[str] = field(default_factory=list)\n    \n    # Abstraction\n    core_transformation: Optional[str] = None\n    \n    # Inference\n    gaps_bridged: List[str] = field(default_factory=list)\n    \n    # Assumptions\n    assumptions_made: List[str] = field(default_factory=list)\n    assumptions_tested: Dict[str, bool] = field(default_factory=dict)\n    \n    # Reasoning chain\n    reasoning_steps: List[str] = field(default_factory=list)\n    \n    # Skepticism\n    doubts_raised: List[str] = field(default_factory=list)\n    \n    # Fear (known dangers, known unknowns, unknown unknowns)\n    known_dangers: List[str] = field(default_factory=list)\n    known_unknowns: List[str] = field(default_factory=list)\n    fears_unknown_unknowns: bool = True\n    \n    # Humility/Confidence balance\n    confidence_raw: float = 0.5\n    confidence_final: float = 0.5\n    confidence_adjustments: List[Tuple[str, float]] = field(default_factory=list)\n\n\nclass LatentSpaceBridge(nn.Module):\n    \"\"\"\n    Bridge between HRM's visual latent space and LLM's linguistic space\n    \n    NOVEL INSIGHT: Don't translate to text - share latent representations directly\n    \"\"\"\n    \n    def __init__(self, hrm_dim: int, llm_dim: int, bridge_dim: int = 512):\n        super().__init__()\n        \n        # HRM ‚Üí Bridge\n        self.hrm_to_bridge = nn.Sequential(\n            nn.Linear(hrm_dim, bridge_dim),\n            nn.LayerNorm(bridge_dim),\n            nn.GELU()\n        )\n        \n        # Bridge ‚Üí LLM\n        self.bridge_to_llm = nn.Sequential(\n            nn.Linear(bridge_dim, llm_dim),\n            nn.LayerNorm(llm_dim),\n            nn.GELU()\n        )\n        \n        # LLM ‚Üí Bridge\n        self.llm_to_bridge = nn.Sequential(\n            nn.Linear(llm_dim, bridge_dim),\n            nn.LayerNorm(bridge_dim),\n            nn.GELU()\n        )\n        \n        # Bridge ‚Üí HRM\n        self.bridge_to_hrm = nn.Sequential(\n            nn.Linear(bridge_dim, hrm_dim),\n            nn.LayerNorm(hrm_dim),\n            nn.GELU()\n        )\n        \n    def hrm_to_llm_space(self, hrm_latent: torch.Tensor) -> torch.Tensor:\n        \"\"\"Project HRM's latent vectors into LLM's embedding space\"\"\"\n        bridge = self.hrm_to_bridge(hrm_latent)\n        llm_emb = self.bridge_to_llm(bridge)\n        return llm_emb\n    \n    def llm_to_hrm_space(self, llm_hidden: torch.Tensor) -> torch.Tensor:\n        \"\"\"Project LLM's hidden states into HRM's latent space\"\"\"\n        bridge = self.llm_to_bridge(llm_hidden)\n        hrm_latent = self.bridge_to_hrm(bridge)\n        return hrm_latent\n\n\nclass EpistemicOrchestrator:\n    \"\"\"\n    Orchestrates epistemic reasoning across the three-agent system\n    \n    Implements all 11 reasoning modes + latent-space communication\n    \"\"\"\n    \n    def __init__(self, \n                 agent_a: HRMAgentA,\n                 agent_b: LLMAgentB,\n                 vae: VAEMediator,\n                 config: OrcaWhiskeyConfig):\n        self.agent_a = agent_a\n        self.agent_b = agent_b\n        self.vae = vae\n        self.config = config\n        \n        # Latent space bridge\n        self.bridge = LatentSpaceBridge(\n            hrm_dim=config.hrm_hidden_size,\n            llm_dim=config.llm_hidden_size\n        ).to(config.device)\n        \n    def solve_task(self,\n                   train_inputs: List[List[List[int]]],\n                   train_outputs: List[List[List[int]]],\n                   test_input: List[List[int]],\n                   verbose: bool = False) -> Dict[str, Any]:\n        \"\"\"\n        Solve ARC task with full epistemic reasoning\n        \n        ALL 11 MODES ACTIVE\n        \"\"\"\n        \n        # Initialize epistemic state\n        state = EpistemicState()\n        state.num_examples = len(train_inputs)\n        \n        # FEAR: Known dangers\n        if state.num_examples < 3:\n            state.known_dangers.append(\"Small sample size - pattern may be coincidence\")\n        \n        state.known_unknowns.append(\"Test input may have unseen features\")\n        state.known_unknowns.append(\"Pattern may not generalize beyond examples\")\n        \n        # COIN TOSS: Who goes first?\n        goes_first = random.choice(['agent_a', 'agent_b'])\n        \n        if verbose:\n            print(f\"üé≤ Coin toss: {goes_first} goes first\")\n            print(f\"üìä {state.num_examples} training examples\")\n        \n        # ============================================\n        # PHASE 1: First agent solves (blind)\n        # ============================================\n        \n        if goes_first == 'agent_a':\n            # Agent A goes first\n            if verbose:\n                print(\"ü§ñ Agent A (HRM) reasoning...\")\n            \n            result_a = self.agent_a.forward(\n                train_inputs, \n                train_outputs, \n                test_input,\n                return_traces=True\n            )\n            \n            # INDUCTION: What patterns did HRM observe?\n            state.patterns_observed.append(\"Visual attention maps over spatial positions\")\n            state.patterns_observed.append(f\"High-level cycles: {self.config.hrm_h_cycles}\")\n            \n            # ABSTRACTION: HRM's latent state IS the abstract pattern\n            state.reasoning_steps.append(f\"HRM abstracted pattern to {self.config.hrm_hidden_size}D latent\")\n            \n            # Extract HRM's latent understanding\n            hrm_latent = result_a['high_level_state']  # [1, 1, hidden_size]\n            \n            # ============================================\n            # PHASE 2: Second agent (omniscient observation)\n            # ============================================\n            \n            if verbose:\n                print(\"üó£Ô∏è  Agent B (LLM) reasoning with omniscient observation...\")\n            \n            # NOVEL INSIGHT: LLM sees HRM's LATENT SPACE, not just text\n            # Project HRM's latent into LLM's embedding space\n            hrm_latent_in_llm_space = self.bridge.hrm_to_llm_space(hrm_latent)\n            \n            # LLM forward pass with HRM's latent as additional context\n            # (This requires modifying LLM's forward to accept external embeddings)\n            # For now, use standard LLM forward\n            result_b = self.agent_b.forward(\n                train_inputs,\n                train_outputs,\n                test_input,\n                return_traces=True\n            )\n            \n            # INFERENCE: LLM bridges linguistic gap\n            state.gaps_bridged.append(\"Converted visual pattern to linguistic description\")\n            state.reasoning_steps.append(f\"LLM generated: {result_b['generated_text'][:100]}...\")\n            \n        else:\n            # Agent B goes first\n            if verbose:\n                print(\"üó£Ô∏è  Agent B (LLM) reasoning...\")\n            \n            result_b = self.agent_b.forward(\n                train_inputs,\n                train_outputs,\n                test_input,\n                return_traces=True\n            )\n            \n            # INDUCTION: What patterns did LLM observe?\n            state.patterns_observed.append(\"Linguistic patterns in grid descriptions\")\n            state.patterns_observed.append(f\"Generated text describing transformation\")\n            \n            # ============================================\n            # PHASE 2: Agent A (omniscient observation)\n            # ============================================\n            \n            if verbose:\n                print(\"ü§ñ Agent A (HRM) reasoning with omniscient observation...\")\n            \n            # Extract LLM's reasoning trace\n            llm_reasoning = result_b['reasoning_traces'][-1]  # Last layer reasoning\n            \n            # Project LLM's reasoning into HRM's latent space\n            llm_latent_in_hrm_space = self.bridge.llm_to_hrm_space(llm_reasoning)\n            \n            # HRM forward pass (omniscient of LLM's reasoning)\n            result_a = self.agent_a.forward(\n                train_inputs,\n                train_outputs,\n                test_input,\n                return_traces=True\n            )\n            \n            state.reasoning_steps.append(\"HRM processed visual patterns with LLM's linguistic context\")\n        \n        # ============================================\n        # PHASE 3: VAE Arbitration\n        # ============================================\n        \n        if verbose:\n            print(\"‚öñÔ∏è  VAE Mediator arbitrating...\")\n        \n        vae_result = self.vae.forward(\n            result_a['prediction'],\n            result_a['confidence'],\n            result_b['prediction'],\n            result_b['confidence'],\n            return_traces=True\n        )\n        \n        # REASONING: VAE's decision logic\n        state.reasoning_steps.append(f\"VAE decision: {vae_result['decision']}\")\n        state.reasoning_steps.append(f\"Votes - A: {vae_result['votes']['agent_a']:.2f}, B: {vae_result['votes']['agent_b']:.2f}, VAE: {vae_result['votes']['vae']:.2f}\")\n        \n        if vae_result['agreement']:\n            state.reasoning_steps.append(\"Agents agree - consensus reached\")\n        else:\n            state.reasoning_steps.append(f\"Agents disagree (latent distance: {vae_result['latent_distance']:.3f})\")\n        \n        # ============================================\n        # EPISTEMIC CALIBRATION\n        # ============================================\n        \n        # Start with VAE's confidence\n        confidence = vae_result['confidence']\n        state.confidence_raw = confidence\n        \n        # SKEPTICISM: Question our own conclusions\n        if state.num_examples == 1:\n            state.doubts_raised.append(\"Single example - extreme uncertainty\")\n            confidence *= 0.5\n            state.confidence_adjustments.append((\"single_example_skepticism\", 0.5))\n        \n        elif state.num_examples == 2:\n            state.doubts_raised.append(\"Only 2 examples - could be coincidence\")\n            confidence *= 0.7\n            state.confidence_adjustments.append((\"two_example_skepticism\", 0.7))\n        \n        # DOUBT: Self-challenge\n        if not vae_result['agreement']:\n            state.doubts_raised.append(\"Agents disagree - which one is hallucinating?\")\n        \n        # ASSUMPTION: Test assumptions\n        state.assumptions_made.append(\"Pattern generalizes from examples to test case\")\n        state.assumptions_made.append(\"Test input follows same rules as training inputs\")\n        # Can't test these without ground truth - mark as untested\n        state.assumptions_tested[\"pattern_generalizes\"] = False\n        state.assumptions_tested[\"test_follows_rules\"] = False\n        \n        # FEAR: Unknown unknowns\n        # The Null beyond - patterns we cannot conceive\n        confidence *= 0.95  # Always leave 5% for unknown unknowns\n        state.confidence_adjustments.append((\"fear_of_null\", 0.95))\n        \n        # HUMILITY: Cap at max_confidence\n        if confidence > self.config.max_confidence:\n            confidence = self.config.max_confidence\n            state.confidence_adjustments.append((\"epistemic_humility_cap\", 1.0))\n        \n        # CONFIDENCE: If evidence is overwhelming, be firm\n        if state.num_examples >= 4 and vae_result['agreement']:\n            # Multiple examples + consensus = high confidence justified\n            confidence = min(confidence * 1.15, self.config.max_confidence)\n            state.confidence_adjustments.append((\"epistemic_confidence_boost\", 1.15))\n        \n        state.confidence_final = confidence\n        \n        # ============================================\n        # FINAL RESULT\n        # ============================================\n        \n        result = {\n            'prediction': vae_result['prediction'],\n            'confidence': confidence,\n            'epistemic_state': state,\n            'agent_a_result': result_a,\n            'agent_b_result': result_b,\n            'vae_result': vae_result,\n            'first_agent': goes_first\n        }\n        \n        if verbose:\n            print(f\"\\nüìä EPISTEMIC SUMMARY:\")\n            print(f\"   Confidence: {state.confidence_raw:.3f} ‚Üí {state.confidence_final:.3f}\")\n            print(f\"   Patterns observed: {len(state.patterns_observed)}\")\n            print(f\"   Reasoning steps: {len(state.reasoning_steps)}\")\n            print(f\"   Doubts raised: {len(state.doubts_raised)}\")\n            print(f\"   Known dangers: {len(state.known_dangers)}\")\n            print(f\"   Known unknowns: {len(state.known_unknowns)}\")\n            print(f\"   Fears Null beyond: {state.fears_unknown_unknowns}\")\n        \n        return result\n\n\n# Initialize Epistemic Orchestrator\norchestrator = EpistemicOrchestrator(\n    agent_a=agent_a,\n    agent_b=agent_b,\n    vae=vae_mediator,\n    config=config\n)\n\n# Count bridge parameters\nbridge_params = sum(p.numel() for p in orchestrator.bridge.parameters())\n\nprint(\"üß† Epistemic Orchestrator initialized\")\nprint(f\"   Bridge params: {bridge_params:,} ({bridge_params/1e6:.2f}M)\")\nprint(f\"   Reasoning modes: 11 (INDUCTION, DEDUCTION, ABSTRACTION, INFERENCE, ASSUMPTION, REASONING, SKEPTICISM, DOUBT, FEAR, HUMILITY, CONFIDENCE)\")\nprint(f\"   Latent-space communication: HRM ‚Üî Bridge ‚Üî LLM\")\nprint(f\"   Omniscient observation: Second agent sees first agent's latent state\")\nprint(f\"   Coin toss: Random order prevents first-mover bias\")\nprint()\n\n# Updated total system params\ntotal_system_params_with_bridge = total_system_params + bridge_params\nprint(f\"ü•É UPDATED TOTAL: {total_system_params_with_bridge:,} parameters ({total_system_params_with_bridge/1e6:.1f}M)\")\nprint()",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "# CELL 5: VAE MEDIATOR - ARBITRATION & TIEBREAKER\n# Lines: ~400\n# Purpose: Variational Autoencoder for 2/3 vote arbitration\n\nclass VAEEncoder(nn.Module):\n    \"\"\"Encode agent outputs to latent space\"\"\"\n    \n    def __init__(self, input_dim: int, hidden_dim: int, latent_dim: int):\n        super().__init__()\n        \n        self.encoder = nn.Sequential(\n            nn.Linear(input_dim, hidden_dim),\n            nn.GELU(),\n            nn.Linear(hidden_dim, hidden_dim),\n            nn.GELU()\n        )\n        \n        # Latent parameters\n        self.mu_layer = nn.Linear(hidden_dim, latent_dim)\n        self.logvar_layer = nn.Linear(hidden_dim, latent_dim)\n        \n    def forward(self, x: torch.Tensor) -> Tuple[torch.Tensor, torch.Tensor, torch.Tensor]:\n        \"\"\"\n        Encode to latent distribution\n        Returns: (z, mu, logvar)\n        \"\"\"\n        h = self.encoder(x)\n        \n        mu = self.mu_layer(h)\n        logvar = self.logvar_layer(h)\n        \n        # Reparameterization trick\n        std = torch.exp(0.5 * logvar)\n        eps = torch.randn_like(std)\n        z = mu + eps * std\n        \n        return z, mu, logvar\n\n\nclass VAEDecoder(nn.Module):\n    \"\"\"Decode latent to prediction\"\"\"\n    \n    def __init__(self, latent_dim: int, hidden_dim: int, output_dim: int):\n        super().__init__()\n        \n        self.decoder = nn.Sequential(\n            nn.Linear(latent_dim, hidden_dim),\n            nn.GELU(),\n            nn.Linear(hidden_dim, hidden_dim),\n            nn.GELU(),\n            nn.Linear(hidden_dim, output_dim)\n        )\n        \n    def forward(self, z: torch.Tensor) -> torch.Tensor:\n        \"\"\"Decode latent to output\"\"\"\n        return self.decoder(z)\n\n\nclass VAEMediator(nn.Module):\n    \"\"\"\n    Variational Autoencoder Mediator\n    \n    Arbitrates between Agent A and Agent B:\n    - Encodes both predictions to latent space\n    - Learns latent representation of \"correctness\"\n    - Provides 2/3 vote tiebreaker when agents disagree\n    - Can generate own prediction if both agents are uncertain\n    \n    Total params: ~5M\n    \"\"\"\n    \n    def __init__(self, config: OrcaWhiskeyConfig):\n        super().__init__()\n        self.config = config\n        \n        # Input dimensions\n        self.grid_dim = config.max_grid_size * config.max_grid_size  # Flattened grid\n        self.hidden_dim = config.vae_hidden_dim\n        self.latent_dim = config.vae_latent_dim\n        \n        # Encoders for each agent's output\n        self.encoder_a = VAEEncoder(self.grid_dim, self.hidden_dim, self.latent_dim)\n        self.encoder_b = VAEEncoder(self.grid_dim, self.hidden_dim, self.latent_dim)\n        \n        # Cross-attention between agents\n        self.cross_attention = nn.MultiheadAttention(\n            self.latent_dim,\n            num_heads=4,\n            batch_first=True\n        )\n        \n        # Arbitration head\n        self.arbitration_head = nn.Sequential(\n            nn.Linear(self.latent_dim * 2, self.hidden_dim),\n            nn.GELU(),\n            nn.Linear(self.hidden_dim, 3),  # [vote_a, vote_b, vote_vae]\n            nn.Softmax(dim=-1)\n        )\n        \n        # Decoder (VAE's own prediction)\n        self.decoder = VAEDecoder(self.latent_dim, self.hidden_dim, self.grid_dim)\n        \n        # Confidence estimation\n        self.confidence_head = nn.Sequential(\n            nn.Linear(self.latent_dim, self.hidden_dim // 2),\n            nn.GELU(),\n            nn.Linear(self.hidden_dim // 2, 1),\n            nn.Sigmoid()\n        )\n        \n    def encode_grid_prediction(self, grid: List[List[int]]) -> torch.Tensor:\n        \"\"\"Convert grid prediction to flat tensor\"\"\"\n        device = next(self.parameters()).device\n        padded = grid_utils.pad_grid(grid, self.config.max_grid_size)\n        flat = padded.flatten().astype(np.float32)\n        return torch.FloatTensor(flat).to(device)\n    \n    def decode_grid_prediction(self, flat: torch.Tensor) -> List[List[int]]:\n        \"\"\"Convert flat tensor back to grid\"\"\"\n        grid = flat.view(self.config.max_grid_size, self.config.max_grid_size)\n        grid = torch.clamp(grid, 0, 9).round().long()\n        unpadded = grid_utils.unpad_grid(grid.cpu().numpy())\n        return unpadded.tolist()\n    \n    def forward(self,\n                pred_a: List[List[int]],\n                conf_a: float,\n                pred_b: List[List[int]],\n                conf_b: float,\n                return_traces: bool = False) -> Dict[str, Any]:\n        \"\"\"\n        Mediate between two agent predictions\n        \n        EPISTEMIC REASONING:\n        - INFERENCE: Synthesize understanding from two perspectives\n        - REASONING: Which agent is likely correct?\n        - SKEPTICISM: Are both wrong?\n        - DOUBT: Should I trust my own judgment?\n        - ASSUMPTION: Agents have complementary strengths\n        - ABSTRACTION: Find common latent truth\n        - CONFIDENCE: Calibrate based on agreement\n        \"\"\"\n        device = next(self.parameters()).device\n        \n        # Encode predictions\n        pred_a_flat = self.encode_grid_prediction(pred_a).unsqueeze(0)\n        pred_b_flat = self.encode_grid_prediction(pred_b).unsqueeze(0)\n        \n        # Encode to latent\n        z_a, mu_a, logvar_a = self.encoder_a(pred_a_flat)\n        z_b, mu_b, logvar_b = self.encoder_b(pred_b_flat)\n        \n        # Cross-attention: A attends to B\n        z_a_attended, attn_weights = self.cross_attention(\n            z_a.unsqueeze(1),\n            z_b.unsqueeze(1),\n            z_b.unsqueeze(1)\n        )\n        z_a_attended = z_a_attended.squeeze(1)\n        \n        # Combine latents\n        z_combined = torch.cat([z_a_attended, z_b], dim=-1)\n        \n        # Arbitration vote: [prob_a, prob_b, prob_vae]\n        votes = self.arbitration_head(z_combined).squeeze(0)\n        \n        vote_a, vote_b, vote_vae = votes\n        \n        # DECISION LOGIC (2/3 vote)\n        # If agents agree (predictions similar), trust consensus\n        agreement_threshold = 0.1\n        latent_distance = torch.norm(mu_a - mu_b, p=2)\n        \n        if latent_distance < agreement_threshold:\n            # CONSENSUS: Agents agree\n            final_prediction = pred_a  # Use higher confidence agent\n            final_confidence = max(conf_a, conf_b)\n            decision = \"consensus\"\n            \n            # EPISTEMIC CONFIDENCE: Agreement increases confidence\n            final_confidence = min(final_confidence * 1.1, self.config.max_confidence)\n        \n        else:\n            # DISAGREEMENT: Use voting\n            max_vote = max(vote_a, vote_b, vote_vae)\n            \n            if vote_a == max_vote:\n                final_prediction = pred_a\n                final_confidence = conf_a * vote_a.item()\n                decision = \"vote_agent_a\"\n            \n            elif vote_b == max_vote:\n                final_prediction = pred_b\n                final_confidence = conf_b * vote_b.item()\n                decision = \"vote_agent_b\"\n            \n            else:\n                # VAE wins: Generate own prediction\n                z_vae = (z_a + z_b) / 2  # Average latent\n                pred_vae_flat = self.decoder(z_vae)\n                final_prediction = self.decode_grid_prediction(pred_vae_flat.squeeze(0))\n                \n                # Estimate confidence\n                vae_confidence_raw = self.confidence_head(z_vae).squeeze()\n                final_confidence = vae_confidence_raw.item() * vote_vae.item()\n                decision = \"vote_vae\"\n            \n            # SKEPTICISM: Disagreement reduces confidence\n            final_confidence = final_confidence * 0.85\n        \n        # Cap confidence\n        final_confidence = max(self.config.min_confidence, \n                              min(final_confidence, self.config.max_confidence))\n        \n        result = {\n            'prediction': final_prediction,\n            'confidence': final_confidence,\n            'decision': decision,\n            'votes': {\n                'agent_a': vote_a.item(),\n                'agent_b': vote_b.item(),\n                'vae': vote_vae.item()\n            },\n            'latent_distance': latent_distance.item(),\n            'agreement': latent_distance.item() < agreement_threshold\n        }\n        \n        if return_traces:\n            result['z_a'] = z_a\n            result['z_b'] = z_b\n            result['mu_a'] = mu_a\n            result['mu_b'] = mu_b\n            result['logvar_a'] = logvar_a\n            result['logvar_b'] = logvar_b\n            result['attention_weights'] = attn_weights\n        \n        return result\n    \n    def compute_loss(self,\n                    pred_a: List[List[int]],\n                    pred_b: List[List[int]],\n                    target: List[List[int]]) -> torch.Tensor:\n        \"\"\"\n        Compute VAE training loss\n        \n        Loss components:\n        - Reconstruction: Can VAE reconstruct correct answer from agent outputs?\n        - KL divergence: Regularize latent space\n        - Arbitration: Did VAE vote for correct agent?\n        \"\"\"\n        device = next(self.parameters()).device\n        \n        # Encode\n        pred_a_flat = self.encode_grid_prediction(pred_a).unsqueeze(0)\n        pred_b_flat = self.encode_grid_prediction(pred_b).unsqueeze(0)\n        target_flat = self.encode_grid_prediction(target).unsqueeze(0)\n        \n        # Latent encoding\n        z_a, mu_a, logvar_a = self.encoder_a(pred_a_flat)\n        z_b, mu_b, logvar_b = self.encoder_b(pred_b_flat)\n        \n        # Cross-attention\n        z_a_attended, _ = self.cross_attention(\n            z_a.unsqueeze(1),\n            z_b.unsqueeze(1),\n            z_b.unsqueeze(1)\n        )\n        z_a_attended = z_a_attended.squeeze(1)\n        \n        # Combine\n        z_combined = torch.cat([z_a_attended, z_b], dim=-1)\n        \n        # Arbitration\n        votes = self.arbitration_head(z_combined)\n        \n        # Decode from combined latent\n        z_avg = (z_a + z_b) / 2\n        reconstruction = self.decoder(z_avg)\n        \n        # Reconstruction loss\n        recon_loss = F.mse_loss(reconstruction, target_flat)\n        \n        # KL divergence\n        kl_loss_a = -0.5 * torch.sum(1 + logvar_a - mu_a.pow(2) - logvar_a.exp())\n        kl_loss_b = -0.5 * torch.sum(1 + logvar_b - mu_b.pow(2) - logvar_b.exp())\n        kl_loss = (kl_loss_a + kl_loss_b) / 2\n        \n        # Arbitration loss: Which agent is closer to target?\n        dist_a = F.mse_loss(pred_a_flat, target_flat)\n        dist_b = F.mse_loss(pred_b_flat, target_flat)\n        \n        # Target vote: favor agent with lower distance\n        if dist_a < dist_b:\n            target_vote = torch.FloatTensor([1.0, 0.0, 0.0]).to(device)\n        elif dist_b < dist_a:\n            target_vote = torch.FloatTensor([0.0, 1.0, 0.0]).to(device)\n        else:\n            target_vote = torch.FloatTensor([0.0, 0.0, 1.0]).to(device)\n        \n        arbitration_loss = F.cross_entropy(votes, target_vote.unsqueeze(0))\n        \n        # Combined loss\n        total_loss = recon_loss + 0.1 * kl_loss + arbitration_loss\n        \n        return total_loss\n\n\n# Initialize VAE Mediator\nvae_mediator = VAEMediator(config).to(config.device)\n\n# Count parameters\ntotal_params_vae = sum(p.numel() for p in vae_mediator.parameters())\ntrainable_params_vae = sum(p.numel() for p in vae_mediator.parameters() if p.requires_grad)\n\nprint(\"‚öñÔ∏è  VAE Mediator initialized\")\nprint(f\"   Total params: {total_params_vae:,} ({total_params_vae/1e6:.1f}M)\")\nprint(f\"   Trainable params: {trainable_params_vae:,}\")\nprint(f\"   Latent dim: {config.vae_latent_dim}\")\nprint(f\"   Hidden dim: {config.vae_hidden_dim}\")\nprint(f\"   Arbitration: 2/3 vote (Agent A, Agent B, VAE)\")\nprint(f\"   Epistemic: Consensus boost (1.1x), Disagreement penalty (0.85x)\")\nprint()\n\n# Total system parameters\ntotal_system_params = total_params + total_params_b + total_params_vae\nprint(f\"ü•É TOTAL SYSTEM: {total_system_params:,} parameters ({total_system_params/1e6:.1f}M)\")\nprint(f\"   Agent A (HRM): {total_params/1e6:.1f}M\")\nprint(f\"   Agent B (LLM): {total_params_b/1e6:.1f}M\")\nprint(f\"   VAE Mediator: {total_params_vae/1e6:.1f}M\")\nprint()",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "# CELL 4: LLM AGENT B - ABSTRACT LANGUAGE REASONING\n# Lines: ~700\n# Purpose: Phi-3-mini inspired text-based reasoning agent\n\nclass LLMTransformerBlock(nn.Module):\n    \"\"\"Transformer block for language reasoning\"\"\"\n    \n    def __init__(self, hidden_size: int, num_heads: int, dropout: float = 0.1):\n        super().__init__()\n        self.hidden_size = hidden_size\n        self.num_heads = num_heads\n        self.head_dim = hidden_size // num_heads\n        \n        # Attention\n        self.qkv_proj = nn.Linear(hidden_size, 3 * hidden_size)\n        self.o_proj = nn.Linear(hidden_size, hidden_size)\n        \n        # Feed-forward (SwiGLU-style)\n        self.gate_proj = nn.Linear(hidden_size, hidden_size * 4)\n        self.up_proj = nn.Linear(hidden_size, hidden_size * 4)\n        self.down_proj = nn.Linear(hidden_size * 4, hidden_size)\n        \n        # Norms\n        self.attn_norm = nn.LayerNorm(hidden_size)\n        self.ffn_norm = nn.LayerNorm(hidden_size)\n        \n        self.dropout = nn.Dropout(dropout)\n        \n    def forward(self, x: torch.Tensor, attention_mask: Optional[torch.Tensor] = None) -> Tuple[torch.Tensor, torch.Tensor]:\n        \"\"\"\n        Forward pass\n        Returns: (output, attention_weights)\n        \"\"\"\n        batch_size, seq_len, _ = x.shape\n        \n        # Attention\n        residual = x\n        x = self.attn_norm(x)\n        \n        qkv = self.qkv_proj(x)\n        qkv = qkv.reshape(batch_size, seq_len, 3, self.num_heads, self.head_dim)\n        q, k, v = qkv.unbind(2)\n        q = q.transpose(1, 2)  # [batch, heads, seq, dim]\n        k = k.transpose(1, 2)\n        v = v.transpose(1, 2)\n        \n        # Attention scores\n        attn_scores = torch.matmul(q, k.transpose(-2, -1)) / math.sqrt(self.head_dim)\n        \n        if attention_mask is not None:\n            attn_scores = attn_scores + attention_mask\n        \n        attn_weights = F.softmax(attn_scores, dim=-1)\n        attn_weights = self.dropout(attn_weights)\n        \n        attn_output = torch.matmul(attn_weights, v)\n        attn_output = attn_output.transpose(1, 2).reshape(batch_size, seq_len, self.hidden_size)\n        attn_output = self.o_proj(attn_output)\n        \n        x = residual + self.dropout(attn_output)\n        \n        # Feed-forward (SwiGLU)\n        residual = x\n        x = self.ffn_norm(x)\n        \n        gate = F.silu(self.gate_proj(x))\n        up = self.up_proj(x)\n        x = self.down_proj(gate * up)\n        \n        x = residual + self.dropout(x)\n        \n        return x, attn_weights.mean(dim=1)  # Average across heads\n\n\nclass GridTokenizer:\n    \"\"\"\n    Convert grids to/from text tokens\n    \n    ABSTRACTION: Bridge visual and linguistic domains\n    \"\"\"\n    \n    def __init__(self, vocab_size: int = 32064):\n        self.vocab_size = vocab_size\n        \n        # Special tokens\n        self.PAD_TOKEN = 0\n        self.BOS_TOKEN = 1\n        self.EOS_TOKEN = 2\n        self.SEP_TOKEN = 3\n        \n        # Grid color tokens: 10-19 (for colors 0-9)\n        self.COLOR_OFFSET = 10\n        \n        # Text tokens: 100+ (simple char-based for prototyping)\n        self.TEXT_OFFSET = 100\n        \n        # Character mapping\n        self.chars = \" abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ0123456789.,;:!?-'\\\"()\\n\"\n        self.char_to_idx = {c: i + self.TEXT_OFFSET for i, c in enumerate(self.chars)}\n        self.idx_to_char = {i + self.TEXT_OFFSET: c for i, c in enumerate(self.chars)}\n        \n    def encode_grid_to_text(self, grid: List[List[int]]) -> str:\n        \"\"\"Convert grid to text description\"\"\"\n        arr = np.array(grid)\n        h, w = arr.shape\n        \n        # Count colors\n        color_counts = Counter(arr.flatten())\n        most_common = color_counts.most_common(1)[0][0] if color_counts else 0\n        \n        # Analyze structure\n        is_symmetric_h = np.allclose(arr, np.fliplr(arr))\n        is_symmetric_v = np.allclose(arr, np.flipud(arr))\n        \n        # Generate description\n        desc = f\"Grid {h}x{w}. \"\n        desc += f\"Most common color: {most_common}. \"\n        \n        if is_symmetric_h:\n            desc += \"Horizontally symmetric. \"\n        if is_symmetric_v:\n            desc += \"Vertically symmetric. \"\n        \n        # Add raw grid\n        desc += \"Data: \"\n        for row in arr:\n            desc += \" \".join(str(c) for c in row) + \" | \"\n        \n        return desc.strip()\n    \n    def encode_text(self, text: str, max_length: int = 512) -> List[int]:\n        \"\"\"Encode text to token IDs\"\"\"\n        tokens = [self.BOS_TOKEN]\n        \n        for char in text[:max_length-2]:\n            if char in self.char_to_idx:\n                tokens.append(self.char_to_idx[char])\n            else:\n                tokens.append(self.TEXT_OFFSET)  # Unknown char\n        \n        tokens.append(self.EOS_TOKEN)\n        \n        return tokens\n    \n    def decode_text(self, tokens: List[int]) -> str:\n        \"\"\"Decode token IDs to text\"\"\"\n        chars = []\n        for tok in tokens:\n            if tok == self.BOS_TOKEN or tok == self.EOS_TOKEN or tok == self.PAD_TOKEN:\n                continue\n            if tok in self.idx_to_char:\n                chars.append(self.idx_to_char[tok])\n        \n        return ''.join(chars)\n    \n    def parse_grid_from_text(self, text: str) -> Optional[List[List[int]]]:\n        \"\"\"\n        Extract grid from text output\n        \n        INFERENCE: Parse structured data from natural language\n        \"\"\"\n        try:\n            # Look for \"Data:\" section\n            if \"Data:\" in text:\n                data_section = text.split(\"Data:\")[1].strip()\n                rows = data_section.split(\"|\")\n                \n                grid = []\n                for row in rows:\n                    if row.strip():\n                        nums = [int(x) for x in row.split() if x.isdigit()]\n                        if nums:\n                            grid.append(nums)\n                \n                return grid if grid else None\n            \n            return None\n        except:\n            return None\n\n\nclass LLMAgentB(nn.Module):\n    \"\"\"\n    Language Model Agent B\n    \n    Abstract reasoning through linguistic domain:\n    - Converts grids to text descriptions\n    - Reasons about patterns in language\n    - Generates output grid as text\n    \n    Inspired by Phi-3-mini (3.8B params)\n    Actual params: ~200M (distilled for efficiency)\n    \"\"\"\n    \n    def __init__(self, config: OrcaWhiskeyConfig):\n        super().__init__()\n        self.config = config\n        self.hidden_size = config.llm_hidden_size\n        \n        # Tokenizer\n        self.tokenizer = GridTokenizer(config.llm_vocab_size)\n        \n        # Embeddings\n        self.token_embedding = nn.Embedding(config.llm_vocab_size, self.hidden_size)\n        self.pos_embedding = nn.Embedding(2048, self.hidden_size)\n        \n        # Transformer blocks\n        self.blocks = nn.ModuleList([\n            LLMTransformerBlock(\n                self.hidden_size,\n                config.llm_num_heads\n            ) for _ in range(config.llm_num_layers)\n        ])\n        \n        # Output\n        self.output_norm = nn.LayerNorm(self.hidden_size)\n        self.output_proj = nn.Linear(self.hidden_size, config.llm_vocab_size)\n        \n        # Reasoning head (intermediate reasoning steps)\n        self.reasoning_head = nn.Sequential(\n            nn.Linear(self.hidden_size, self.hidden_size),\n            nn.GELU(),\n            nn.Linear(self.hidden_size, self.hidden_size // 2)\n        )\n        \n        # Confidence estimation\n        self.confidence_head = nn.Sequential(\n            nn.Linear(self.hidden_size, self.hidden_size // 2),\n            nn.GELU(),\n            nn.Linear(self.hidden_size // 2, 1),\n            nn.Sigmoid()\n        )\n        \n    def encode_task_as_text(self, \n                           train_inputs: List[List[List[int]]], \n                           train_outputs: List[List[List[int]]],\n                           test_input: List[List[int]]) -> str:\n        \"\"\"\n        Encode entire task as text prompt\n        \n        INDUCTION + ABSTRACTION: Convert visual patterns to linguistic concepts\n        \"\"\"\n        prompt = \"ARC Task Analysis:\\n\\n\"\n        \n        # Training examples\n        for i, (inp, out) in enumerate(zip(train_inputs, train_outputs)):\n            prompt += f\"Example {i+1}:\\n\"\n            prompt += f\"Input: {self.tokenizer.encode_grid_to_text(inp)}\\n\"\n            prompt += f\"Output: {self.tokenizer.encode_grid_to_text(out)}\\n\\n\"\n        \n        # Pattern analysis (ABSTRACTION)\n        prompt += \"Pattern: \"\n        \n        # Analyze transformations\n        size_changes = []\n        for inp, out in zip(train_inputs, train_outputs):\n            inp_h, inp_w = len(inp), len(inp[0])\n            out_h, out_w = len(out), len(out[0])\n            \n            if out_h < inp_h or out_w < inp_w:\n                size_changes.append(\"smaller\")\n            elif out_h > inp_h or out_w > inp_w:\n                size_changes.append(\"larger\")\n            else:\n                size_changes.append(\"same\")\n        \n        if all(s == \"smaller\" for s in size_changes):\n            prompt += \"Output is cropped or filtered. \"\n        elif all(s == \"larger\" for s in size_changes):\n            prompt += \"Output is expanded or tiled. \"\n        elif all(s == \"same\" for s in size_changes):\n            prompt += \"Output is transformed in-place. \"\n        \n        # Test input\n        prompt += f\"\\n\\nTest Input: {self.tokenizer.encode_grid_to_text(test_input)}\\n\"\n        prompt += \"Test Output: Data: \"\n        \n        return prompt\n    \n    def forward(self,\n                train_inputs: List[List[List[int]]],\n                train_outputs: List[List[List[int]]],\n                test_input: List[List[int]],\n                return_traces: bool = False) -> Dict[str, Any]:\n        \"\"\"\n        Forward pass: Linguistic reasoning\n        \n        EPISTEMIC REASONING:\n        - INDUCTION: Learn pattern from examples via text\n        - ABSTRACTION: Convert visual to conceptual\n        - DEDUCTION: Apply pattern via language generation\n        - REASONING: Chain logical steps in natural language\n        - INFERENCE: Fill in missing details\n        - SKEPTICISM: Question if text pattern matches visual truth\n        - DOUBT: \"Can language capture this visual pattern?\"\n        - FEAR: Unknown unknowns (visual patterns with no words)\n        - HUMILITY: Language may not suffice\n        \"\"\"\n        device = next(self.parameters()).device\n        \n        # Encode task as text\n        prompt = self.encode_task_as_text(train_inputs, train_outputs, test_input)\n        \n        # Tokenize\n        tokens = self.tokenizer.encode_text(prompt, max_length=1024)\n        input_ids = torch.LongTensor(tokens).unsqueeze(0).to(device)\n        \n        # Embeddings\n        seq_len = input_ids.shape[1]\n        pos_ids = torch.arange(seq_len, device=device).unsqueeze(0)\n        \n        x = self.token_embedding(input_ids) + self.pos_embedding(pos_ids)\n        \n        # Transformer blocks\n        attention_maps = []\n        reasoning_traces = []\n        \n        for block in self.blocks:\n            x, attn = block(x)\n            attention_maps.append(attn)\n            \n            # Extract reasoning trace\n            reasoning_trace = self.reasoning_head(x[:, -1, :])  # Last token\n            reasoning_traces.append(reasoning_trace)\n        \n        # Output\n        x = self.output_norm(x)\n        logits = self.output_proj(x)\n        \n        # Generate output tokens (greedy decoding for now)\n        generated_tokens = []\n        max_gen_length = 200\n        \n        current_input = input_ids\n        \n        for _ in range(max_gen_length):\n            # Forward pass on current sequence\n            seq_len = current_input.shape[1]\n            pos_ids = torch.arange(seq_len, device=device).unsqueeze(0)\n            \n            emb = self.token_embedding(current_input) + self.pos_embedding(pos_ids)\n            \n            h = emb\n            for block in self.blocks:\n                h, _ = block(h)\n            \n            h = self.output_norm(h)\n            logits_step = self.output_proj(h)\n            \n            # Get next token\n            next_token = torch.argmax(logits_step[:, -1, :], dim=-1)\n            \n            # Stop if EOS\n            if next_token.item() == self.tokenizer.EOS_TOKEN:\n                break\n            \n            generated_tokens.append(next_token.item())\n            \n            # Append to input\n            current_input = torch.cat([current_input, next_token.unsqueeze(0)], dim=1)\n        \n        # Decode generated text\n        generated_text = self.tokenizer.decode_text(generated_tokens)\n        \n        # Parse grid from generated text\n        pred_grid = self.tokenizer.parse_grid_from_text(generated_text)\n        \n        # Fallback: use test input shape if parsing fails\n        if pred_grid is None:\n            pred_grid = [[0] * len(test_input[0]) for _ in range(len(test_input))]\n        \n        # Confidence estimation\n        confidence_raw = self.confidence_head(x[:, -1, :]).squeeze()\n        \n        # EPISTEMIC CALIBRATION\n        num_examples = len(train_inputs)\n        \n        # Known danger: Small sample\n        if num_examples < 3:\n            confidence = confidence_raw * self.config.small_sample_penalty\n        else:\n            confidence = confidence_raw\n        \n        # DOUBT: Language may miss visual patterns\n        # Apply skepticism penalty\n        language_uncertainty = 0.9  # Inherent limit of language for visual reasoning\n        confidence = confidence * language_uncertainty\n        \n        # Cap at max_confidence\n        confidence = torch.clamp(confidence, self.config.min_confidence, self.config.max_confidence)\n        \n        result = {\n            'prediction': pred_grid,\n            'confidence': confidence.item(),\n            'generated_text': generated_text,\n            'prompt': prompt,\n            'num_examples': num_examples\n        }\n        \n        if return_traces:\n            result['attention_maps'] = attention_maps\n            result['reasoning_traces'] = reasoning_traces\n        \n        return result\n    \n    def compute_loss(self,\n                    train_inputs: List[List[List[int]]],\n                    train_outputs: List[List[List[int]]],\n                    target: List[List[int]]) -> torch.Tensor:\n        \"\"\"\n        Compute generation loss\n        \n        DEDUCTION: Measure how well we apply learned rules\n        \"\"\"\n        device = next(self.parameters()).device\n        \n        # Create training prompt\n        prompt = self.encode_task_as_text(train_inputs[:-1], train_outputs[:-1], train_inputs[-1])\n        \n        # Add target as continuation\n        target_text = self.tokenizer.encode_grid_to_text(target)\n        full_text = prompt + target_text\n        \n        # Tokenize\n        tokens = self.tokenizer.encode_text(full_text, max_length=1024)\n        input_ids = torch.LongTensor(tokens).unsqueeze(0).to(device)\n        \n        # Embeddings\n        seq_len = input_ids.shape[1]\n        pos_ids = torch.arange(seq_len, device=device).unsqueeze(0)\n        \n        x = self.token_embedding(input_ids) + self.pos_embedding(pos_ids)\n        \n        # Forward\n        for block in self.blocks:\n            x, _ = block(x)\n        \n        x = self.output_norm(x)\n        logits = self.output_proj(x)\n        \n        # Compute loss (predict next token)\n        shift_logits = logits[:, :-1, :].contiguous()\n        shift_labels = input_ids[:, 1:].contiguous()\n        \n        loss = F.cross_entropy(\n            shift_logits.view(-1, self.config.llm_vocab_size),\n            shift_labels.view(-1)\n        )\n        \n        return loss\n\n\n# Initialize Agent B\nagent_b = LLMAgentB(config).to(config.device)\n\n# Count parameters\ntotal_params_b = sum(p.numel() for p in agent_b.parameters())\ntrainable_params_b = sum(p.numel() for p in agent_b.parameters() if p.requires_grad)\n\nprint(\"üó£Ô∏è  Agent B (LLM) initialized\")\nprint(f\"   Total params: {total_params_b:,} ({total_params_b/1e6:.1f}M)\")\nprint(f\"   Trainable params: {trainable_params_b:,}\")\nprint(f\"   Architecture: {config.llm_num_layers} transformer blocks\")\nprint(f\"   Hidden size: {config.llm_hidden_size}\")\nprint(f\"   Vocab size: {config.llm_vocab_size}\")\nprint(f\"   Epistemic: Language skepticism (0.9x), Small sample penalty ({config.small_sample_penalty})\")\nprint()",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "# CELL 3: HRM AGENT A - VISUAL PATTERN REASONING\n# Lines: ~600\n# Purpose: Hierarchical Reasoning Model with dual-level architecture\n\nclass RotaryPositionalEmbedding(nn.Module):\n    \"\"\"RoPE for position-aware attention\"\"\"\n    \n    def __init__(self, dim: int, max_seq_len: int = 2048):\n        super().__init__()\n        self.dim = dim\n        inv_freq = 1.0 / (10000 ** (torch.arange(0, dim, 2).float() / dim))\n        self.register_buffer('inv_freq', inv_freq)\n        \n        # Precompute for max_seq_len\n        t = torch.arange(max_seq_len, dtype=torch.float32)\n        freqs = torch.outer(t, inv_freq)\n        self.register_buffer('cos_cached', freqs.cos())\n        self.register_buffer('sin_cached', freqs.sin())\n    \n    def forward(self, x: torch.Tensor, seq_len: int = None):\n        \"\"\"Apply rotary embeddings to x\"\"\"\n        if seq_len is None:\n            seq_len = x.shape[1]\n        \n        cos = self.cos_cached[:seq_len, :]\n        sin = self.sin_cached[:seq_len, :]\n        \n        # Apply rotation\n        x1, x2 = x[..., ::2], x[..., 1::2]\n        rotated = torch.stack([\n            x1 * cos - x2 * sin,\n            x1 * sin + x2 * cos\n        ], dim=-1).flatten(-2)\n        \n        return rotated\n\n\nclass HierarchicalTransformerLayer(nn.Module):\n    \"\"\"Single transformer layer with recurrent state\"\"\"\n    \n    def __init__(self, hidden_size: int, num_heads: int, dropout: float = 0.1):\n        super().__init__()\n        self.hidden_size = hidden_size\n        self.num_heads = num_heads\n        self.head_dim = hidden_size // num_heads\n        \n        # Multi-head attention\n        self.q_proj = nn.Linear(hidden_size, hidden_size)\n        self.k_proj = nn.Linear(hidden_size, hidden_size)\n        self.v_proj = nn.Linear(hidden_size, hidden_size)\n        self.o_proj = nn.Linear(hidden_size, hidden_size)\n        \n        # Feed-forward\n        self.ff1 = nn.Linear(hidden_size, hidden_size * 4)\n        self.ff2 = nn.Linear(hidden_size * 4, hidden_size)\n        \n        # Layer norms\n        self.ln1 = nn.LayerNorm(hidden_size)\n        self.ln2 = nn.LayerNorm(hidden_size)\n        \n        self.dropout = nn.Dropout(dropout)\n        \n    def forward(self, x: torch.Tensor, mask: Optional[torch.Tensor] = None) -> Tuple[torch.Tensor, torch.Tensor]:\n        \"\"\"\n        Forward pass with attention output\n        Returns: (output, attention_weights)\n        \"\"\"\n        batch_size, seq_len, _ = x.shape\n        \n        # Multi-head attention\n        residual = x\n        x = self.ln1(x)\n        \n        q = self.q_proj(x).view(batch_size, seq_len, self.num_heads, self.head_dim).transpose(1, 2)\n        k = self.k_proj(x).view(batch_size, seq_len, self.num_heads, self.head_dim).transpose(1, 2)\n        v = self.v_proj(x).view(batch_size, seq_len, self.num_heads, self.head_dim).transpose(1, 2)\n        \n        # Scaled dot-product attention\n        attn_scores = torch.matmul(q, k.transpose(-2, -1)) / math.sqrt(self.head_dim)\n        \n        if mask is not None:\n            attn_scores = attn_scores.masked_fill(mask == 0, float('-inf'))\n        \n        attn_weights = F.softmax(attn_scores, dim=-1)\n        attn_weights = self.dropout(attn_weights)\n        \n        attn_output = torch.matmul(attn_weights, v)\n        attn_output = attn_output.transpose(1, 2).contiguous().view(batch_size, seq_len, self.hidden_size)\n        attn_output = self.o_proj(attn_output)\n        \n        x = residual + self.dropout(attn_output)\n        \n        # Feed-forward\n        residual = x\n        x = self.ln2(x)\n        x = self.ff2(F.gelu(self.ff1(x)))\n        x = residual + self.dropout(x)\n        \n        return x, attn_weights.mean(dim=1)  # Average across heads\n\n\nclass HighLevelModule(nn.Module):\n    \"\"\"High-level abstract reasoning module\"\"\"\n    \n    def __init__(self, config: OrcaWhiskeyConfig):\n        super().__init__()\n        self.config = config\n        self.hidden_size = config.hrm_hidden_size\n        \n        # Transformer layers\n        self.layers = nn.ModuleList([\n            HierarchicalTransformerLayer(\n                self.hidden_size, \n                config.hrm_num_heads\n            ) for _ in range(config.hrm_num_layers_h)\n        ])\n        \n        # Recurrent state\n        self.state_norm = nn.LayerNorm(self.hidden_size)\n        \n    def forward(self, x: torch.Tensor, state: Optional[torch.Tensor] = None) -> Tuple[torch.Tensor, torch.Tensor, List[torch.Tensor]]:\n        \"\"\"\n        High-level reasoning with recurrent state\n        Returns: (output, new_state, attention_maps)\n        \"\"\"\n        batch_size, seq_len, _ = x.shape\n        \n        # Initialize or use provided state\n        if state is None:\n            state = torch.zeros(batch_size, 1, self.hidden_size, device=x.device)\n        \n        # Concatenate state with input\n        x = torch.cat([state, x], dim=1)\n        \n        # Process through layers\n        attention_maps = []\n        for layer in self.layers:\n            x, attn = layer(x)\n            attention_maps.append(attn)\n        \n        # Extract new state (first token)\n        new_state = x[:, :1, :]\n        new_state = self.state_norm(new_state)\n        \n        # Output (remaining tokens)\n        output = x[:, 1:, :]\n        \n        return output, new_state, attention_maps\n\n\nclass LowLevelModule(nn.Module):\n    \"\"\"Low-level execution module for rapid processing\"\"\"\n    \n    def __init__(self, config: OrcaWhiskeyConfig):\n        super().__init__()\n        self.config = config\n        self.hidden_size = config.hrm_hidden_size\n        \n        # Transformer layers\n        self.layers = nn.ModuleList([\n            HierarchicalTransformerLayer(\n                self.hidden_size,\n                config.hrm_num_heads\n            ) for _ in range(config.hrm_num_layers_l)\n        ])\n        \n        # Recurrent state\n        self.state_norm = nn.LayerNorm(self.hidden_size)\n        \n    def forward(self, x: torch.Tensor, h_output: torch.Tensor, state: Optional[torch.Tensor] = None) -> Tuple[torch.Tensor, torch.Tensor, List[torch.Tensor]]:\n        \"\"\"\n        Low-level execution guided by high-level output\n        Returns: (output, new_state, attention_maps)\n        \"\"\"\n        batch_size, seq_len, _ = x.shape\n        \n        # Initialize state\n        if state is None:\n            state = torch.zeros(batch_size, 1, self.hidden_size, device=x.device)\n        \n        # Combine input with high-level guidance\n        x = x + h_output  # Residual connection from high-level\n        \n        # Concatenate state\n        x = torch.cat([state, x], dim=1)\n        \n        # Process through layers\n        attention_maps = []\n        for layer in self.layers:\n            x, attn = layer(x)\n            attention_maps.append(attn)\n        \n        # Extract new state\n        new_state = x[:, :1, :]\n        new_state = self.state_norm(new_state)\n        \n        # Output\n        output = x[:, 1:, :]\n        \n        return output, new_state, attention_maps\n\n\nclass HRMAgentA(nn.Module):\n    \"\"\"\n    Hierarchical Reasoning Model - Agent A\n    \n    Visual pattern reasoning with dual-level architecture:\n    - High-level: Abstract planning and pattern recognition\n    - Low-level: Rapid execution and transformation\n    \n    Total params: ~27M\n    \"\"\"\n    \n    def __init__(self, config: OrcaWhiskeyConfig):\n        super().__init__()\n        self.config = config\n        self.hidden_size = config.hrm_hidden_size\n        \n        # Grid embedding\n        self.grid_embedding = nn.Embedding(config.vocab_size, self.hidden_size)\n        \n        # Position encoding\n        self.rope = RotaryPositionalEmbedding(self.hidden_size)\n        \n        # Hierarchical modules\n        self.high_level = HighLevelModule(config)\n        self.low_level = LowLevelModule(config)\n        \n        # Output head\n        self.output_norm = nn.LayerNorm(self.hidden_size)\n        self.output_proj = nn.Linear(self.hidden_size, config.vocab_size)\n        \n        # Epistemic layers (confidence estimation)\n        self.confidence_head = nn.Sequential(\n            nn.Linear(self.hidden_size, self.hidden_size // 2),\n            nn.GELU(),\n            nn.Linear(self.hidden_size // 2, 1),\n            nn.Sigmoid()\n        )\n        \n    def encode_grids(self, train_inputs: List[List[List[int]]], train_outputs: List[List[List[int]]]) -> torch.Tensor:\n        \"\"\"\n        Encode training pairs as sequences\n        \n        INDUCTION: Learn patterns from examples (bottom-up)\n        \"\"\"\n        device = next(self.parameters()).device\n        sequences = []\n        \n        for inp, out in zip(train_inputs, train_outputs):\n            # Pad and flatten\n            inp_flat = grid_utils.encode_grid_flat(inp, self.config.max_grid_size)\n            out_flat = grid_utils.encode_grid_flat(out, self.config.max_grid_size)\n            \n            # Concatenate input-output pair\n            pair_seq = np.concatenate([inp_flat, out_flat])\n            sequences.append(torch.LongTensor(pair_seq))\n        \n        # Stack and move to device\n        sequences = torch.stack(sequences).to(device)\n        \n        return sequences\n    \n    def forward(self, \n                train_inputs: List[List[List[int]]], \n                train_outputs: List[List[List[int]]],\n                test_input: List[List[int]],\n                return_traces: bool = False) -> Dict[str, Any]:\n        \"\"\"\n        Forward pass: Reason from examples to prediction\n        \n        EPISTEMIC REASONING:\n        - INDUCTION: Learn from training pairs\n        - ABSTRACTION: Find core transformation pattern\n        - DEDUCTION: Apply to test input\n        - INFERENCE: Bridge gaps in understanding\n        - SKEPTICISM: Question if pattern is real or coincidence\n        - FEAR: Known dangers (small sample), unknown unknowns\n        - HUMILITY: Default to uncertainty\n        \"\"\"\n        device = next(self.parameters()).device\n        batch_size = 1  # Process one task at a time\n        \n        # Encode training examples\n        train_seq = self.encode_grids(train_inputs, train_outputs)\n        train_seq = train_seq.unsqueeze(0)  # [1, num_pairs, seq_len]\n        \n        # Encode test input\n        test_flat = grid_utils.encode_grid_flat(test_input, self.config.max_grid_size)\n        test_seq = torch.LongTensor(test_flat).unsqueeze(0).to(device)  # [1, seq_len]\n        \n        # Embed\n        train_emb = self.grid_embedding(train_seq)  # [1, num_pairs, seq_len, hidden]\n        test_emb = self.grid_embedding(test_seq)    # [1, seq_len, hidden]\n        \n        # Flatten training pairs into single sequence\n        num_pairs = train_emb.shape[1]\n        train_emb = train_emb.view(batch_size, -1, self.hidden_size)  # [1, num_pairs*seq_len, hidden]\n        \n        # HIGH-LEVEL REASONING: Abstract pattern discovery\n        h_state = None\n        h_attention_maps = []\n        \n        for cycle in range(self.config.hrm_h_cycles):\n            train_emb, h_state, h_attn = self.high_level(train_emb, h_state)\n            h_attention_maps.extend(h_attn)\n        \n        # Pool high-level understanding\n        h_summary = train_emb.mean(dim=1, keepdim=True)  # [1, 1, hidden]\n        \n        # Broadcast to test sequence length\n        h_guidance = h_summary.expand(-1, test_emb.shape[1], -1)\n        \n        # LOW-LEVEL EXECUTION: Apply transformation\n        l_state = None\n        l_attention_maps = []\n        \n        for cycle in range(self.config.hrm_l_cycles):\n            test_emb, l_state, l_attn = self.low_level(test_emb, h_guidance, l_state)\n            l_attention_maps.extend(l_attn)\n        \n        # Output prediction\n        output = self.output_norm(test_emb)\n        logits = self.output_proj(output)  # [1, seq_len, vocab_size]\n        \n        # Predict grid\n        predictions = torch.argmax(logits, dim=-1)  # [1, seq_len]\n        \n        # Confidence estimation (epistemic uncertainty)\n        confidence_raw = self.confidence_head(output).mean()\n        \n        # EPISTEMIC CALIBRATION\n        num_examples = len(train_inputs)\n        \n        # Known danger: Small sample size\n        if num_examples < 3:\n            confidence = confidence_raw * self.config.small_sample_penalty\n        else:\n            confidence = confidence_raw\n        \n        # Cap at max_confidence (epistemic humility)\n        confidence = torch.clamp(confidence, self.config.min_confidence, self.config.max_confidence)\n        \n        # Decode prediction\n        pred_grid = grid_utils.decode_grid_flat(\n            predictions.squeeze(0).cpu().numpy(), \n            self.config.max_grid_size\n        )\n        \n        result = {\n            'prediction': pred_grid.tolist(),\n            'confidence': confidence.item(),\n            'logits': logits,\n            'num_examples': num_examples\n        }\n        \n        if return_traces:\n            result['high_level_attention'] = h_attention_maps\n            result['low_level_attention'] = l_attention_maps\n            result['high_level_state'] = h_state\n            result['low_level_state'] = l_state\n        \n        return result\n    \n    def compute_loss(self, \n                     train_inputs: List[List[List[int]]], \n                     train_outputs: List[List[List[int]]],\n                     target: List[List[int]]) -> torch.Tensor:\n        \"\"\"\n        Compute reconstruction loss for training\n        \n        DEDUCTION: Apply learned rules, measure error\n        \"\"\"\n        device = next(self.parameters()).device\n        \n        # Encode everything\n        train_seq = self.encode_grids(train_inputs, train_outputs).unsqueeze(0)\n        target_flat = grid_utils.encode_grid_flat(target, self.config.max_grid_size)\n        target_seq = torch.LongTensor(target_flat).unsqueeze(0).to(device)\n        \n        # Get last training input as \"test\"\n        test_input = train_inputs[-1]\n        \n        # Forward pass\n        output = self.forward(train_inputs[:-1], train_outputs[:-1], test_input)\n        logits = output['logits']\n        \n        # Cross-entropy loss\n        loss = F.cross_entropy(\n            logits.view(-1, self.config.vocab_size),\n            target_seq.view(-1)\n        )\n        \n        return loss\n\n\n# Initialize Agent A\nagent_a = HRMAgentA(config).to(config.device)\n\n# Count parameters\ntotal_params = sum(p.numel() for p in agent_a.parameters())\ntrainable_params = sum(p.numel() for p in agent_a.parameters() if p.requires_grad)\n\nprint(\"ü§ñ Agent A (HRM) initialized\")\nprint(f\"   Total params: {total_params:,} ({total_params/1e6:.1f}M)\")\nprint(f\"   Trainable params: {trainable_params:,}\")\nprint(f\"   Architecture: {config.hrm_num_layers_h}H + {config.hrm_num_layers_l}L layers\")\nprint(f\"   Cycles: {config.hrm_h_cycles} high-level, {config.hrm_l_cycles} low-level\")\nprint(f\"   Epistemic: Humility (max {config.max_confidence}), Small sample penalty ({config.small_sample_penalty})\")\nprint()",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}