{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# UberOrca SubtleGenius v5 - Infrastructure Edition\n",
    "## The Stig-Level Precision Driving - Full Integration\n",
    "\n",
    "**NEW IN V5:**\n",
    "- âœ… Performance Tracker - Real-time coverage + accuracy monitoring\n",
    "- âœ… Fixed Object Transformations - Detection + Transformation together\n",
    "- âœ… Enhanced Logging - Per-solver statistics\n",
    "- âœ… Comprehensive Telemetry - Know what works, data-driven iteration\n",
    "\n",
    "**Integrated Solvers:**\n",
    "- Iteration 4: Rule Induction (HIGHEST PRIORITY)\n",
    "- Iteration 1: Pattern Matching (geometric + color)\n",
    "- Iteration 2: Object Detection (FIXED - actual transformations)\n",
    "- Iteration 3: Ensemble Voting\n",
    "\n",
    "**Infrastructure:**\n",
    "- Transmission: Validation-ready architecture\n",
    "- Engine: Data-driven solver selection\n",
    "- Twin-Turbo: Real-time performance monitoring\n",
    "\n",
    "**Output:**\n",
    "- `/kaggle/working/submission.json` - ARC Prize 2025 format\n",
    "- `/kaggle/working/log.txt` - Detailed execution log + statistics\n",
    "\n",
    "**Status:** âœ… Production Ready - The Stig Edition\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# CELL 1: CONFIGURATION, IMPORTS & PERFORMANCE TRACKER\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "import json\n",
    "import numpy as np\n",
    "import os\n",
    "import time\n",
    "from typing import Dict, List, Any, Tuple, Optional, Callable\n",
    "from datetime import datetime\n",
    "from dataclasses import dataclass, field\n",
    "from collections import Counter, defaultdict\n",
    "\n",
    "print(\"ğŸ‹ UberOrca SubtleGenius v5 - Infrastructure Edition\")\n",
    "print(f\"â° Initialized: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "print(\"ğŸï¸  The Stig-Level Precision Driving - Engaged\\n\")\n",
    "\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# CONFIGURATION\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "class ARC2025Config:\n",
    "    IS_KAGGLE = os.path.exists('/kaggle/input')\n",
    "    \n",
    "    if IS_KAGGLE:\n",
    "        INPUT_PATH = '/kaggle/input/arc-prize-2025/arc-agi_test_challenges.json'\n",
    "        OUTPUT_PATH = '/kaggle/working/submission.json'\n",
    "        LOG_PATH = '/kaggle/working/log.txt'\n",
    "    else:\n",
    "        INPUT_PATH = 'data/arc-agi_test_challenges.json'\n",
    "        OUTPUT_PATH = 'submission.json'\n",
    "        LOG_PATH = 'log.txt'\n",
    "\n",
    "config = ARC2025Config()\n",
    "\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# PERFORMANCE TRACKER (Built-in Infrastructure)\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "@dataclass\n",
    "class SolverStats:\n",
    "    name: str\n",
    "    triggers: int = 0\n",
    "    attempts: int = 0\n",
    "    task_ids: List[str] = field(default_factory=list)\n",
    "\n",
    "class PerformanceTracker:\n",
    "    def __init__(self):\n",
    "        self.solvers: Dict[str, SolverStats] = {}\n",
    "        self.total_tasks = 0\n",
    "        self.start_time = time.time()\n",
    "\n",
    "    def record_trigger(self, solver_name: str, task_id: str):\n",
    "        if solver_name not in self.solvers:\n",
    "            self.solvers[solver_name] = SolverStats(name=solver_name)\n",
    "        stats = self.solvers[solver_name]\n",
    "        stats.triggers += 1\n",
    "        if task_id not in stats.task_ids:\n",
    "            stats.task_ids.append(task_id)\n",
    "\n",
    "    def set_total_tasks(self, total: int):\n",
    "        self.total_tasks = total\n",
    "\n",
    "    def get_coverage(self, solver_name: str) -> float:\n",
    "        if solver_name not in self.solvers or self.total_tasks == 0:\n",
    "            return 0.0\n",
    "        return self.solvers[solver_name].triggers / self.total_tasks\n",
    "\n",
    "    def get_stats_summary(self) -> Dict:\n",
    "        summary = {}\n",
    "        for name, stats in self.solvers.items():\n",
    "            summary[name] = {\n",
    "                'triggers': stats.triggers,\n",
    "                'coverage': self.get_coverage(name)\n",
    "            }\n",
    "        return summary\n",
    "\n",
    "# Global performance tracker\n",
    "perf_tracker = PerformanceTracker()\n",
    "\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# LOGGING SYSTEM\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "class Logger:\n",
    "    def __init__(self, log_path: str):\n",
    "        self.log_path = log_path\n",
    "        self.start_time = time.time()\n",
    "        with open(self.log_path, 'w') as f:\n",
    "            f.write(f\"UberOrca SubtleGenius v5 - Infrastructure Edition\\n\")\n",
    "            f.write(f\"Started: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\\n\")\n",
    "            f.write(f\"Environment: {'Kaggle' if config.IS_KAGGLE else 'Local'}\\n\")\n",
    "            f.write(\"=\"*70 + \"\\n\\n\")\n",
    "    \n",
    "    def log(self, message: str, console: bool = True):\n",
    "        timestamp = time.time() - self.start_time\n",
    "        log_line = f\"[{timestamp:8.2f}s] {message}\\n\"\n",
    "        with open(self.log_path, 'a') as f:\n",
    "            f.write(log_line)\n",
    "        if console:\n",
    "            print(message)\n",
    "\n",
    "logger = Logger(config.LOG_PATH)\n",
    "logger.log(f\"âœ… Configuration loaded\")\n",
    "logger.log(f\"âœ… Performance tracker initialized\")\n",
    "logger.log(f\"   Environment: {'Kaggle' if config.IS_KAGGLE else 'Local'}\")\n",
    "logger.log(f\"   Output: {config.OUTPUT_PATH}\\n\")"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# CELL 2: SUBMISSION VALIDATOR\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "class SubmissionValidator:\n",
    "    @staticmethod\n",
    "    def validate_grid(grid: List[List[int]], context: str = \"\") -> Tuple[bool, str]:\n",
    "        if not isinstance(grid, list):\n",
    "            return False, f\"{context}: Grid must be list\"\n",
    "        if len(grid) == 0:\n",
    "            return False, f\"{context}: Grid cannot be empty\"\n",
    "        if not all(isinstance(row, list) for row in grid):\n",
    "            return False, f\"{context}: Grid must be 2D list\"\n",
    "        if len(grid) > 0:\n",
    "            row_len = len(grid[0])\n",
    "            if not all(len(row) == row_len for row in grid):\n",
    "                return False, f\"{context}: Ragged array\"\n",
    "        for i, row in enumerate(grid):\n",
    "            for j, val in enumerate(row):\n",
    "                if not isinstance(val, (int, np.integer)):\n",
    "                    return False, f\"{context}[{i}][{j}]: Must be int\"\n",
    "                if val < 0 or val > 9:\n",
    "                    return False, f\"{context}[{i}][{j}]: Value {val} not in 0-9\"\n",
    "        return True, \"Valid\"\n",
    "    \n",
    "    @staticmethod\n",
    "    def validate_submission(submission: Dict, test_challenges: Dict) -> Tuple[bool, str]:\n",
    "        logger.log(\"\\n\" + \"=\"*70)\n",
    "        logger.log(\"ğŸ” VALIDATING SUBMISSION\")\n",
    "        logger.log(\"=\"*70)\n",
    "        \n",
    "        if not isinstance(submission, dict):\n",
    "            return False, f\"âŒ Submission must be DICT\"\n",
    "        \n",
    "        logger.log(f\"âœ… Structure: Dictionary\")\n",
    "        \n",
    "        test_task_ids = set(test_challenges.keys())\n",
    "        submission_task_ids = set(submission.keys())\n",
    "        \n",
    "        missing_tasks = test_task_ids - submission_task_ids\n",
    "        if missing_tasks:\n",
    "            return False, f\"âŒ Missing tasks: {list(missing_tasks)[:5]}\"\n",
    "        \n",
    "        logger.log(f\"âœ… Task coverage: {len(submission_task_ids)} tasks\")\n",
    "        \n",
    "        errors = []\n",
    "        for task_id, predictions in submission.items():\n",
    "            if not isinstance(predictions, list):\n",
    "                errors.append(f\"Task {task_id}: predictions must be list\")\n",
    "                continue\n",
    "            \n",
    "            for idx, pred in enumerate(predictions):\n",
    "                if \"attempt_1\" not in pred or \"attempt_2\" not in pred:\n",
    "                    errors.append(f\"Task {task_id}[{idx}]: Missing attempts\")\n",
    "                    continue\n",
    "                \n",
    "                for attempt_key in [\"attempt_1\", \"attempt_2\"]:\n",
    "                    is_valid, msg = SubmissionValidator.validate_grid(\n",
    "                        pred[attempt_key], f\"{task_id}[{idx}][{attempt_key}]\"\n",
    "                    )\n",
    "                    if not is_valid:\n",
    "                        errors.append(msg)\n",
    "            \n",
    "            if len(errors) >= 5:\n",
    "                break\n",
    "        \n",
    "        if errors:\n",
    "            return False, f\"âŒ Errors:\\n\" + \"\\n\".join(errors[:5])\n",
    "        \n",
    "        logger.log(f\"âœ… All predictions valid\")\n",
    "        logger.log(\"=\"*70)\n",
    "        logger.log(\"ğŸ‰ VALIDATION PASSED\")\n",
    "        logger.log(\"=\"*70 + \"\\n\")\n",
    "        \n",
    "        return True, \"Valid\"\n",
    "\n",
    "logger.log(\"âœ… Validator loaded\")"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# CELL 3: SAFE DEFAULTS\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "class SafeDefaults:\n",
    "    @staticmethod\n",
    "    def copy_input(task_data: Dict, test_idx: int = 0) -> List[List[int]]:\n",
    "        try:\n",
    "            return task_data['test'][test_idx]['input']\n",
    "        except:\n",
    "            return [[0]]\n",
    "    \n",
    "    @staticmethod\n",
    "    def convert_to_python_list(grid):\n",
    "        if isinstance(grid, np.ndarray):\n",
    "            return grid.tolist()\n",
    "        return grid\n",
    "\n",
    "logger.log(\"âœ… Safe defaults loaded\")"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# CELL 4: MEGA SOLVER - ALL ITERATIONS + INFRASTRUCTURE INTEGRATED\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# UTILITY FUNCTIONS\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "def grid_to_tuple(grid: List[List[int]]) -> Tuple:\n",
    "    return tuple(tuple(row) for row in grid)\n",
    "\n",
    "def grids_equal(g1: List[List[int]], g2: List[List[int]]) -> bool:\n",
    "    return np.array_equal(np.array(g1), np.array(g2))\n",
    "\n",
    "def shape(grid: List[List[int]]) -> Tuple[int, int]:\n",
    "    if not grid:\n",
    "        return (0, 0)\n",
    "    return (len(grid), len(grid[0]) if grid[0] else 0)\n",
    "\n",
    "def flatten(grid: List[List[int]]) -> List[int]:\n",
    "    return [val for row in grid for val in row]\n",
    "\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# OBJECT DETECTION - FIXED VERSION (Detection + Transformation Together)\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "@dataclass\n",
    "class DetectedObject:\n",
    "    id: int\n",
    "    color: int\n",
    "    pixels: List[Tuple[int, int]]\n",
    "    bounding_box: Tuple[int, int, int, int]\n",
    "    @property\n",
    "    def area(self) -> int:\n",
    "        return len(self.pixels)\n",
    "\n",
    "def find_connected_components(grid: List[List[int]], background_color: int = 0) -> List[DetectedObject]:\n",
    "    arr = np.array(grid)\n",
    "    h, w = arr.shape\n",
    "    visited = np.zeros((h, w), dtype=bool)\n",
    "    objects = []\n",
    "    obj_id = 0\n",
    "    \n",
    "    for i in range(h):\n",
    "        for j in range(w):\n",
    "            if visited[i, j] or arr[i, j] == background_color:\n",
    "                continue\n",
    "            color = arr[i, j]\n",
    "            pixels = []\n",
    "            stack = [(i, j)]\n",
    "            \n",
    "            while stack:\n",
    "                r, c = stack.pop()\n",
    "                if r < 0 or r >= h or c < 0 or c >= w:\n",
    "                    continue\n",
    "                if visited[r, c] or arr[r, c] != color:\n",
    "                    continue\n",
    "                visited[r, c] = True\n",
    "                pixels.append((r, c))\n",
    "                stack.extend([(r-1, c), (r+1, c), (r, c-1), (r, c+1)])\n",
    "            \n",
    "            if pixels:\n",
    "                rows = [p[0] for p in pixels]\n",
    "                cols = [p[1] for p in pixels]\n",
    "                bbox = (min(rows), min(cols), max(rows), max(cols))\n",
    "                objects.append(DetectedObject(obj_id, color, pixels, bbox))\n",
    "                obj_id += 1\n",
    "    \n",
    "    return objects\n",
    "\n",
    "def detect_object_color_change(task_data: Dict) -> Optional[Dict]:\n",
    "    train_pairs = task_data.get('train', [])\n",
    "    if len(train_pairs) < 1:\n",
    "        return None\n",
    "    try:\n",
    "        color_mappings = []\n",
    "        for pair in train_pairs:\n",
    "            inp = pair['input']\n",
    "            out = pair['output']\n",
    "            if np.array(inp).shape != np.array(out).shape:\n",
    "                return None\n",
    "            inp_objects = find_connected_components(inp)\n",
    "            out_objects = find_connected_components(out)\n",
    "            if len(inp_objects) != len(out_objects):\n",
    "                return None\n",
    "            pair_mapping = {}\n",
    "            for inp_obj, out_obj in zip(inp_objects, out_objects):\n",
    "                if sorted(inp_obj.pixels) != sorted(out_obj.pixels):\n",
    "                    return None\n",
    "                if inp_obj.color in pair_mapping:\n",
    "                    if pair_mapping[inp_obj.color] != out_obj.color:\n",
    "                        return None\n",
    "                else:\n",
    "                    pair_mapping[inp_obj.color] = out_obj.color\n",
    "            color_mappings.append(pair_mapping)\n",
    "        if not color_mappings:\n",
    "            return None\n",
    "        first_mapping = color_mappings[0]\n",
    "        if not all(m == first_mapping for m in color_mappings):\n",
    "            return None\n",
    "        if all(k == v for k, v in first_mapping.items()):\n",
    "            return None\n",
    "        return {'type': 'object_color_change', 'color_mapping': first_mapping, 'confidence': 0.85}\n",
    "    except:\n",
    "        return None\n",
    "\n",
    "def apply_object_color_change(test_input: List[List[int]], color_mapping: Dict[int, int]) -> List[List[int]]:\n",
    "    arr = np.array(test_input)\n",
    "    result = arr.copy()\n",
    "    for old_color, new_color in color_mapping.items():\n",
    "        result[arr == old_color] = new_color\n",
    "    return result.tolist()\n",
    "\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# RULE INDUCTION (Iteration 4) - HIGHEST PRIORITY\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "def detect_color_mapping_rule(train_pairs: List[Dict]) -> Optional[Dict]:\n",
    "    if not train_pairs:\n",
    "        return None\n",
    "    try:\n",
    "        inp = train_pairs[0]['input']\n",
    "        out = train_pairs[0]['output']\n",
    "        if shape(inp) != shape(out):\n",
    "            return None\n",
    "        mapping = {}\n",
    "        for (in_val, out_val) in zip(flatten(inp), flatten(out)):\n",
    "            if in_val in mapping:\n",
    "                if mapping[in_val] != out_val:\n",
    "                    return None\n",
    "            else:\n",
    "                mapping[in_val] = out_val\n",
    "        if all(k == v for k, v in mapping.items()):\n",
    "            return None\n",
    "        for pair in train_pairs[1:]:\n",
    "            if shape(pair['input']) != shape(pair['output']):\n",
    "                return None\n",
    "            for (in_val, out_val) in zip(flatten(pair['input']), flatten(pair['output'])):\n",
    "                if mapping.get(in_val, in_val) != out_val:\n",
    "                    return None\n",
    "        return {'type': 'color_mapping', 'mapping': mapping, 'confidence': 0.90}\n",
    "    except:\n",
    "        return None\n",
    "\n",
    "def apply_color_mapping_rule(grid: List[List[int]], mapping: Dict[int, int]) -> List[List[int]]:\n",
    "    result = []\n",
    "    for row in grid:\n",
    "        new_row = [mapping.get(val, val) for val in row]\n",
    "        result.append(new_row)\n",
    "    return result\n",
    "\n",
    "def detect_size_tile_rule(train_pairs: List[Dict]) -> Optional[Dict]:\n",
    "    if not train_pairs:\n",
    "        return None\n",
    "    try:\n",
    "        ratios = []\n",
    "        for pair in train_pairs:\n",
    "            inp_h, inp_w = shape(pair['input'])\n",
    "            out_h, out_w = shape(pair['output'])\n",
    "            if inp_h == 0 or inp_w == 0:\n",
    "                return None\n",
    "            ratios.append((out_h / inp_h, out_w / inp_w))\n",
    "        if not all(r == ratios[0] for r in ratios):\n",
    "            return None\n",
    "        h_ratio, w_ratio = ratios[0]\n",
    "        if h_ratio != int(h_ratio) or w_ratio != int(w_ratio) or (h_ratio == 1.0 and w_ratio == 1.0):\n",
    "            return None\n",
    "        h_scale, w_scale = int(h_ratio), int(w_ratio)\n",
    "        for pair in train_pairs:\n",
    "            expected = np.tile(np.array(pair['input']), (h_scale, w_scale))\n",
    "            if not np.array_equal(expected, np.array(pair['output'])):\n",
    "                return None\n",
    "        return {'type': 'size_tile', 'h_scale': h_scale, 'w_scale': w_scale, 'confidence': 0.95}\n",
    "    except:\n",
    "        return None\n",
    "\n",
    "def apply_size_tile_rule(grid: List[List[int]], h_scale: int, w_scale: int) -> List[List[int]]:\n",
    "    return np.tile(np.array(grid), (h_scale, w_scale)).tolist()\n",
    "\n",
    "def detect_rule_induction(task_data: Dict) -> Optional[Tuple[str, Callable, float]]:\n",
    "    train_pairs = task_data.get('train', [])\n",
    "    if not train_pairs:\n",
    "        return None\n",
    "    rule = detect_color_mapping_rule(train_pairs)\n",
    "    if rule:\n",
    "        mapping = rule['mapping']\n",
    "        return (\"rule_color_map\", lambda g: apply_color_mapping_rule(g, mapping), rule['confidence'])\n",
    "    rule = detect_size_tile_rule(train_pairs)\n",
    "    if rule:\n",
    "        h_scale, w_scale = rule['h_scale'], rule['w_scale']\n",
    "        return (\"rule_tile\", lambda g: apply_size_tile_rule(g, h_scale, w_scale), rule['confidence'])\n",
    "    return None\n",
    "\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# PATTERN MATCHING (Iteration 1)\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "def rotate_90_cw(grid: List[List[int]]) -> List[List[int]]:\n",
    "    return np.rot90(np.array(grid), k=-1).tolist()\n",
    "\n",
    "def flip_horizontal(grid: List[List[int]]) -> List[List[int]]:\n",
    "    return np.fliplr(np.array(grid)).tolist()\n",
    "\n",
    "def flip_vertical(grid: List[List[int]]) -> List[List[int]]:\n",
    "    return np.flipud(np.array(grid)).tolist()\n",
    "\n",
    "def detect_color_mapping(input_grid: List[List[int]], output_grid: List[List[int]]) -> Optional[Dict[int, int]]:\n",
    "    inp = np.array(input_grid)\n",
    "    out = np.array(output_grid)\n",
    "    if inp.shape != out.shape:\n",
    "        return None\n",
    "    mapping = {}\n",
    "    for in_val, out_val in zip(inp.flatten(), out.flatten()):\n",
    "        if in_val in mapping and mapping[in_val] != out_val:\n",
    "            return None\n",
    "        mapping[in_val] = out_val\n",
    "    return mapping if not all(k == v for k, v in mapping.items()) else None\n",
    "\n",
    "def apply_color_mapping(grid: List[List[int]], mapping: Dict[int, int]) -> List[List[int]]:\n",
    "    arr = np.array(grid)\n",
    "    result = arr.copy()\n",
    "    for old_color, new_color in mapping.items():\n",
    "        result[arr == old_color] = new_color\n",
    "    return result.tolist()\n",
    "\n",
    "def detect_pattern_matching(task_data: Dict) -> Optional[Tuple[str, Callable]]:\n",
    "    train_pairs = task_data.get('train', [])\n",
    "    if len(train_pairs) < 1:\n",
    "        return None\n",
    "    transformations = [\n",
    "        (\"rotate_90_cw\", rotate_90_cw),\n",
    "        (\"rotate_180\", lambda g: rotate_90_cw(rotate_90_cw(g))),\n",
    "        (\"flip_horizontal\", flip_horizontal),\n",
    "        (\"flip_vertical\", flip_vertical),\n",
    "    ]\n",
    "    for name, transform in transformations:\n",
    "        if all(grids_equal(transform(pair['input']), pair['output']) for pair in train_pairs):\n",
    "            return (name, transform)\n",
    "    first_mapping = detect_color_mapping(train_pairs[0]['input'], train_pairs[0]['output'])\n",
    "    if first_mapping:\n",
    "        if all(detect_color_mapping(pair['input'], pair['output']) == first_mapping for pair in train_pairs):\n",
    "            return (\"color_mapping\", lambda g: apply_color_mapping(g, first_mapping))\n",
    "    return None\n",
    "\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# SYMMETRY (Iteration 3)\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "def detect_symmetry(grid: List[List[int]]) -> Optional[str]:\n",
    "    arr = np.array(grid)\n",
    "    h, w = arr.shape\n",
    "    left = arr[:, :w//2]\n",
    "    right = np.fliplr(arr[:, w//2:])\n",
    "    if left.shape == right.shape and 0.6 <= np.mean(left == right) < 0.95:\n",
    "        return \"horizontal\"\n",
    "    top = arr[:h//2, :]\n",
    "    bottom = np.flipud(arr[h//2:, :])\n",
    "    if top.shape == bottom.shape and 0.6 <= np.mean(top == bottom) < 0.95:\n",
    "        return \"vertical\"\n",
    "    return None\n",
    "\n",
    "def complete_symmetry(grid: List[List[int]], sym_type: str) -> List[List[int]]:\n",
    "    arr = np.array(grid)\n",
    "    h, w = arr.shape\n",
    "    if sym_type == \"horizontal\":\n",
    "        left = arr[:, :w//2]\n",
    "        return np.hstack([left, np.fliplr(left)]).tolist()\n",
    "    elif sym_type == \"vertical\":\n",
    "        top = arr[:h//2, :]\n",
    "        return np.vstack([top, np.flipud(top)]).tolist()\n",
    "    return grid\n",
    "\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# ENSEMBLE SYSTEM WITH PERFORMANCE TRACKING\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "@dataclass\n",
    "class SolverPrediction:\n",
    "    grid: List[List[int]]\n",
    "    confidence: float\n",
    "    solver_name: str\n",
    "\n",
    "def collect_predictions(test_input: List[List[int]], task_data: Dict, task_id: str) -> List[SolverPrediction]:\n",
    "    predictions = []\n",
    "    \n",
    "    # PRIORITY 1: Rule Induction\n",
    "    try:\n",
    "        result = detect_rule_induction(task_data)\n",
    "        if result:\n",
    "            name, transform, conf = result\n",
    "            pred = SafeDefaults.convert_to_python_list(transform(test_input))\n",
    "            predictions.append(SolverPrediction(pred, conf, name))\n",
    "            perf_tracker.record_trigger(name, task_id)\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    # PRIORITY 2: Pattern matching\n",
    "    try:\n",
    "        result = detect_pattern_matching(task_data)\n",
    "        if result:\n",
    "            name, transform = result\n",
    "            pred = SafeDefaults.convert_to_python_list(transform(test_input))\n",
    "            predictions.append(SolverPrediction(pred, 0.85, f\"pattern_{name}\"))\n",
    "            perf_tracker.record_trigger(f\"pattern_{name}\", task_id)\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    # PRIORITY 3: Object transformations (FIXED)\n",
    "    try:\n",
    "        rule = detect_object_color_change(task_data)\n",
    "        if rule and rule['type'] == 'object_color_change':\n",
    "            pred = apply_object_color_change(test_input, rule['color_mapping'])\n",
    "            predictions.append(SolverPrediction(pred, rule['confidence'], 'object_color_change'))\n",
    "            perf_tracker.record_trigger('object_color_change', task_id)\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    # PRIORITY 4: Symmetry completion\n",
    "    try:\n",
    "        sym_type = detect_symmetry(test_input)\n",
    "        if sym_type:\n",
    "            pred = SafeDefaults.convert_to_python_list(complete_symmetry(test_input, sym_type))\n",
    "            predictions.append(SolverPrediction(pred, 0.75, f\"symmetry_{sym_type}\"))\n",
    "            perf_tracker.record_trigger(f\"symmetry_{sym_type}\", task_id)\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    return predictions\n",
    "\n",
    "def vote_on_predictions(predictions: List[SolverPrediction], attempt: int, test_input: List[List[int]]) -> List[List[int]]:\n",
    "    if not predictions:\n",
    "        return test_input\n",
    "    vote_groups = {}\n",
    "    for pred in predictions:\n",
    "        grid_key = grid_to_tuple(pred.grid)\n",
    "        if grid_key not in vote_groups:\n",
    "            vote_groups[grid_key] = {\"grid\": pred.grid, \"total_confidence\": 0.0, \"solvers\": []}\n",
    "        vote_groups[grid_key][\"total_confidence\"] += pred.confidence\n",
    "        vote_groups[grid_key][\"solvers\"].append(pred.solver_name)\n",
    "    ranked = sorted(vote_groups.values(), key=lambda x: x[\"total_confidence\"], reverse=True)\n",
    "    if attempt == 1:\n",
    "        return ranked[0][\"grid\"]\n",
    "    else:\n",
    "        if ranked[0][\"total_confidence\"] > 0.95:\n",
    "            return ranked[0][\"grid\"]\n",
    "        return ranked[1][\"grid\"] if len(ranked) > 1 else test_input\n",
    "\n",
    "def ensemble_solver(test_input: List[List[int]], task_data: Dict, attempt: int = 1, task_id: str = \"\") -> List[List[int]]:\n",
    "    try:\n",
    "        predictions = collect_predictions(test_input, task_data, task_id)\n",
    "        if predictions:\n",
    "            solver_names = [p.solver_name for p in predictions]\n",
    "            logger.log(f\"  Task {task_id}: {len(predictions)} solvers â†’ {solver_names}\", console=False)\n",
    "        result = vote_on_predictions(predictions, attempt, test_input)\n",
    "        return SafeDefaults.convert_to_python_list(result)\n",
    "    except Exception as e:\n",
    "        logger.log(f\"  âš ï¸  Task {task_id} error: {str(e)[:60]}\", console=False)\n",
    "        return test_input\n",
    "\n",
    "logger.log(\"âœ… Mega Solver loaded (v5 - Infrastructure Edition)\")\n",
    "logger.log(\"   - Rule Induction (HIGHEST PRIORITY)\")\n",
    "logger.log(\"   - Pattern Matching\")\n",
    "logger.log(\"   - Object Transformations (FIXED)\")\n",
    "logger.log(\"   - Symmetry Completion\")\n",
    "logger.log(\"   - Performance Tracking (ENABLED)\\n\")"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# CELL 5: SUBMISSION GENERATOR WITH PERFORMANCE TRACKING\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "def generate_submission(test_challenges: Dict) -> Dict:\n",
    "    logger.log(\"\\n\" + \"=\"*70)\n",
    "    logger.log(\"ğŸ”¨ GENERATING SUBMISSION\")\n",
    "    logger.log(\"=\"*70)\n",
    "    \n",
    "    submission = {}\n",
    "    total_tasks = len(test_challenges)\n",
    "    perf_tracker.set_total_tasks(total_tasks)\n",
    "    start_time = time.time()\n",
    "    \n",
    "    for task_idx, (task_id, task_data) in enumerate(test_challenges.items(), 1):\n",
    "        if task_idx % 50 == 0:\n",
    "            elapsed = time.time() - start_time\n",
    "            rate = task_idx / elapsed if elapsed > 0 else 0\n",
    "            remaining = (total_tasks - task_idx) / rate if rate > 0 else 0\n",
    "            logger.log(f\"  Progress: {task_idx}/{total_tasks} ({task_idx/total_tasks*100:.1f}%) | \"\n",
    "                      f\"Rate: {rate:.1f} tasks/sec | ETA: {remaining/60:.1f}min\")\n",
    "        \n",
    "        task_predictions = []\n",
    "        for test_idx in range(len(task_data['test'])):\n",
    "            test_input = task_data['test'][test_idx]['input']\n",
    "            attempt_1 = ensemble_solver(test_input, task_data, attempt=1, task_id=task_id)\n",
    "            attempt_2 = ensemble_solver(test_input, task_data, attempt=2, task_id=task_id)\n",
    "            task_predictions.append({\n",
    "                \"attempt_1\": SafeDefaults.convert_to_python_list(attempt_1),\n",
    "                \"attempt_2\": SafeDefaults.convert_to_python_list(attempt_2)\n",
    "            })\n",
    "        submission[task_id] = task_predictions\n",
    "    \n",
    "    elapsed = time.time() - start_time\n",
    "    logger.log(f\"\\nâœ… Generated {total_tasks} tasks in {elapsed:.1f}s\")\n",
    "    logger.log(\"=\"*70 + \"\\n\")\n",
    "    \n",
    "    # Performance report\n",
    "    logger.log(\"\\n\" + \"=\"*70)\n",
    "    logger.log(\"ğŸ“Š PERFORMANCE STATISTICS\")\n",
    "    logger.log(\"=\"*70)\n",
    "    \n",
    "    stats = perf_tracker.get_stats_summary()\n",
    "    if stats:\n",
    "        logger.log(f\"  {'Solver':<30} {'Triggers':>10} {'Coverage':>12}\")\n",
    "        logger.log(f\"  {'-'*30} {'-'*10} {'-'*12}\")\n",
    "        for solver, data in sorted(stats.items(), key=lambda x: x[1]['coverage'], reverse=True):\n",
    "            logger.log(f\"  {solver:<30} {data['triggers']:>10} {data['coverage']*100:>11.1f}%\")\n",
    "    \n",
    "    logger.log(\"=\"*70 + \"\\n\")\n",
    "    \n",
    "    return submission\n",
    "\n",
    "logger.log(\"âœ… Submission generator loaded\")"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# CELL 6: MAIN EXECUTION\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "def main():\n",
    "    logger.log(\"\\n\" + \"=\"*70)\n",
    "    logger.log(\"ğŸ‹ UBERORCA SUBTLEGENIUS V5 - THE STIG EDITION\")\n",
    "    logger.log(\"=\"*70)\n",
    "    logger.log(f\"Environment: {'Kaggle' if config.IS_KAGGLE else 'Local'}\")\n",
    "    logger.log(f\"Output: {config.OUTPUT_PATH}\")\n",
    "    logger.log(\"=\"*70 + \"\\n\")\n",
    "    \n",
    "    logger.log(\"ğŸ“‚ Loading test challenges...\")\n",
    "    try:\n",
    "        with open(config.INPUT_PATH, 'r') as f:\n",
    "            test_challenges = json.load(f)\n",
    "        logger.log(f\"âœ… Loaded {len(test_challenges)} tasks\\n\")\n",
    "    except Exception as e:\n",
    "        logger.log(f\"âŒ Failed to load: {e}\")\n",
    "        return\n",
    "    \n",
    "    submission = generate_submission(test_challenges)\n",
    "    \n",
    "    is_valid, msg = SubmissionValidator.validate_submission(submission, test_challenges)\n",
    "    if not is_valid:\n",
    "        logger.log(f\"âŒ VALIDATION FAILED: {msg}\")\n",
    "        return\n",
    "    \n",
    "    logger.log(\"ğŸ’¾ Saving submission...\")\n",
    "    with open(config.OUTPUT_PATH, 'w') as f:\n",
    "        json.dump(submission, f, indent=2)\n",
    "    \n",
    "    file_size = os.path.getsize(config.OUTPUT_PATH)\n",
    "    logger.log(f\"âœ… Saved: {config.OUTPUT_PATH} ({file_size:,} bytes)\")\n",
    "    \n",
    "    logger.log(\"\\n\" + \"=\"*70)\n",
    "    logger.log(\"ğŸ‰ EXECUTION COMPLETE - THE STIG HAS DRIVEN\")\n",
    "    logger.log(\"=\"*70)\n",
    "    logger.log(f\"Submission: {config.OUTPUT_PATH}\")\n",
    "    logger.log(f\"Log: {config.LOG_PATH}\")\n",
    "    logger.log(f\"Status: âœ… READY FOR KAGGLE\")\n",
    "    logger.log(\"=\"*70 + \"\\n\")\n",
    "    \n",
    "    print(f\"\\nğŸ“ Log: {config.LOG_PATH}\")\n",
    "    print(f\"ğŸ“Š Submission: {config.OUTPUT_PATH}\")\n",
    "    print(f\"âœ… UNLEASHED!\\n\")\n",
    "\n",
    "# RUN IT\n",
    "main()"
   ],
   "outputs": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
