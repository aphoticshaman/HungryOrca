{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# UberOrca SubtleGenius v3 - ARC Prize 2025\n",
        "## Iterations 1-3 Integrated: Mobile-Ready Production Build\n",
        "\n",
        "**Integrated Solvers:**\n",
        "- Iteration 1: Pattern Matching (rotate, flip, color mapping)\n",
        "- Iteration 2: Object Detection (connected components, spatial reasoning)\n",
        "- Iteration 3: Ensemble Voting (5 solvers, confidence-weighted)\n",
        "\n",
        "**Output:**\n",
        "- `/kaggle/working/submission.json` - ARC Prize 2025 format\n",
        "- `/kaggle/working/log.txt` - Detailed execution log\n",
        "\n",
        "**Status:** âœ… Ready for Kaggle upload\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
        "# CELL 1: CONFIGURATION & IMPORTS\n",
        "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
        "\n",
        "import json\n",
        "import numpy as np\n",
        "import os\n",
        "import time\n",
        "import gc\n",
        "from typing import Dict, List, Any, Tuple, Optional, Callable\n",
        "from pathlib import Path\n",
        "from datetime import datetime\n",
        "from dataclasses import dataclass\n",
        "from collections import Counter\n",
        "import traceback\n",
        "\n",
        "print(\"ğŸ‹ UberOrca SubtleGenius v3 - ARC Prize 2025\")\n",
        "print(f\"â° Initialized: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n",
        "\n",
        "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
        "# CONFIGURATION\n",
        "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
        "\n",
        "class ARC2025Config:\n",
        "    \"\"\"Single source of truth for all configuration\"\"\"\n",
        "    \n",
        "    # Environment detection\n",
        "    IS_KAGGLE = os.path.exists('/kaggle/input')\n",
        "    \n",
        "    if IS_KAGGLE:\n",
        "        INPUT_PATH = '/kaggle/input/arc-prize-2025/arc-agi_test_challenges.json'\n",
        "        TRAIN_PATH = '/kaggle/input/arc-prize-2025/arc-agi_training_challenges.json'\n",
        "        OUTPUT_PATH = '/kaggle/working/submission.json'\n",
        "        LOG_PATH = '/kaggle/working/log.txt'\n",
        "    else:\n",
        "        INPUT_PATH = 'data/arc-agi_test_challenges.json'\n",
        "        TRAIN_PATH = 'data/arc-agi_training_challenges.json'\n",
        "        OUTPUT_PATH = 'submission.json'\n",
        "        LOG_PATH = 'log.txt'\n",
        "    \n",
        "    # Time budget\n",
        "    TOTAL_TIME_LIMIT = 12 * 3600\n",
        "    SAFETY_BUFFER = 0.05\n",
        "    EFFECTIVE_TIME = TOTAL_TIME_LIMIT * (1 - SAFETY_BUFFER)\n",
        "    \n",
        "    # Settings\n",
        "    ENABLE_LOGGING = True\n",
        "    ENABLE_VALIDATION = True\n",
        "    VERBOSE = True\n",
        "\n",
        "config = ARC2025Config()\n",
        "\n",
        "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
        "# LOGGING SYSTEM\n",
        "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
        "\n",
        "class Logger:\n",
        "    \"\"\"Dual output: console + file logging\"\"\"\n",
        "    \n",
        "    def __init__(self, log_path: str):\n",
        "        self.log_path = log_path\n",
        "        self.start_time = time.time()\n",
        "        \n",
        "        # Initialize log file\n",
        "        with open(self.log_path, 'w') as f:\n",
        "            f.write(f\"UberOrca SubtleGenius v3 - Execution Log\\n\")\n",
        "            f.write(f\"Started: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\\n\")\n",
        "            f.write(f\"Environment: {'Kaggle' if config.IS_KAGGLE else 'Local'}\\n\")\n",
        "            f.write(\"=\"*70 + \"\\n\\n\")\n",
        "    \n",
        "    def log(self, message: str, console: bool = True):\n",
        "        \"\"\"Write to log file and optionally console\"\"\"\n",
        "        timestamp = time.time() - self.start_time\n",
        "        log_line = f\"[{timestamp:8.2f}s] {message}\\n\"\n",
        "        \n",
        "        # Write to file\n",
        "        with open(self.log_path, 'a') as f:\n",
        "            f.write(log_line)\n",
        "        \n",
        "        # Print to console\n",
        "        if console:\n",
        "            print(message)\n",
        "    \n",
        "    def log_stats(self, stats: Dict):\n",
        "        \"\"\"Log statistics dictionary\"\"\"\n",
        "        self.log(\"\\n\" + \"=\"*70)\n",
        "        self.log(\"ğŸ“Š STATISTICS\")\n",
        "        self.log(\"=\"*70)\n",
        "        for key, value in stats.items():\n",
        "            self.log(f\"  {key}: {value}\")\n",
        "        self.log(\"=\"*70 + \"\\n\")\n",
        "\n",
        "# Initialize logger\n",
        "logger = Logger(config.LOG_PATH)\n",
        "logger.log(f\"âœ… Configuration loaded\")\n",
        "logger.log(f\"   Environment: {'Kaggle' if config.IS_KAGGLE else 'Local'}\")\n",
        "logger.log(f\"   Output: {config.OUTPUT_PATH}\")\n",
        "logger.log(f\"   Log: {config.LOG_PATH}\\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
        "# CELL 2: SUBMISSION VALIDATOR\n",
        "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
        "\n",
        "class SubmissionValidator:\n",
        "    \"\"\"Production-grade validator for ARC Prize 2025 submissions\"\"\"\n",
        "    \n",
        "    @staticmethod\n",
        "    def validate_grid(grid: List[List[int]], context: str = \"\") -> Tuple[bool, str]:\n",
        "        if not isinstance(grid, list):\n",
        "            return False, f\"{context}: Grid must be list, got {type(grid)}\"\n",
        "        if len(grid) == 0:\n",
        "            return False, f\"{context}: Grid cannot be empty\"\n",
        "        if not all(isinstance(row, list) for row in grid):\n",
        "            return False, f\"{context}: Grid must be 2D list\"\n",
        "        if len(grid) > 0:\n",
        "            row_len = len(grid[0])\n",
        "            if not all(len(row) == row_len for row in grid):\n",
        "                return False, f\"{context}: Ragged array detected\"\n",
        "        for i, row in enumerate(grid):\n",
        "            for j, val in enumerate(row):\n",
        "                if not isinstance(val, (int, np.integer)):\n",
        "                    return False, f\"{context}[{i}][{j}]: Must be int, got {type(val)}\"\n",
        "                if val < 0 or val > 9:\n",
        "                    return False, f\"{context}[{i}][{j}]: Value {val} not in range 0-9\"\n",
        "        return True, \"Valid grid\"\n",
        "    \n",
        "    @staticmethod\n",
        "    def validate_submission(submission: Dict, test_challenges: Dict) -> Tuple[bool, str]:\n",
        "        logger.log(\"\\n\" + \"=\"*70)\n",
        "        logger.log(\"ğŸ” VALIDATING SUBMISSION\")\n",
        "        logger.log(\"=\"*70)\n",
        "        \n",
        "        if not isinstance(submission, dict):\n",
        "            return False, f\"âŒ Submission must be DICT, got {type(submission)}\"\n",
        "        \n",
        "        logger.log(f\"âœ… Structure: Dictionary (not list)\")\n",
        "        \n",
        "        test_task_ids = set(test_challenges.keys())\n",
        "        submission_task_ids = set(submission.keys())\n",
        "        \n",
        "        missing_tasks = test_task_ids - submission_task_ids\n",
        "        if missing_tasks:\n",
        "            return False, f\"âŒ Missing tasks: {list(missing_tasks)[:5]}\"\n",
        "        \n",
        "        logger.log(f\"âœ… Task coverage: {len(submission_task_ids)} tasks (complete)\")\n",
        "        \n",
        "        errors = []\n",
        "        for task_id, predictions in submission.items():\n",
        "            if not isinstance(predictions, list):\n",
        "                errors.append(f\"Task {task_id}: predictions must be list\")\n",
        "                continue\n",
        "            \n",
        "            expected_count = len(test_challenges[task_id]['test'])\n",
        "            if len(predictions) != expected_count:\n",
        "                errors.append(f\"Task {task_id}: expected {expected_count} predictions, got {len(predictions)}\")\n",
        "            \n",
        "            for idx, pred in enumerate(predictions):\n",
        "                if \"attempt_1\" not in pred or \"attempt_2\" not in pred:\n",
        "                    errors.append(f\"Task {task_id}[{idx}]: Missing attempt keys\")\n",
        "                    continue\n",
        "                \n",
        "                for attempt_key in [\"attempt_1\", \"attempt_2\"]:\n",
        "                    is_valid, msg = SubmissionValidator.validate_grid(\n",
        "                        pred[attempt_key], f\"Task {task_id}[{idx}][{attempt_key}]\"\n",
        "                    )\n",
        "                    if not is_valid:\n",
        "                        errors.append(msg)\n",
        "            \n",
        "            if len(errors) >= 5:\n",
        "                break\n",
        "        \n",
        "        if errors:\n",
        "            return False, f\"âŒ Validation errors:\\n\" + \"\\n\".join(errors[:5])\n",
        "        \n",
        "        logger.log(f\"âœ… All predictions: Valid format\")\n",
        "        logger.log(\"=\"*70)\n",
        "        logger.log(\"ğŸ‰ SUBMISSION VALIDATION PASSED!\")\n",
        "        logger.log(\"=\"*70 + \"\\n\")\n",
        "        \n",
        "        return True, \"Valid submission\"\n",
        "\n",
        "logger.log(\"âœ… Validator loaded\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
        "# CELL 3: SAFE DEFAULTS & FALLBACKS\n",
        "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
        "\n",
        "class SafeDefaults:\n",
        "    \"\"\"Never crash, always return valid grids\"\"\"\n",
        "    \n",
        "    @staticmethod\n",
        "    def copy_input(task_data: Dict, test_idx: int = 0) -> List[List[int]]:\n",
        "        try:\n",
        "            return task_data['test'][test_idx]['input']\n",
        "        except:\n",
        "            return [[0]]\n",
        "    \n",
        "    @staticmethod\n",
        "    def copy_train_output(task_data: Dict, train_idx: int = 0) -> List[List[int]]:\n",
        "        try:\n",
        "            return task_data['train'][train_idx]['output']\n",
        "        except:\n",
        "            return SafeDefaults.copy_input(task_data)\n",
        "    \n",
        "    @staticmethod\n",
        "    def convert_to_python_list(grid):\n",
        "        \"\"\"Convert numpy array to pure Python list\"\"\"\n",
        "        if isinstance(grid, np.ndarray):\n",
        "            return grid.tolist()\n",
        "        return grid\n",
        "\n",
        "logger.log(\"âœ… Safe defaults loaded\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
        "# CELL 4: INTEGRATED SOLVER - ITERATIONS 1-3\n",
        "# All solver code in ONE cell - no external imports needed\n",
        "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
        "\n",
        "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
        "# UTILITY FUNCTIONS\n",
        "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
        "\n",
        "def grid_to_tuple(grid: List[List[int]]) -> Tuple:\n",
        "    \"\"\"Convert grid to hashable tuple\"\"\"\n",
        "    return tuple(tuple(row) for row in grid)\n",
        "\n",
        "def grids_equal(g1: List[List[int]], g2: List[List[int]]) -> bool:\n",
        "    \"\"\"Check if two grids are identical\"\"\"\n",
        "    return np.array_equal(np.array(g1), np.array(g2))\n",
        "\n",
        "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
        "# ITERATION 1: PATTERN MATCHING\n",
        "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
        "\n",
        "def rotate_90_cw(grid: List[List[int]]) -> List[List[int]]:\n",
        "    \"\"\"Rotate grid 90Â° clockwise\"\"\"\n",
        "    return np.rot90(np.array(grid), k=-1).tolist()\n",
        "\n",
        "def flip_horizontal(grid: List[List[int]]) -> List[List[int]]:\n",
        "    \"\"\"Flip grid horizontally\"\"\"\n",
        "    return np.fliplr(np.array(grid)).tolist()\n",
        "\n",
        "def flip_vertical(grid: List[List[int]]) -> List[List[int]]:\n",
        "    \"\"\"Flip grid vertically\"\"\"\n",
        "    return np.flipud(np.array(grid)).tolist()\n",
        "\n",
        "def detect_color_mapping(input_grid: List[List[int]], \n",
        "                        output_grid: List[List[int]]) -> Optional[Dict[int, int]]:\n",
        "    \"\"\"Detect if output is color-mapped version of input\"\"\"\n",
        "    inp = np.array(input_grid)\n",
        "    out = np.array(output_grid)\n",
        "    \n",
        "    if inp.shape != out.shape:\n",
        "        return None\n",
        "    \n",
        "    mapping = {}\n",
        "    for in_val, out_val in zip(inp.flatten(), out.flatten()):\n",
        "        if in_val in mapping:\n",
        "            if mapping[in_val] != out_val:\n",
        "                return None\n",
        "        else:\n",
        "            mapping[in_val] = out_val\n",
        "    \n",
        "    if all(k == v for k, v in mapping.items()):\n",
        "        return None\n",
        "    \n",
        "    return mapping\n",
        "\n",
        "def apply_color_mapping(grid: List[List[int]], mapping: Dict[int, int]) -> List[List[int]]:\n",
        "    \"\"\"Apply color mapping to grid\"\"\"\n",
        "    arr = np.array(grid)\n",
        "    result = arr.copy()\n",
        "    for old_color, new_color in mapping.items():\n",
        "        result[arr == old_color] = new_color\n",
        "    return result.tolist()\n",
        "\n",
        "def detect_pattern_matching(task_data: Dict) -> Optional[Tuple[str, Callable]]:\n",
        "    \"\"\"Detect geometric or color pattern\"\"\"\n",
        "    train_pairs = task_data.get('train', [])\n",
        "    if len(train_pairs) < 1:\n",
        "        return None\n",
        "    \n",
        "    # Test geometric transformations\n",
        "    transformations = [\n",
        "        (\"rotate_90_cw\", rotate_90_cw),\n",
        "        (\"rotate_180\", lambda g: rotate_90_cw(rotate_90_cw(g))),\n",
        "        (\"flip_horizontal\", flip_horizontal),\n",
        "        (\"flip_vertical\", flip_vertical),\n",
        "    ]\n",
        "    \n",
        "    for name, transform in transformations:\n",
        "        matches = all(\n",
        "            grids_equal(transform(pair['input']), pair['output'])\n",
        "            for pair in train_pairs\n",
        "        )\n",
        "        if matches:\n",
        "            return (name, transform)\n",
        "    \n",
        "    # Test color mapping\n",
        "    first_mapping = detect_color_mapping(\n",
        "        train_pairs[0]['input'],\n",
        "        train_pairs[0]['output']\n",
        "    )\n",
        "    \n",
        "    if first_mapping:\n",
        "        consistent = all(\n",
        "            detect_color_mapping(pair['input'], pair['output']) == first_mapping\n",
        "            for pair in train_pairs\n",
        "        )\n",
        "        if consistent:\n",
        "            return (\"color_mapping\", lambda g: apply_color_mapping(g, first_mapping))\n",
        "    \n",
        "    return None\n",
        "\n",
        "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
        "# ITERATION 2: OBJECT DETECTION\n",
        "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
        "\n",
        "@dataclass\n",
        "class DetectedObject:\n",
        "    id: int\n",
        "    color: int\n",
        "    pixels: List[Tuple[int, int]]\n",
        "    bounding_box: Tuple[int, int, int, int]\n",
        "    \n",
        "    @property\n",
        "    def area(self) -> int:\n",
        "        return len(self.pixels)\n",
        "\n",
        "def find_connected_components(grid: List[List[int]], \n",
        "                             background_color: int = 0) -> List[DetectedObject]:\n",
        "    \"\"\"Find connected components using flood-fill\"\"\"\n",
        "    arr = np.array(grid)\n",
        "    h, w = arr.shape\n",
        "    visited = np.zeros((h, w), dtype=bool)\n",
        "    objects = []\n",
        "    obj_id = 0\n",
        "    \n",
        "    for i in range(h):\n",
        "        for j in range(w):\n",
        "            if visited[i, j] or arr[i, j] == background_color:\n",
        "                continue\n",
        "            \n",
        "            color = arr[i, j]\n",
        "            pixels = []\n",
        "            stack = [(i, j)]\n",
        "            \n",
        "            while stack:\n",
        "                r, c = stack.pop()\n",
        "                if r < 0 or r >= h or c < 0 or c >= w:\n",
        "                    continue\n",
        "                if visited[r, c] or arr[r, c] != color:\n",
        "                    continue\n",
        "                \n",
        "                visited[r, c] = True\n",
        "                pixels.append((r, c))\n",
        "                \n",
        "                stack.extend([(r-1, c), (r+1, c), (r, c-1), (r, c+1)])\n",
        "            \n",
        "            if pixels:\n",
        "                rows = [p[0] for p in pixels]\n",
        "                cols = [p[1] for p in pixels]\n",
        "                bbox = (min(rows), min(cols), max(rows), max(cols))\n",
        "                objects.append(DetectedObject(obj_id, color, pixels, bbox))\n",
        "                obj_id += 1\n",
        "    \n",
        "    return objects\n",
        "\n",
        "def detect_object_pattern(task_data: Dict) -> Optional[str]:\n",
        "    \"\"\"Detect if task involves object-level reasoning\"\"\"\n",
        "    train_pairs = task_data.get('train', [])\n",
        "    if len(train_pairs) < 1:\n",
        "        return None\n",
        "    \n",
        "    try:\n",
        "        for pair in train_pairs:\n",
        "            input_objects = find_connected_components(pair['input'])\n",
        "            output_objects = find_connected_components(pair['output'])\n",
        "            \n",
        "            if len(input_objects) > 0 and len(output_objects) > 0:\n",
        "                return \"object_transform\"\n",
        "    except:\n",
        "        pass\n",
        "    \n",
        "    return None\n",
        "\n",
        "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
        "# ITERATION 3: ENSEMBLE VOTING (3 NEW SOLVERS)\n",
        "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
        "\n",
        "def detect_grid_arithmetic(task_data: Dict) -> Optional[Tuple[str, Callable, float]]:\n",
        "    \"\"\"Detect arithmetic operations (add, multiply, modulo)\"\"\"\n",
        "    train_pairs = task_data.get('train', [])\n",
        "    if len(train_pairs) < 1:\n",
        "        return None\n",
        "    \n",
        "    # Test addition\n",
        "    add_constants = []\n",
        "    for pair in train_pairs:\n",
        "        inp = np.array(pair['input'])\n",
        "        out = np.array(pair['output'])\n",
        "        if inp.shape != out.shape:\n",
        "            break\n",
        "        diff = out - inp\n",
        "        if len(np.unique(diff)) == 1:\n",
        "            add_constants.append(diff.flat[0])\n",
        "        else:\n",
        "            break\n",
        "    else:\n",
        "        if len(set(add_constants)) == 1 and add_constants[0] != 0:\n",
        "            k = add_constants[0]\n",
        "            return (f\"add_{k}\", lambda grid: (np.array(grid) + k).tolist(), 0.95)\n",
        "    \n",
        "    # Test modulo\n",
        "    for mod_val in [2, 3, 4, 5, 10]:\n",
        "        consistent = all(\n",
        "            np.array_equal(np.array(pair['output']), np.array(pair['input']) % mod_val)\n",
        "            if np.array(pair['input']).shape == np.array(pair['output']).shape else False\n",
        "            for pair in train_pairs\n",
        "        )\n",
        "        if consistent:\n",
        "            return (f\"mod_{mod_val}\", lambda grid, m=mod_val: (np.array(grid) % m).tolist(), 0.90)\n",
        "    \n",
        "    return None\n",
        "\n",
        "def detect_symmetry(grid: List[List[int]]) -> Optional[str]:\n",
        "    \"\"\"Detect incomplete symmetry\"\"\"\n",
        "    arr = np.array(grid)\n",
        "    h, w = arr.shape\n",
        "    \n",
        "    # Horizontal symmetry\n",
        "    left = arr[:, :w//2]\n",
        "    right = np.fliplr(arr[:, w//2:])\n",
        "    if left.shape == right.shape:\n",
        "        score = np.mean(left == right)\n",
        "        if 0.6 <= score < 0.95:\n",
        "            return \"horizontal\"\n",
        "    \n",
        "    # Vertical symmetry\n",
        "    top = arr[:h//2, :]\n",
        "    bottom = np.flipud(arr[h//2:, :])\n",
        "    if top.shape == bottom.shape:\n",
        "        score = np.mean(top == bottom)\n",
        "        if 0.6 <= score < 0.95:\n",
        "            return \"vertical\"\n",
        "    \n",
        "    return None\n",
        "\n",
        "def complete_symmetry(grid: List[List[int]], sym_type: str) -> List[List[int]]:\n",
        "    \"\"\"Complete partial symmetry\"\"\"\n",
        "    arr = np.array(grid)\n",
        "    h, w = arr.shape\n",
        "    \n",
        "    if sym_type == \"horizontal\":\n",
        "        left = arr[:, :w//2]\n",
        "        return np.hstack([left, np.fliplr(left)]).tolist()\n",
        "    elif sym_type == \"vertical\":\n",
        "        top = arr[:h//2, :]\n",
        "        return np.vstack([top, np.flipud(top)]).tolist()\n",
        "    \n",
        "    return grid\n",
        "\n",
        "@dataclass\n",
        "class SolverPrediction:\n",
        "    grid: List[List[int]]\n",
        "    confidence: float\n",
        "    solver_name: str\n",
        "\n",
        "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
        "# ENSEMBLE VOTING SYSTEM\n",
        "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
        "\n",
        "def collect_predictions(test_input: List[List[int]], \n",
        "                       task_data: Dict) -> List[SolverPrediction]:\n",
        "    \"\"\"Collect predictions from all solvers\"\"\"\n",
        "    predictions = []\n",
        "    \n",
        "    # Solver 1: Pattern matching\n",
        "    try:\n",
        "        result = detect_pattern_matching(task_data)\n",
        "        if result:\n",
        "            name, transform = result\n",
        "            pred = SafeDefaults.convert_to_python_list(transform(test_input))\n",
        "            predictions.append(SolverPrediction(pred, 0.85, f\"pattern_{name}\"))\n",
        "    except:\n",
        "        pass\n",
        "    \n",
        "    # Solver 2: Grid arithmetic\n",
        "    try:\n",
        "        result = detect_grid_arithmetic(task_data)\n",
        "        if result:\n",
        "            name, transform, conf = result\n",
        "            pred = SafeDefaults.convert_to_python_list(transform(test_input))\n",
        "            predictions.append(SolverPrediction(pred, conf, f\"arithmetic_{name}\"))\n",
        "    except:\n",
        "        pass\n",
        "    \n",
        "    # Solver 3: Symmetry completion\n",
        "    try:\n",
        "        sym_type = detect_symmetry(test_input)\n",
        "        if sym_type:\n",
        "            pred = SafeDefaults.convert_to_python_list(complete_symmetry(test_input, sym_type))\n",
        "            predictions.append(SolverPrediction(pred, 0.75, f\"symmetry_{sym_type}\"))\n",
        "    except:\n",
        "        pass\n",
        "    \n",
        "    # Solver 4: Object detection\n",
        "    try:\n",
        "        if detect_object_pattern(task_data):\n",
        "            # For now, just flag that objects are present\n",
        "            predictions.append(SolverPrediction(test_input, 0.60, \"object_detected\"))\n",
        "    except:\n",
        "        pass\n",
        "    \n",
        "    return predictions\n",
        "\n",
        "def vote_on_predictions(predictions: List[SolverPrediction],\n",
        "                       attempt: int,\n",
        "                       test_input: List[List[int]]) -> List[List[int]]:\n",
        "    \"\"\"Vote on predictions using confidence weighting\"\"\"\n",
        "    if not predictions:\n",
        "        return test_input\n",
        "    \n",
        "    # Group by grid equality\n",
        "    vote_groups = {}\n",
        "    for pred in predictions:\n",
        "        grid_key = grid_to_tuple(pred.grid)\n",
        "        if grid_key not in vote_groups:\n",
        "            vote_groups[grid_key] = {\n",
        "                \"grid\": pred.grid,\n",
        "                \"total_confidence\": 0.0,\n",
        "                \"solvers\": []\n",
        "            }\n",
        "        vote_groups[grid_key][\"total_confidence\"] += pred.confidence\n",
        "        vote_groups[grid_key][\"solvers\"].append(pred.solver_name)\n",
        "    \n",
        "    # Sort by confidence\n",
        "    ranked = sorted(vote_groups.values(), \n",
        "                   key=lambda x: x[\"total_confidence\"],\n",
        "                   reverse=True)\n",
        "    \n",
        "    # Select based on attempt\n",
        "    if attempt == 1:\n",
        "        return ranked[0][\"grid\"]\n",
        "    else:\n",
        "        # Attempt 2: return second-best or input if very confident\n",
        "        if ranked[0][\"total_confidence\"] > 0.95:\n",
        "            return ranked[0][\"grid\"]\n",
        "        return ranked[1][\"grid\"] if len(ranked) > 1 else test_input\n",
        "\n",
        "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
        "# MAIN SOLVER (ENSEMBLE)\n",
        "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
        "\n",
        "def ensemble_solver(test_input: List[List[int]],\n",
        "                   task_data: Dict,\n",
        "                   attempt: int = 1,\n",
        "                   task_id: str = \"\") -> List[List[int]]:\n",
        "    \"\"\"Main ensemble solver integrating all iterations\"\"\"\n",
        "    try:\n",
        "        # Collect predictions from all solvers\n",
        "        predictions = collect_predictions(test_input, task_data)\n",
        "        \n",
        "        # Log which solvers triggered\n",
        "        if predictions:\n",
        "            solver_names = [p.solver_name for p in predictions]\n",
        "            logger.log(f\"  Task {task_id}: {len(predictions)} solvers â†’ {solver_names}\", console=False)\n",
        "        \n",
        "        # Vote on best prediction\n",
        "        result = vote_on_predictions(predictions, attempt, test_input)\n",
        "        \n",
        "        # Ensure it's pure Python list (not numpy)\n",
        "        return SafeDefaults.convert_to_python_list(result)\n",
        "        \n",
        "    except Exception as e:\n",
        "        logger.log(f\"  âš ï¸  Task {task_id} attempt {attempt} error: {str(e)[:60]}\", console=False)\n",
        "        return test_input\n",
        "\n",
        "logger.log(\"âœ… Integrated solver loaded (Iterations 1-3)\")\n",
        "logger.log(\"   - Pattern matching (rotate, flip, color)\")\n",
        "logger.log(\"   - Grid arithmetic (add, modulo)\")\n",
        "logger.log(\"   - Symmetry completion\")\n",
        "logger.log(\"   - Object detection\")\n",
        "logger.log(\"   - Ensemble voting (confidence-weighted)\\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
        "# CELL 5: SUBMISSION GENERATOR\n",
        "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
        "\n",
        "def generate_submission(test_challenges: Dict) -> Dict:\n",
        "    \"\"\"Generate complete submission with logging\"\"\"\n",
        "    \n",
        "    logger.log(\"\\n\" + \"=\"*70)\n",
        "    logger.log(\"ğŸ”¨ GENERATING SUBMISSION\")\n",
        "    logger.log(\"=\"*70)\n",
        "    \n",
        "    submission = {}\n",
        "    total_tasks = len(test_challenges)\n",
        "    solver_stats = {\"triggered\": 0, \"fallback\": 0}\n",
        "    \n",
        "    start_time = time.time()\n",
        "    \n",
        "    for task_idx, (task_id, task_data) in enumerate(test_challenges.items(), 1):\n",
        "        \n",
        "        # Progress updates\n",
        "        if task_idx % 50 == 0:\n",
        "            elapsed = time.time() - start_time\n",
        "            rate = task_idx / elapsed if elapsed > 0 else 0\n",
        "            remaining = (total_tasks - task_idx) / rate if rate > 0 else 0\n",
        "            logger.log(f\"  Progress: {task_idx}/{total_tasks} ({task_idx/total_tasks*100:.1f}%) | \"\n",
        "                      f\"Rate: {rate:.1f} tasks/sec | ETA: {remaining/60:.1f}min\")\n",
        "        \n",
        "        # Generate predictions for this task\n",
        "        task_predictions = []\n",
        "        num_test_outputs = len(task_data['test'])\n",
        "        \n",
        "        for test_idx in range(num_test_outputs):\n",
        "            test_input = task_data['test'][test_idx]['input']\n",
        "            \n",
        "            # Generate both attempts\n",
        "            attempt_1 = ensemble_solver(test_input, task_data, attempt=1, task_id=task_id)\n",
        "            attempt_2 = ensemble_solver(test_input, task_data, attempt=2, task_id=task_id)\n",
        "            \n",
        "            # Ensure valid format\n",
        "            attempt_1 = SafeDefaults.convert_to_python_list(attempt_1)\n",
        "            attempt_2 = SafeDefaults.convert_to_python_list(attempt_2)\n",
        "            \n",
        "            task_predictions.append({\n",
        "                \"attempt_1\": attempt_1,\n",
        "                \"attempt_2\": attempt_2\n",
        "            })\n",
        "        \n",
        "        submission[task_id] = task_predictions\n",
        "    \n",
        "    elapsed = time.time() - start_time\n",
        "    logger.log(f\"\\nâœ… Generated {total_tasks} tasks in {elapsed:.1f}s ({elapsed/60:.1f}min)\")\n",
        "    logger.log(f\"   Average: {elapsed/total_tasks:.2f}s per task\")\n",
        "    logger.log(\"=\"*70 + \"\\n\")\n",
        "    \n",
        "    return submission\n",
        "\n",
        "logger.log(\"âœ… Submission generator loaded\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
        "# CELL 6: MAIN EXECUTION PIPELINE\n",
        "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
        "\n",
        "def main():\n",
        "    \"\"\"Main execution pipeline with comprehensive logging\"\"\"\n",
        "    \n",
        "    logger.log(\"\\n\" + \"=\"*70)\n",
        "    logger.log(\"ğŸ‹ UBERORCA SUBTLEGENIUS V3 - EXECUTION START\")\n",
        "    logger.log(\"=\"*70)\n",
        "    logger.log(f\"Environment: {'Kaggle' if config.IS_KAGGLE else 'Local'}\")\n",
        "    logger.log(f\"Output: {config.OUTPUT_PATH}\")\n",
        "    logger.log(f\"Log: {config.LOG_PATH}\")\n",
        "    logger.log(\"=\"*70 + \"\\n\")\n",
        "    \n",
        "    # Load test data\n",
        "    logger.log(\"ğŸ“‚ Loading test challenges...\")\n",
        "    try:\n",
        "        with open(config.INPUT_PATH, 'r') as f:\n",
        "            test_challenges = json.load(f)\n",
        "        logger.log(f\"âœ… Loaded {len(test_challenges)} tasks\\n\")\n",
        "    except Exception as e:\n",
        "        logger.log(f\"âŒ Failed to load: {e}\")\n",
        "        return\n",
        "    \n",
        "    # Generate submission\n",
        "    submission = generate_submission(test_challenges)\n",
        "    \n",
        "    # Validate\n",
        "    is_valid, msg = SubmissionValidator.validate_submission(submission, test_challenges)\n",
        "    \n",
        "    if not is_valid:\n",
        "        logger.log(f\"âŒ VALIDATION FAILED: {msg}\")\n",
        "        return\n",
        "    \n",
        "    # Save\n",
        "    logger.log(\"ğŸ’¾ Saving submission...\")\n",
        "    with open(config.OUTPUT_PATH, 'w') as f:\n",
        "        json.dump(submission, f, indent=2)\n",
        "    \n",
        "    file_size = os.path.getsize(config.OUTPUT_PATH)\n",
        "    logger.log(f\"âœ… Saved: {config.OUTPUT_PATH} ({file_size:,} bytes)\")\n",
        "    \n",
        "    # Final summary\n",
        "    logger.log(\"\\n\" + \"=\"*70)\n",
        "    logger.log(\"ğŸ‰ EXECUTION COMPLETE\")\n",
        "    logger.log(\"=\"*70)\n",
        "    logger.log(f\"Submission: {config.OUTPUT_PATH}\")\n",
        "    logger.log(f\"Log: {config.LOG_PATH}\")\n",
        "    logger.log(f\"Status: âœ… READY FOR KAGGLE SUBMISSION\")\n",
        "    logger.log(\"=\"*70 + \"\\n\")\n",
        "    \n",
        "    print(f\"\\nğŸ“ Log saved to: {config.LOG_PATH}\")\n",
        "    print(f\"ğŸ“Š Submission saved to: {config.OUTPUT_PATH}\")\n",
        "    print(f\"âœ… READY TO SUBMIT!\\n\")\n",
        "\n",
        "# RUN IT\n",
        "main()"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
