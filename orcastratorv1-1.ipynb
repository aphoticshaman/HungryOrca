{"cells":[{"source":"<a href=\"https://www.kaggle.com/code/ryancardwell/orcastratorv1-1?scriptVersionId=271493342\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown"},{"cell_type":"code","execution_count":1,"id":"03462c3d","metadata":{"execution":{"iopub.execute_input":"2025-10-28T09:21:00.052306Z","iopub.status.busy":"2025-10-28T09:21:00.051941Z","iopub.status.idle":"2025-10-28T09:21:05.658444Z","shell.execute_reply":"2025-10-28T09:21:05.657326Z"},"papermill":{"duration":5.613711,"end_time":"2025-10-28T09:21:05.660118","exception":false,"start_time":"2025-10-28T09:21:00.046407","status":"completed"},"tags":[]},"outputs":[{"name":"stdout","output_type":"stream","text":["Using device: cpu\n"]}],"source":["#   Cell 1\n","import torch\n","import torch.nn as nn\n","import numpy as np\n","import json\n","import time\n","import logging\n","from functools import lru_cache\n","from collections import defaultdict, deque\n","from scipy import ndimage\n","import math\n","from typing import List, Dict, Tuple, Optional, Any\n","\n","# Enhanced configuration for S-tier performance\n","class ARCConfig:\n","    def __init__(self):\n","        # Extended runtime (5x from user)\n","        self.MAX_BEAM_DEPTH = 12\n","        self.MAX_BEAM_WIDTH = 64\n","        self.MAX_RUNTIME_PER_TASK = 300\n","        self.MAX_PROGRAM_LENGTH = 20\n","        \n","        # 3D projection enhancements\n","        self.USE_3D_EARLY = True\n","        self.USE_3D_ON_HARD = True\n","        self.MAX_3D_DEPTH = 8\n","        self.ENABLE_3D_PATTERNS = True\n","        \n","        # Enhanced search strategies\n","        self.DYNAMIC_BEAM_SCALING = True\n","        self.ADAPTIVE_DEPTH = True\n","        self.MULTI_PASS_SEARCH = True\n","        self.EARLY_TERMINATION_PATIENCE = 5\n","        \n","        # Neural and caching\n","        self.VETO_THRESHOLD = 0.25\n","        self.LRU_CACHE_SIZE = 5000\n","        self.PRUNE_EARLY = True\n","        \n","        # Novel insights integration\n","        self.FUZZY_ALPHA = 0.5\n","        self.QUANTUM_DIMS = 4\n","        self.HYPER_DIM = 128\n","        self.CONFIDENCE_DECAY = 0.95\n","        \n","        # Original optimized parameters\n","        self.SEED = 1337\n","        self.BG = 0\n","        self.MAX_GRID_SIDE = 60\n","        self.ATTEMPTS_PER_TEST = 2\n","\n","config = ARCConfig()\n","\n","# Device setup\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","print(f\"Using device: {device}\")\n","\n","# Enhanced logging\n","logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n","logger = logging.getLogger(__name__)\n","\n","# Core utilities with 3D support\n","def grid_to_numpy(grid):\n","    return np.array(grid, dtype=np.int32)\n","\n","def numpy_to_grid(arr):\n","    return arr.tolist()\n","\n","@lru_cache(maxsize=config.LRU_CACHE_SIZE)\n","def calculate_iou(grid1, grid2):\n","    if isinstance(grid1, list):\n","        grid1 = grid_to_numpy(grid1)\n","    if isinstance(grid2, list):\n","        grid2 = grid_to_numpy(grid2)\n","    \n","    intersection = np.sum((grid1 > 0) & (grid2 > 0))\n","    union = np.sum((grid1 > 0) | (grid2 > 0))\n","    return intersection / union if union > 0 else 0.0\n","\n","def extract_palette(grid):\n","    if isinstance(grid, list):\n","        grid = grid_to_numpy(grid)\n","    unique, counts = np.unique(grid, return_counts=True)\n","    return dict(zip(unique, counts))\n","\n","# 3D Orthogonal Projection System (from user)\n","class OrthogonalProjector3D:\n","    def __init__(self):\n","        self.projection_cache = {}\n","        self.voxel_cache = {}\n","        \n","    def grid_to_3d_voxels(self, grid, depth_layers=4):\n","        cache_key = (tuple(map(tuple, grid)), depth_layers)\n","        if cache_key in self.voxel_cache:\n","            return self.voxel_cache[cache_key]\n","            \n","        if isinstance(grid, list):\n","            grid = grid_to_numpy(grid)\n","            \n","        h, w = grid.shape\n","        voxels = np.zeros((h, w, depth_layers), dtype=np.int32)\n","        \n","        for i in range(h):\n","            for j in range(w):\n","                color_val = grid[i, j]\n","                if color_val > 0:\n","                    depth = min(depth_layers - 1, color_val % depth_layers)\n","                    voxels[i, j, depth] = color_val\n","                    \n","        self.voxel_cache[cache_key] = voxels\n","        return voxels\n","    \n","    def project_3d_to_2d(self, voxels, projection_type='front'):\n","        cache_key = (voxels.tobytes(), projection_type)\n","        if cache_key in self.projection_cache:\n","            return self.projection_cache[cache_key]\n","            \n","        h, w, d = voxels.shape\n","        \n","        if projection_type == 'front':\n","            projection = np.max(voxels, axis=2)\n","        elif projection_type == 'top':\n","            projection = np.max(voxels, axis=0).T\n","        elif projection_type == 'side':\n","            projection = np.max(voxels, axis=1)\n","        elif projection_type == 'composite':\n","            front = np.max(voxels, axis=2)\n","            top = np.max(voxels, axis=0).T\n","            side = np.max(voxels, axis=1)\n","            max_h = max(front.shape[0], top.shape[0], side.shape[0])\n","            max_w = max(front.shape[1], top.shape[1], side.shape[1])\n","            projection = np.zeros((max_h, max_w), dtype=np.int32)\n","            projection[:front.shape[0], :front.shape[1]] = np.maximum(\n","                projection[:front.shape[0], :front.shape[1]], front)\n","        else:\n","            projection = np.max(voxels, axis=2)\n","            \n","        self.projection_cache[cache_key] = projection\n","        return projection\n","\n","projector_3d = OrthogonalProjector3D()\n","\n","# Enhanced NeuroBudget (from user)\n","class EnhancedNeuroBudget:\n","    def __init__(self, total_budget=1.0):\n","        self.total_budget = total_budget\n","        self.remaining_budget = total_budget\n","        self.task_budgets = {}\n","        self.complexity_scores = {}\n","        \n","    def allocate_task_budget(self, task_id, complexity_score):\n","        base_budget = 0.1\n","        complexity_factor = min(2.0, 1.0 + complexity_score)\n","        allocated = base_budget * complexity_factor\n","        self.task_budgets[task_id] = allocated\n","        return allocated\n","    \n","    def should_continue(self, task_id, elapsed_time):\n","        if task_id not in self.task_budgets:\n","            return True\n","        budget_used = elapsed_time / config.MAX_RUNTIME_PER_TASK\n","        return budget_used < self.task_budgets[task_id]"]},{"cell_type":"code","execution_count":2,"id":"583f07db","metadata":{"execution":{"iopub.execute_input":"2025-10-28T09:21:05.669622Z","iopub.status.busy":"2025-10-28T09:21:05.668575Z","iopub.status.idle":"2025-10-28T09:21:05.700287Z","shell.execute_reply":"2025-10-28T09:21:05.69917Z"},"papermill":{"duration":0.038235,"end_time":"2025-10-28T09:21:05.702046","exception":false,"start_time":"2025-10-28T09:21:05.663811","status":"completed"},"tags":[]},"outputs":[],"source":["#  Cell 2\n","class EnhancedDSL:\n","    def __init__(self):\n","        self.primitives = {}\n","        self._register_primitives()\n","        self.dynamic_color_primitives = {}\n","        \n","    def _register_primitives(self):\n","        # Geometric transformations (optimized)\n","        self.primitives['rotate_90'] = lambda g: np.rot90(g, 1)\n","        self.primitives['rotate_180'] = lambda g: np.rot90(g, 2)\n","        self.primitives['rotate_270'] = lambda g: np.rot90(g, 3)\n","        self.primitives['flip_horizontal'] = lambda g: np.fliplr(g)\n","        self.primitives['flip_vertical'] = lambda g: np.flipud(g)\n","        self.primitives['transpose'] = lambda g: g.T\n","        \n","        # Color operations\n","        self.primitives['color_invert'] = self.color_invert\n","        self.primitives['color_replace'] = self.color_replace\n","        self.primitives['swap_most_common'] = self.swap_most_common\n","        \n","        # Size operations\n","        self.primitives['scale_2x'] = self.scale_2x\n","        self.primitives['scale_3x'] = self.scale_3x\n","        self.primitives['tile_2x2'] = lambda g: np.tile(g, (2, 2))\n","        self.primitives['crop_to_content'] = self.crop_to_content\n","        \n","        # Object operations\n","        self.primitives['extract_largest_object'] = self.extract_largest_object\n","        self.primitives['gravity_down'] = self.gravity_down\n","        \n","        # 3D projection operations (from user)\n","        self.primitives['project_3d_front'] = lambda g: projector_3d.project_3d_to_2d(\n","            projector_3d.grid_to_3d_voxels(g, config.MAX_3D_DEPTH), 'front')\n","        self.primitives['project_3d_top'] = lambda g: projector_3d.project_3d_to_2d(\n","            projector_3d.grid_to_3d_voxels(g, config.MAX_3D_DEPTH), 'top')\n","        self.primitives['project_3d_side'] = lambda g: projector_3d.project_3d_to_2d(\n","            projector_3d.grid_to_3d_voxels(g, config.MAX_3D_DEPTH), 'side')\n","        \n","        # Novel Insight 1: Adaptive scaling with fuzzy tuning\n","        self.primitives['adaptive_scale'] = lambda g, factor=2: np.repeat(np.repeat(g, factor, axis=0), factor, axis=1)\n","        \n","        # Novel Insight 2: Symmetry-aware operations\n","        self.primitives['symmetry_reflect'] = lambda g: np.maximum(g, np.fliplr(g))\n","        \n","        # Novel Insight 3: Density-based filling\n","        self.primitives['density_fill'] = lambda g: np.where(g == 0, np.mean(g[g > 0]) if np.any(g > 0) else 0, g)\n","        \n","        # Novel Insight 4: Pattern extrapolation\n","        self.primitives['pattern_extrapolate'] = self.pattern_extrapolate\n","        \n","        # Novel Insight 5: Causal inference modeling\n","        self.primitives['causal_infer'] = lambda g: np.cumsum(g, axis=0)\n","        \n","        # Novel Insight 6: Fuzzy thresholding\n","        self.primitives['fuzzy_threshold'] = lambda g: np.where(g > config.FUZZY_ALPHA * np.mean(g), g, 0)\n","        \n","        # Novel Insight 7: Quantum-inspired superposition\n","        self.primitives['quantum_superpose'] = self.quantum_superpose\n","        \n","        # Novel Insight 8: Bio-evolutionary adaptation\n","        self.primitives['bio_evolve'] = self.bio_evolve\n","        \n","        # Novel Insight 9: Multi-resolution analysis\n","        self.primitives['multi_resolution'] = self.multi_resolution\n","        \n","        # Novel Insight 10: Recursive synthesis\n","        self.primitives['recursive_synth'] = self.recursive_synth\n","\n","    def generate_dynamic_color_primitives(self, train_colors):\n","        for color_in, color_out in train_colors:\n","            if color_in != color_out:\n","                prim_name = f'color_{color_in}_to_{color_out}'\n","                self.dynamic_color_primitives[prim_name] = \\\n","                    lambda grid, cin=color_in, cout=color_out: self.color_replace(grid, cin, cout)\n","        self.primitives.update(self.dynamic_color_primitives)\n","    \n","    # Core operation implementations\n","    def color_invert(self, grid):\n","        inverted = grid.copy()\n","        mask = grid > 0\n","        if np.any(mask):\n","            max_color = np.max(grid[mask])\n","            inverted[mask] = max_color - grid[mask] + 1\n","        return inverted\n","    \n","    def color_replace(self, grid, color_from, color_to):\n","        replaced = grid.copy()\n","        replaced[grid == color_from] = color_to\n","        return replaced\n","    \n","    def swap_most_common(self, grid):\n","        if np.any(grid > 0):\n","            unique, counts = np.unique(grid[grid > 0], return_counts=True)\n","            if len(unique) >= 2:\n","                most_common = unique[np.argmax(counts)]\n","                second_common = unique[np.argsort(counts)[-2]]\n","                return self.color_replace(grid, most_common, second_common)\n","        return grid\n","    \n","    def scale_2x(self, grid):\n","        h, w = grid.shape\n","        scaled = np.zeros((h*2, w*2), dtype=grid.dtype)\n","        for i in range(h):\n","            for j in range(w):\n","                scaled[i*2:(i+1)*2, j*2:(j+1)*2] = grid[i, j]\n","        return scaled\n","    \n","    def scale_3x(self, grid):\n","        h, w = grid.shape\n","        scaled = np.zeros((h*3, w*3), dtype=grid.dtype)\n","        for i in range(h):\n","            for j in range(w):\n","                scaled[i*3:(i+1)*3, j*3:(j+1)*3] = grid[i, j]\n","        return scaled\n","    \n","    def crop_to_content(self, grid):\n","        if not np.any(grid > 0):\n","            return grid\n","        \n","        rows = np.any(grid > 0, axis=1)\n","        cols = np.any(grid > 0, axis=0)\n","        \n","        rmin, rmax = np.where(rows)[0][[0, -1]]\n","        cmin, cmax = np.where(cols)[0][[0, -1]]\n","        \n","        return grid[rmin:rmax+1, cmin:cmax+1]\n","    \n","    def extract_largest_object(self, grid):\n","        labeled, num_features = ndimage.label(grid > 0)\n","        if num_features == 0:\n","            return grid\n","        \n","        largest_component = None\n","        largest_size = 0\n","        for i in range(1, num_features + 1):\n","            component_mask = (labeled == i)\n","            size = np.sum(component_mask)\n","            if size > largest_size:\n","                largest_size = size\n","                largest_component = component_mask\n","        \n","        result = np.zeros_like(grid)\n","        result[largest_component] = grid[largest_component]\n","        return result\n","    \n","    def gravity_down(self, grid):\n","        result = np.zeros_like(grid)\n","        h, w = grid.shape\n","        \n","        for j in range(w):\n","            col = grid[:, j]\n","            non_zero = col[col > 0]\n","            if len(non_zero) > 0:\n","                result[h-len(non_zero):, j] = non_zero\n","        return result\n","    \n","    # Novel insight implementations\n","    def pattern_extrapolate(self, grid):\n","        h, w = grid.shape\n","        if h % 2 == 0:\n","            return np.tile(grid[:h//2], (2, 1))\n","        return grid\n","    \n","    def quantum_superpose(self, grid):\n","        # Quantum-inspired superposition of multiple transformations\n","        transformations = [\n","            lambda g: g,\n","            lambda g: np.rot90(g, 1),\n","            lambda g: np.fliplr(g),\n","            lambda g: np.flipud(g)\n","        ]\n","        weights = [0.4, 0.2, 0.2, 0.2]  # Fuzzy weights\n","        result = np.zeros_like(grid)\n","        \n","        for transform, weight in zip(transformations, weights):\n","            result = np.maximum(result, transform(grid) * weight)\n","        \n","        return np.clip(result, 0, 9).astype(int)\n","    \n","    def bio_evolve(self, grid, generations=3):\n","        # Bio-inspired evolutionary optimization\n","        current = grid.copy()\n","        for gen in range(generations):\n","            mutation = current + np.random.randint(-1, 2, size=current.shape)\n","            mutation = np.clip(mutation, 0, 9)\n","            \n","            # Fitness: prefer patterns with higher structure\n","            current_fitness = np.std(current)\n","            mutation_fitness = np.std(mutation)\n","            \n","            if mutation_fitness > current_fitness:\n","                current = mutation\n","        return current\n","    \n","    def multi_resolution(self, grid):\n","        # Multi-resolution analysis\n","        h, w = grid.shape\n","        if h > 4 and w > 4:\n","            # Downsample then upsample to capture patterns\n","            downsampled = grid[::2, ::2]\n","            upsampled = np.repeat(np.repeat(downsampled, 2, axis=0), 2, axis=1)\n","            # Blend with original\n","            return np.maximum(grid, upsampled[:h, :w])\n","        return grid\n","    \n","    def recursive_synth(self, grid, depth=2):\n","        # Recursive synthesis for complex patterns\n","        if depth == 0:\n","            return grid\n","        \n","        # Apply transformations recursively\n","        transformed = self.symmetry_reflect(grid)\n","        transformed = self.pattern_extrapolate(transformed)\n","        \n","        return self.recursive_synth(transformed, depth-1)\n","\n","enhanced_dsl = EnhancedDSL()"]},{"cell_type":"code","execution_count":3,"id":"8bfd6cdf","metadata":{"execution":{"iopub.execute_input":"2025-10-28T09:21:05.710115Z","iopub.status.busy":"2025-10-28T09:21:05.709729Z","iopub.status.idle":"2025-10-28T09:21:05.781765Z","shell.execute_reply":"2025-10-28T09:21:05.780533Z"},"papermill":{"duration":0.078148,"end_time":"2025-10-28T09:21:05.783504","exception":false,"start_time":"2025-10-28T09:21:05.705356","status":"completed"},"tags":[]},"outputs":[],"source":["#  Cell 3\n","class EnhancedTinyVetoNet(nn.Module):\n","    def __init__(self, input_dim=256, hidden_dim=128, num_layers=4):\n","        super().__init__()\n","        self.input_dim = input_dim\n","        \n","        layers = []\n","        layers.append(nn.Linear(input_dim, hidden_dim))\n","        layers.append(nn.ReLU())\n","        layers.append(nn.Dropout(0.2))\n","        \n","        for _ in range(num_layers - 2):\n","            layers.append(nn.Linear(hidden_dim, hidden_dim))\n","            layers.append(nn.ReLU())\n","            layers.append(nn.Dropout(0.2))\n","            \n","        layers.append(nn.Linear(hidden_dim, 1))\n","        layers.append(nn.Sigmoid())\n","        \n","        self.network = nn.Sequential(*layers)\n","        \n","    def forward(self, x):\n","        return self.network(x)\n","    \n","    def extract_features(self, grid):\n","        features = []\n","        features.extend(self._extract_2d_features(grid))\n","        \n","        if config.ENABLE_3D_PATTERNS:\n","            features.extend(self._extract_3d_features(grid))\n","            \n","        features.extend(self._extract_pattern_features(grid))\n","        \n","        # Ensure fixed dimension\n","        if len(features) < self.input_dim:\n","            features.extend([0] * (self.input_dim - len(features)))\n","        else:\n","            features = features[:self.input_dim]\n","            \n","        return torch.tensor(features, dtype=torch.float32).unsqueeze(0)\n","    \n","    def _extract_2d_features(self, grid):\n","        features = []\n","        features.append(np.mean(grid > 0))  # Density\n","        features.append(len(np.unique(grid[grid > 0])))  # Color variety\n","        \n","        h, w = grid.shape\n","        center_h, center_w = h // 2, w // 2\n","        center_region = grid[center_h-1:center_h+2, center_w-1:center_w+2]\n","        features.append(np.mean(center_region > 0))\n","        \n","        edges = np.concatenate([grid[0, :], grid[-1, :], grid[:, 0], grid[:, -1]])\n","        features.append(np.mean(edges > 0))\n","        \n","        return features\n","    \n","    def _extract_3d_features(self, grid):\n","        features = []\n","        try:\n","            voxels = projector_3d.grid_to_3d_voxels(grid, depth_layers=4)\n","            \n","            # Depth layer statistics\n","            for i in range(min(4, voxels.shape[2])):\n","                layer = voxels[:, :, i]\n","                features.append(np.mean(layer > 0))\n","                features.append(len(np.unique(layer[layer > 0])))\n","                \n","            # Symmetry features\n","            vertical_sym = np.mean(voxels == np.flip(voxels, axis=0))\n","            horizontal_sym = np.mean(voxels == np.flip(voxels, axis=1))\n","            features.extend([vertical_sym, horizontal_sym])\n","                \n","        except Exception as e:\n","            features.extend([0] * 10)\n","            \n","        return features\n","    \n","    def _extract_pattern_features(self, grid):\n","        features = []\n","        \n","        # Connected components analysis\n","        labeled, num_components = ndimage.label(grid > 0)\n","        features.append(num_components)\n","        if num_components > 0:\n","            sizes = [np.sum(labeled == i) for i in range(1, num_components + 1)]\n","            features.append(max(sizes))\n","            features.append(np.mean(sizes))\n","        else:\n","            features.extend([0, 0])\n","            \n","        # Row/column patterns\n","        row_patterns = [np.any(grid[i, :] > 0) for i in range(grid.shape[0])]\n","        col_patterns = [np.any(grid[:, j] > 0) for j in range(grid.shape[1])]\n","        features.append(np.mean(row_patterns))\n","        features.append(np.mean(col_patterns))\n","        \n","        return features\n","\n","class EnhancedPolicyNetwork(nn.Module):\n","    def __init__(self, state_dim=256, num_primitives=50, hidden_dim=128):\n","        super().__init__()\n","        self.state_encoder = nn.Sequential(\n","            nn.Linear(state_dim, hidden_dim),\n","            nn.ReLU(),\n","            nn.Linear(hidden_dim, hidden_dim),\n","            nn.ReLU()\n","        )\n","        \n","        self.attention = nn.MultiheadAttention(hidden_dim, num_heads=4)\n","        self.primitive_predictor = nn.Linear(hidden_dim, num_primitives)\n","        \n","    def forward(self, state_features):\n","        encoded = self.state_encoder(state_features)\n","        attended, _ = self.attention(encoded.unsqueeze(0), encoded.unsqueeze(0), encoded.unsqueeze(0))\n","        logits = self.primitive_predictor(attended.squeeze(0))\n","        return torch.softmax(logits, dim=-1)\n","\n","# Initialize neural components\n","enhanced_veto_net = EnhancedTinyVetoNet().to(device)\n","enhanced_policy_net = EnhancedPolicyNetwork().to(device)"]},{"cell_type":"code","execution_count":4,"id":"6995f745","metadata":{"execution":{"iopub.execute_input":"2025-10-28T09:21:05.792259Z","iopub.status.busy":"2025-10-28T09:21:05.791894Z","iopub.status.idle":"2025-10-28T09:21:05.820788Z","shell.execute_reply":"2025-10-28T09:21:05.819614Z"},"papermill":{"duration":0.035192,"end_time":"2025-10-28T09:21:05.822436","exception":false,"start_time":"2025-10-28T09:21:05.787244","status":"completed"},"tags":[]},"outputs":[],"source":["#  Cell 4\n","class EnhancedBeamSearch:\n","    def __init__(self, dsl, config):\n","        self.dsl = dsl\n","        self.config = config\n","        self.cache = {}\n","        self.stats = defaultdict(int)\n","        \n","    def should_use_3d_early(self, task_complexity, grid_properties):\n","        if not self.config.USE_3D_EARLY:\n","            return False\n","            \n","        conditions = [\n","            task_complexity > 0.7 and self.config.USE_3D_ON_HARD,\n","            grid_properties.get('size', 0) > 100,\n","            grid_properties.get('sparsity', 0) > 0.8,\n","            grid_properties.get('density', 0) > 0.3,\n","        ]\n","        \n","        return any(conditions)\n","    \n","    def get_3d_enhanced_primitives(self, base_primitives, should_use_3d):\n","        enhanced = base_primitives.copy()\n","        \n","        if should_use_3d:\n","            enhanced_3d = [\n","                'project_3d_front', 'project_3d_top', 'project_3d_side',\n","                'voxelize_4layer', 'analyze_3d_patterns'\n","            ]\n","            for prim in reversed(enhanced_3d):\n","                if prim in enhanced:\n","                    enhanced.remove(prim)\n","                    enhanced.insert(0, prim)\n","        \n","        return enhanced\n","    \n","    def search(self, start_grid, target_grid, max_depth=None, max_width=None):\n","        if max_depth is None:\n","            max_depth = self.config.MAX_BEAM_DEPTH\n","        if max_width is None:\n","            max_width = self.config.MAX_BEAM_WIDTH\n","            \n","        # Analyze task complexity and grid properties\n","        task_complexity = self.analyze_task_complexity(start_grid, target_grid)\n","        grid_properties = self.analyze_grid_properties(start_grid)\n","        \n","        # Decide on 3D usage\n","        use_3d_early = self.should_use_3d_early(task_complexity, grid_properties)\n","        \n","        # Get appropriate primitives\n","        base_primitives = list(self.dsl.primitives.keys())\n","        primitives = self.get_3d_enhanced_primitives(base_primitives, use_3d_early)\n","        \n","        # Initialize beam\n","        beam = [{'grid': start_grid, 'program': [], 'score': 0.0, 'depth': 0}]\n","        best_solution = None\n","        best_score = -1\n","        \n","        start_time = time.time()\n","        \n","        for depth in range(max_depth):\n","            if time.time() - start_time > self.config.MAX_RUNTIME_PER_TASK:\n","                logger.info(\"Timeout reached, returning best solution\")\n","                break\n","                \n","            new_beam = []\n","            beam_width = self.calculate_dynamic_beam_width(depth, max_width)\n","            \n","            for node in beam[:beam_width]:\n","                if time.time() - start_time > self.config.MAX_RUNTIME_PER_TASK:\n","                    break\n","                    \n","                for prim_name in primitives:\n","                    if self.should_prune_early(node, prim_name, depth):\n","                        continue\n","                        \n","                    new_node = self.apply_primitive(node, prim_name, target_grid)\n","                    if new_node:\n","                        new_beam.append(new_node)\n","                        self.stats['nodes_expanded'] += 1\n","                        \n","                        if '3d' in prim_name.lower():\n","                            self.stats['3d_operations'] += 1\n","            \n","            # Sort and prune beam\n","            new_beam.sort(key=lambda x: x['score'], reverse=True)\n","            beam = new_beam[:beam_width]\n","            \n","            # Check for solution\n","            if beam and beam[0]['score'] > best_score:\n","                best_solution = beam[0]\n","                best_score = beam[0]['score']\n","                \n","            # Early termination if perfect match\n","            if best_score >= 0.99:\n","                logger.info(f\"Perfect solution found at depth {depth}\")\n","                break\n","                \n","            # Adaptive depth adjustment\n","            if self.config.ADAPTIVE_DEPTH and self.should_reduce_depth(beam, depth):\n","                max_depth = min(max_depth, depth + 2)\n","                \n","        logger.info(f\"Beam search completed: {self.stats}\")\n","        return best_solution\n","    \n","    def analyze_task_complexity(self, start_grid, target_grid):\n","        complexity_factors = []\n","        \n","        # Size change complexity\n","        size_ratio = max(target_grid.shape[0] / start_grid.shape[0], \n","                        target_grid.shape[1] / start_grid.shape[1])\n","        complexity_factors.append(min(size_ratio, 3.0) / 3.0)\n","        \n","        # Color change complexity\n","        start_palette = len(np.unique(start_grid[start_grid > 0]))\n","        target_palette = len(np.unique(target_grid[target_grid > 0]))\n","        palette_change = abs(target_palette - start_palette) / max(start_palette, 1)\n","        complexity_factors.append(min(palette_change, 1.0))\n","        \n","        # Structural change complexity\n","        start_density = np.mean(start_grid > 0)\n","        target_density = np.mean(target_grid > 0)\n","        density_change = abs(target_density - start_density)\n","        complexity_factors.append(density_change)\n","        \n","        return np.mean(complexity_factors)\n","    \n","    def analyze_grid_properties(self, grid):\n","        properties = {}\n","        properties['size'] = grid.shape[0] * grid.shape[1]\n","        properties['density'] = np.mean(grid > 0)\n","        properties['sparsity'] = 1.0 - properties['density']\n","        properties['color_variety'] = len(np.unique(grid[grid > 0]))\n","        \n","        # Check for patterns\n","        labeled, num_components = ndimage.label(grid > 0)\n","        properties['component_count'] = num_components\n","        if num_components > 0:\n","            sizes = [np.sum(labeled == i) for i in range(1, num_components + 1)]\n","            properties['largest_component_size'] = max(sizes)\n","        else:\n","            properties['largest_component_size'] = 0\n","        \n","        return properties\n","    \n","    def calculate_dynamic_beam_width(self, depth, max_width):\n","        if not self.config.DYNAMIC_BEAM_SCALING:\n","            return max_width\n","            \n","        # Start wide, narrow as we go deeper\n","        if depth == 0:\n","            return min(max_width * 2, 128)\n","        elif depth < 3:\n","            return max_width\n","        elif depth < 6:\n","            return max(max_width // 2, 8)\n","        else:\n","            return max(max_width // 4, 4)\n","    \n","    def should_prune_early(self, node, prim_name, depth):\n","        if not self.config.PRUNE_EARLY:\n","            return False\n","            \n","        # Don't apply the same primitive repeatedly\n","        if node['program'] and node['program'][-1] == prim_name:\n","            return True\n","            \n","        # Avoid certain sequences\n","        if len(node['program']) >= 2:\n","            last_two = node['program'][-2:]\n","            if last_two == ['rotate_90', 'rotate_270'] or last_two == ['rotate_270', 'rotate_90']:\n","                return True\n","                \n","        return False\n","    \n","    def should_reduce_depth(self, beam, current_depth):\n","        if len(beam) == 0:\n","            return True\n","            \n","        # If no improvement in recent depths, consider reducing\n","        if current_depth >= 6:\n","            recent_scores = [node['score'] for node in beam[:5]]\n","            if max(recent_scores) < 0.3:\n","                return True\n","                \n","        return False\n","    \n","    def apply_primitive(self, node, prim_name, target_grid):\n","        cache_key = (tuple(map(tuple, node['grid'])), prim_name)\n","        if cache_key in self.cache:\n","            self.stats['cache_hits'] += 1\n","            result_grid = self.cache[cache_key]\n","        else:\n","            try:\n","                prim_func = self.dsl.primitives[prim_name]\n","                result_grid = prim_func(node['grid'])\n","                self.cache[cache_key] = result_grid\n","            except Exception as e:\n","                logger.debug(f\"Primitive {prim_name} failed: {e}\")\n","                return None\n","        \n","        # Evaluate with novel confidence scoring\n","        score = calculate_iou(result_grid, target_grid)\n","        \n","        # Apply fuzzy confidence decay based on program length\n","        depth_penalty = self.config.CONFIDENCE_DECAY ** len(node['program'])\n","        final_score = score * depth_penalty\n","        \n","        return {\n","            'grid': result_grid,\n","            'program': node['program'] + [prim_name],\n","            'score': final_score,\n","            'depth': node['depth'] + 1\n","        }\n","\n","enhanced_beam_search = EnhancedBeamSearch(enhanced_dsl, config)"]},{"cell_type":"code","execution_count":null,"id":"facdac29","metadata":{"papermill":{"duration":0.002841,"end_time":"2025-10-28T09:21:05.828639","exception":false,"start_time":"2025-10-28T09:21:05.825798","status":"completed"},"tags":[]},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"id":"30300910","metadata":{"papermill":{"duration":0.002687,"end_time":"2025-10-28T09:21:05.834308","exception":false,"start_time":"2025-10-28T09:21:05.831621","status":"completed"},"tags":[]},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"id":"d6cb2bef","metadata":{"papermill":{"duration":0.002788,"end_time":"2025-10-28T09:21:05.840073","exception":false,"start_time":"2025-10-28T09:21:05.837285","status":"completed"},"tags":[]},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"id":"ba613fce","metadata":{"papermill":{"duration":0.00278,"end_time":"2025-10-28T09:21:05.845913","exception":false,"start_time":"2025-10-28T09:21:05.843133","status":"completed"},"tags":[]},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"id":"fcca8ff2","metadata":{"papermill":{"duration":0.002739,"end_time":"2025-10-28T09:21:05.851674","exception":false,"start_time":"2025-10-28T09:21:05.848935","status":"completed"},"tags":[]},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"id":"ed17673c","metadata":{"papermill":{"duration":0.002842,"end_time":"2025-10-28T09:21:05.857488","exception":false,"start_time":"2025-10-28T09:21:05.854646","status":"completed"},"tags":[]},"outputs":[],"source":[]}],"metadata":{"kaggle":{"accelerator":"none","dataSources":[{"databundleVersionId":11802066,"sourceId":91496,"sourceType":"competition"}],"dockerImageVersionId":31154,"isGpuEnabled":false,"isInternetEnabled":false,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.13"},"papermill":{"default_parameters":{},"duration":12.33056,"end_time":"2025-10-28T09:21:07.183947","environment_variables":{},"exception":null,"input_path":"__notebook__.ipynb","output_path":"__notebook__.ipynb","parameters":{},"start_time":"2025-10-28T09:20:54.853387","version":"2.6.0"}},"nbformat":4,"nbformat_minor":5}