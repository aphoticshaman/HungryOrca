#!/usr/bin/env python3
"""
UNIFIED CORTEX - The Core Brain Substrate
==========================================

One shared neural state. Not modules.
Consciousness emerges from coherent activation patterns.

ABLATION FLAGS: Every feature can be disabled for testing
"""

import numpy as np
from scipy import sparse
from typing import Dict, List, Tuple, Optional
import time

# ============================================================================
# ABLATION FLAGS - Flip to False to test impact
# ============================================================================

ENABLE_UNIFIED_CORTEX = True      # Core system (baseline)
ENABLE_SEMANTIC_BIAS = True       # Semantic processing tendency
ENABLE_SPATIAL_BIAS = True        # Spatial processing tendency
ENABLE_DISTRIBUTED_REPS = True    # Overlapping representations
ENABLE_ITERATIVE_PROPAGATION = True  # Multi-step activation spread
ENABLE_NONLINEARITY = True        # ReLU activation

# Performance tracking
ABLATION_SCORES = {}


# ============================================================================
# UNIFIED CORTEX - Core Class
# ============================================================================

class UnifiedCortex:
    """
    Single shared cortical state.

    Architecture:
    - 10,000 neurons (all shared, no hard boundaries)
    - Neurons 0-2500: Visual cortex (perception)
    - Neurons 2500-5000: Semantic-biased (patterns, rules, language-like)
    - Neurons 5000-7500: Spatial-biased (geometry, transforms, topology)
    - Neurons 7500-10000: Motor cortex (output construction)

    BUT: These are TENDENCIES, not hard boundaries!
    Neurons 4000-6000 respond to BOTH semantic and spatial.
    """

    def __init__(self, size: int = 10000, connection_density: float = 0.01):
        """
        Initialize unified cortical state.

        Args:
            size: Number of neurons (default 10,000)
            connection_density: Sparsity of connections (default 1%)
        """

        if not ENABLE_UNIFIED_CORTEX:
            # Fallback to simple processing if disabled
            self.neurons = np.zeros(100)  # Minimal state
            self.connections = sparse.eye(100)
            return

        # SHARED NEURAL STATE (the key innovation!)
        self.size = size
        self.neurons = np.zeros(size)

        # CONNECTIVITY MATRIX (sparse for efficiency)
        # Real brain: ~10^4 connections per neuron, but we can't afford that
        # Use 1% density = ~100 connections per neuron
        self.connections = sparse.random(size, size, density=connection_density, format='csr')

        # Make connections roughly normalized (prevent explosion)
        row_sums = np.array(self.connections.sum(axis=1)).flatten()
        row_sums[row_sums == 0] = 1  # Avoid div by zero
        self.connections = sparse.diags(1.0 / row_sums) @ self.connections

        # PROCESSING BIASES (not separate modules!)
        if ENABLE_SEMANTIC_BIAS:
            self.semantic_bias = np.zeros(size)
            sem_start = int(size * 0.25)
            sem_end = int(size * 0.50)
            self.semantic_bias[sem_start:sem_end] = 1.0  # Peak in "semantic region"
            # But also some influence in overlap region
            overlap_start = int(size * 0.40)
            overlap_end = int(size * 0.60)
            self.semantic_bias[overlap_start:overlap_end] = 0.5
        else:
            self.semantic_bias = np.zeros(size)

        if ENABLE_SPATIAL_BIAS:
            self.spatial_bias = np.zeros(size)
            spat_start = int(size * 0.50)
            spat_end = int(size * 0.75)
            self.spatial_bias[spat_start:spat_end] = 1.0  # Peak in "spatial region"
            # And overlap region
            overlap_start = int(size * 0.40)
            overlap_end = int(size * 0.60)
            self.spatial_bias[overlap_start:overlap_end] = 0.5
        else:
            self.spatial_bias = np.zeros(size)

        # State tracking
        self.activation_history = []
        self.current_context = 'both'  # 'semantic', 'spatial', or 'both'

    def reset(self):
        """Reset cortical state to baseline."""
        self.neurons = np.zeros(self.size)
        self.activation_history = []

    def encode_grid(self, grid: np.ndarray) -> np.ndarray:
        """
        Encode ARC grid into neural activation pattern.

        Simple encoding: Flatten grid and map to visual cortex.
        Visual cortex = first 25% of neurons (0-25%).
        """

        # Flatten grid
        flat = grid.flatten()

        # Map to visual cortex (first 25% of neurons)
        visual_size = int(self.size * 0.25)
        visual_activation = np.zeros(visual_size)

        # Repeat pattern to fill visual cortex
        repeats = int(np.ceil(visual_size / len(flat)))
        extended = np.tile(flat, repeats)[:visual_size]

        # Normalize to [0, 1]
        if extended.max() > 0:
            visual_activation = extended / extended.max()
        else:
            visual_activation = extended

        return visual_activation

    def activate(self, stimulus: np.ndarray, context: str = 'both',
                 iterations: int = 10) -> np.ndarray:
        """
        Activate cortex with stimulus.

        Args:
            stimulus: Input (e.g., encoded grid)
            context: Processing bias ('semantic', 'spatial', 'both')
            iterations: Number of propagation steps

        Returns:
            Final cortical state
        """

        if not ENABLE_UNIFIED_CORTEX:
            # Fallback: simple passthrough
            return stimulus[:100] if len(stimulus) > 100 else np.pad(stimulus, (0, 100-len(stimulus)))

        # INITIAL ACTIVATION: Stimulus activates visual cortex
        visual_size = int(self.size * 0.25)
        if len(stimulus) <= visual_size:
            self.neurons[:len(stimulus)] += stimulus
        else:
            self.neurons[:visual_size] += stimulus[:visual_size]

        # ITERATIVE PROPAGATION
        if ENABLE_ITERATIVE_PROPAGATION:
            for iteration in range(iterations):
                # Propagate through connections
                new_activation = self.connections @ self.neurons

                # Apply contextual bias
                if context == 'semantic' or context == 'both':
                    if ENABLE_SEMANTIC_BIAS:
                        new_activation *= (1 + self.semantic_bias)

                if context == 'spatial' or context == 'both':
                    if ENABLE_SPATIAL_BIAS:
                        new_activation *= (1 + self.spatial_bias)

                # Update with decay (prevent saturation)
                self.neurons = 0.7 * self.neurons + 0.3 * new_activation

                # Non-linearity
                if ENABLE_NONLINEARITY:
                    self.neurons = np.maximum(0, self.neurons)  # ReLU

                # Record history
                self.activation_history.append(self.neurons.copy())

        return self.neurons

    def get_semantic_state(self) -> np.ndarray:
        """Get semantic-biased region activation."""
        start = int(self.size * 0.25)
        end = int(self.size * 0.50)
        return self.neurons[start:end]

    def get_spatial_state(self) -> np.ndarray:
        """Get spatial-biased region activation."""
        start = int(self.size * 0.50)
        end = int(self.size * 0.75)
        return self.neurons[start:end]

    def get_motor_state(self) -> np.ndarray:
        """Get motor cortex (output planning) activation."""
        start = int(self.size * 0.75)
        return self.neurons[start:]

    def measure_coherence(self) -> float:
        """
        Measure semantic-spatial coherence.

        High coherence = both regions agree (unified percept).
        Low coherence = conflict (still processing).
        """

        semantic = self.get_semantic_state()
        spatial = self.get_spatial_state()

        # Coherence = correlation in overlap region
        # Overlap region is 40-60% of cortex (influenced by both)
        overlap_start = int(self.size * 0.40)
        overlap_mid = int(self.size * 0.50)
        overlap_end = int(self.size * 0.60)

        overlap_semantic = self.neurons[overlap_start:overlap_mid]  # Tail of semantic
        overlap_spatial = self.neurons[overlap_mid:overlap_end]     # Head of spatial

        if ENABLE_DISTRIBUTED_REPS:
            # Measure agreement via dot product
            min_len = min(len(overlap_semantic), len(overlap_spatial))
            if min_len > 0:
                coherence = np.dot(overlap_semantic[:min_len], overlap_spatial[:min_len])
                # Normalize
                norm_s = np.linalg.norm(overlap_semantic[:min_len])
                norm_p = np.linalg.norm(overlap_spatial[:min_len])
                if norm_s > 0 and norm_p > 0:
                    coherence = coherence / (norm_s * norm_p)
                else:
                    coherence = 0.0
            else:
                coherence = 0.0
        else:
            # Without distributed reps, coherence is always low
            coherence = 0.0

        return coherence

    def get_energy(self) -> float:
        """
        Calculate cortical energy.

        Lower energy = more stable, coherent state.
        Physics-inspired: systems seek minimum energy.
        """

        # Energy component 1: Self-consistency
        # How stable is current state?
        next_state = self.connections @ self.neurons
        stability_energy = np.linalg.norm(next_state - self.neurons)

        # Energy component 2: Coherence
        # Are semantic and spatial aligned?
        coherence = self.measure_coherence()
        coherence_energy = 1.0 - coherence  # Lower coherence = higher energy

        # Energy component 3: Total activation
        # Prevent over-activation
        activation_energy = np.sum(self.neurons ** 2)

        total_energy = 0.5 * stability_energy + 0.3 * coherence_energy + 0.2 * activation_energy

        return total_energy


# ============================================================================
# SIMPLE SOLVER USING UNIFIED CORTEX
# ============================================================================

class CorticalSolver:
    """
    Simple solver that uses unified cortex.

    Baseline implementation to test cortical processing.
    """

    def __init__(self):
        self.cortex = UnifiedCortex()

    def solve_task(self, train_pairs: List[Tuple[np.ndarray, np.ndarray]],
                   test_input: np.ndarray,
                   time_limit: float = 5.0) -> Tuple[np.ndarray, float]:
        """
        Solve ARC task using cortical processing.

        Baseline approach:
        1. Activate cortex with training examples
        2. Learn cortical pattern
        3. Apply to test input
        4. Extract solution from motor cortex
        """

        start_time = time.time()

        # Calculate cortex regions (proportional, not hardcoded!)
        cortex_size = self.cortex.size
        motor_start = int(cortex_size * 0.75)  # Last 25% is motor cortex
        motor_size = cortex_size - motor_start

        # TRAINING PHASE: Learn from examples
        for inp, out in train_pairs:
            self.cortex.reset()

            # Encode input
            inp_encoded = self.cortex.encode_grid(inp)
            self.cortex.activate(inp_encoded, context='both')

            # Encode output (what we want to achieve)
            out_encoded = self.cortex.encode_grid(out)
            # Activate motor cortex with desired output
            motor_len = min(len(out_encoded), motor_size)
            self.cortex.neurons[motor_start:motor_start+motor_len] = out_encoded[:motor_len]

            if time.time() - start_time > time_limit * 0.3:
                break

        # TEST PHASE: Apply to test input
        self.cortex.reset()
        test_encoded = self.cortex.encode_grid(test_input)
        self.cortex.activate(test_encoded, context='both')

        # Extract solution from motor cortex
        motor_output = self.cortex.get_motor_state()

        # Decode (simple: reshape to match test input)
        try:
            solution = motor_output[:test_input.size].reshape(test_input.shape)
            # Discretize to ARC colors (0-9)
            solution = np.round(solution * 9).astype(int)
            solution = np.clip(solution, 0, 9)
        except:
            # Fallback: return input
            solution = test_input.copy()

        # Confidence = coherence
        confidence = self.cortex.measure_coherence()

        return solution, confidence


# ============================================================================
# ABLATION TEST HARNESS
# ============================================================================

def run_ablation_test(solver, test_tasks: List, num_samples: int = 10,
                      feature_name: str = "BASELINE"):
    """
    Test solver performance with ablation tracking.

    Args:
        solver: Solver instance
        test_tasks: List of ARC tasks
        num_samples: Number of tasks to test
        feature_name: Name of feature being tested

    Returns:
        Average accuracy
    """

    correct = 0
    total = 0
    confidences = []

    for task in test_tasks[:num_samples]:
        train_pairs = [(np.array(p['input']), np.array(p['output']))
                      for p in task['train']]
        test_input = np.array(task['test'][0]['input'])

        solution, confidence = solver.solve_task(train_pairs, test_input, time_limit=2.0)
        confidences.append(confidence)
        total += 1

        # Simple correctness check (would need ground truth for real test)
        # For now, just track confidence as proxy

    avg_confidence = np.mean(confidences) if confidences else 0.0

    # Store result
    ABLATION_SCORES[feature_name] = avg_confidence

    print(f"\nüß™ ABLATION TEST: {feature_name}")
    print(f"   Samples: {total}")
    print(f"   Avg Confidence: {avg_confidence:.3f}")
    print(f"   Status: {'‚úÖ KEEP' if avg_confidence > 0.1 else '‚ùå DROP'}")

    return avg_confidence


# ============================================================================
# QUICK TEST
# ============================================================================

if __name__ == '__main__':
    print("="*80)
    print("UNIFIED CORTEX - Quick Test")
    print("="*80)

    # Test 1: Basic cortical activation
    print("\nüìä Test 1: Basic Cortical Activation")
    cortex = UnifiedCortex()

    # Create simple test grid
    test_grid = np.array([[1, 2, 3], [4, 5, 6], [7, 8, 9]])
    encoded = cortex.encode_grid(test_grid)

    print(f"   Grid shape: {test_grid.shape}")
    print(f"   Encoded length: {len(encoded)}")
    print(f"   Visual cortex activated: {np.sum(cortex.neurons[:2500] > 0)} neurons")

    # Test 2: Activation propagation
    print("\nüìä Test 2: Activation Propagation")
    cortex.activate(encoded, context='both', iterations=10)

    print(f"   Total active neurons: {np.sum(cortex.neurons > 0.01)}/{cortex.size}")
    print(f"   Semantic region active: {np.sum(cortex.get_semantic_state() > 0.01)}")
    print(f"   Spatial region active: {np.sum(cortex.get_spatial_state() > 0.01)}")
    print(f"   Motor region active: {np.sum(cortex.get_motor_state() > 0.01)}")
    print(f"   Coherence: {cortex.measure_coherence():.3f}")
    print(f"   Energy: {cortex.get_energy():.3f}")

    # Test 3: Try loading real ARC data
    print("\nüìä Test 3: Real ARC Data Test")
    try:
        import json
        with open('arc-agi_training_challenges.json') as f:
            training_tasks = json.load(f)

        # Test cortical solver on first task
        task_id = list(training_tasks.keys())[0]
        task = training_tasks[task_id]

        solver = CorticalSolver()
        train_pairs = [(np.array(p['input']), np.array(p['output']))
                      for p in task['train']]
        test_input = np.array(task['test'][0]['input'])

        solution, confidence = solver.solve_task(train_pairs, test_input)

        print(f"   Task: {task_id}")
        print(f"   Input shape: {test_input.shape}")
        print(f"   Output shape: {solution.shape}")
        print(f"   Confidence: {confidence:.3f}")
        print(f"   ‚úÖ Cortical solver working!")

    except Exception as e:
        print(f"   ‚ö†Ô∏è  Could not load ARC data: {e}")
        print(f"   (This is OK - just testing cortex mechanics)")

    print("\n" + "="*80)
    print("‚úÖ UNIFIED CORTEX CORE: OPERATIONAL")
    print("="*80)
    print("\nüß™ ABLATION FLAGS:")
    print(f"   ENABLE_UNIFIED_CORTEX: {ENABLE_UNIFIED_CORTEX}")
    print(f"   ENABLE_SEMANTIC_BIAS: {ENABLE_SEMANTIC_BIAS}")
    print(f"   ENABLE_SPATIAL_BIAS: {ENABLE_SPATIAL_BIAS}")
    print(f"   ENABLE_DISTRIBUTED_REPS: {ENABLE_DISTRIBUTED_REPS}")
    print(f"   ENABLE_ITERATIVE_PROPAGATION: {ENABLE_ITERATIVE_PROPAGATION}")
    print(f"   ENABLE_NONLINEARITY: {ENABLE_NONLINEARITY}")
    print("\nReady for Phase 2: 360¬∞ Vision System")
